{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Digital Garden","text":"<p>A living knowledge base for distributed systems, storage architecture, and infrastructure engineering</p>"},{"location":"#latest-posts","title":"\ud83d\udcdd Latest Posts","text":"<p>\u27a1\ufe0f View All Posts</p>"},{"location":"#kubectl-essentials-your-kubernetes-swiss-army-knife","title":"kubectl Essentials: Your Kubernetes Swiss Army Knife","text":"<p>Kubernetes \u00b7 13 min read</p> <p>Master kubectl commands, output formats, and productivity patterns essential for CKA exam success. Learn imperative vs declarative approaches, JSONPath queries, context management, and time-saving aliases for Kubernetes cluster management.</p> <p>Topics: kubernetes, k8s, cka-prep, kubectl</p> <p>Read more \u2192</p>"},{"location":"#setting-up-your-kubernetes-lab-environment","title":"Setting Up Your Kubernetes Lab Environment","text":"<p>Kubernetes \u00b7 Infrastructure \u00b7 12 min read</p> <p>Complete guide to setting up Kubernetes lab environments for CKA preparation. Covers kubeadm cluster setup, Minikube for local development, kind for testing, kubectl installation, and kubeconfig management with practical examples.</p> <p>Topics: kubernetes, k8s, cka-prep, kubeadm, kubectl, minikube</p> <p>Read more \u2192</p>"},{"location":"#kubernetes-architecture-fundamentals","title":"Kubernetes Architecture Fundamentals","text":"<p>Kubernetes \u00b7 Architecture \u00b7 15 min read</p> <p>Deep dive into Kubernetes cluster architecture, control plane components, and the distributed systems design that powers container orchestration at scale. Essential foundations for CKA certification with comprehensive diagrams, kubectl commands, and hands-on practice exercises.</p> <p>Topics: kubernetes, k8s, cka-prep, architecture, control-plane, kubectl</p> <p>Read more \u2192</p>"},{"location":"#high-performance-pnfs-v42-distributed-storage-architecture","title":"High-Performance pNFS v4.2 Distributed Storage Architecture","text":"<p>Storage \u00b7 Architecture \u00b7 12 min read</p> <p>A deep dive into building a clustered, high-availability parallel NFS storage system with load-balanced metadata servers, NVMe-backed storage nodes, and low-latency interconnects. Features production-grade architecture with InfiniBand/RoCE fabrics, active-active MDS clustering, and parallel data paths achieving 28 GB/s aggregate throughput.</p> <p>Topics: pNFS v4.2, distributed storage, NVMe, InfiniBand, RoCE, high availability, load balancing, metadata clustering</p> <p>Read more \u2192</p>"},{"location":"#browse-by-theme","title":"\ud83d\uddc2\ufe0f Browse by Theme","text":"<ul> <li> <p> Kubernetes CKA Mastery</p> <p>Complete CKA certification prep with 22 comprehensive posts</p> <p>Explore Kubernetes \u2192</p> </li> <li> <p> AI &amp; Automation</p> <p>Agents, MCP servers, tool orchestration, LLM workflows</p> <p>Explore AI \u2192</p> </li> <li> <p> Cloud Infrastructure</p> <p>GCP, Azure, AWS, multi-cloud architectures</p> <p>Explore Cloud \u2192</p> </li> <li> <p> Infrastructure as Code</p> <p>Terraform, Ansible, GitOps, automation</p> <p>Explore IaC \u2192</p> </li> <li> <p> On-Premise Systems</p> <p>Bare metal, datacenter, networking, storage</p> <p>Explore On-Prem \u2192</p> </li> <li> <p> Cybersecurity</p> <p>Security architecture, hardening, compliance</p> <p>Explore Security \u2192</p> </li> <li> <p> Storage &amp; Networking</p> <p>File systems, protocols, high-performance I/O</p> <p>Explore Storage \u2192</p> </li> </ul>"},{"location":"#additional-resources","title":"\ud83e\udded Additional Resources","text":"<ul> <li>Knowledge Base: Curated reference material and evergreen documentation</li> <li>Principles: Engineering principles and design patterns</li> <li>Journal: Progress logs and learning notes</li> <li>Tags: Browse all content by tag</li> </ul> <p>This garden grows continuously \u00b7 Follow on GitHub \u00b7 RSS Feed</p>"},{"location":"blog/","title":"Blog","text":"<p>Technical deep-dives into distributed systems, storage architecture, and infrastructure engineering.</p>"},{"location":"blog/#navigate","title":"Navigate","text":"<ul> <li>Browse by Tags for topic-based exploration</li> <li>View the Archive for chronological browsing</li> <li>Filter by Categories below</li> </ul> <p>All posts include estimated read times and are optimized for both technical depth and practical application.</p>"},{"location":"blog/tags/","title":"Tag Index","text":"<p>Browse all posts by tag. Tags provide fine-grained topic classification across multiple dimensions.</p>"},{"location":"blog/tags/#tag:infiniband","title":"InfiniBand","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:nvme","title":"NVMe","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:roce","title":"RoCE","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:architecture","title":"architecture","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> </ul>"},{"location":"blog/tags/#tag:cka-prep","title":"cka-prep","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:clustering","title":"clustering","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:command-line","title":"command-line","text":"<ul> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:control-plane","title":"control-plane","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> </ul>"},{"location":"blog/tags/#tag:distributed-storage","title":"distributed-storage","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:high-availability","title":"high-availability","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:k8s","title":"k8s","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:kubeadm","title":"kubeadm","text":"<ul> <li>            Setting Up Your Kubernetes Lab Environment          </li> </ul>"},{"location":"blog/tags/#tag:kubectl","title":"kubectl","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:kubernetes","title":"kubernetes","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:load-balancing","title":"load-balancing","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:metadata","title":"metadata","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:minikube","title":"minikube","text":"<ul> <li>            Setting Up Your Kubernetes Lab Environment          </li> </ul>"},{"location":"blog/tags/#tag:pnfs","title":"pNFS","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:parallel-io","title":"parallel-io","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag-descriptions","title":"Tag Descriptions","text":"<ul> <li>pNFS: Parallel NFS protocol and implementations</li> <li>distributed-storage: Multi-node storage architectures</li> <li>NVMe: Non-Volatile Memory Express technologies</li> <li>high-availability: HA clustering and failover systems</li> <li>load-balancing: Traffic distribution and request routing</li> <li>metadata: Metadata server design and optimization</li> <li>clustering: Cluster management and coordination</li> <li>InfiniBand: InfiniBand networking and RDMA</li> <li>RoCE: RDMA over Converged Ethernet</li> <li>parallel-io: Parallel I/O patterns and optimization</li> <li>file-systems: File system design and internals</li> <li>linux: Linux kernel and system programming</li> <li>performance-tuning: System optimization techniques</li> <li>scalability: Scaling strategies and patterns</li> </ul>"},{"location":"blog/2025/11/11/kubectl-essentials/","title":"kubectl Essentials: Your Kubernetes Swiss Army Knife","text":"<p>Master kubectl for CKA exam success. Learn imperative commands for speed, output formats for precision, and productivity patterns that save critical exam minutes.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#overview","title":"Overview","text":"<p>kubectl is the command-line interface to Kubernetes and your primary tool during the CKA exam. While the exam allows access to official documentation, proficiency with kubectl commands determines whether you finish in time.</p> <p>CKA Exam Domain: All domains (kubectl is used for every task)</p> <p>Key Insight: CKA exam success correlates directly with kubectl speed. Candidates who master imperative commands and output formats consistently score higher and finish with time to spare.</p> <p>What You'll Learn: - Essential kubectl commands by category - Imperative vs declarative approaches for exam efficiency - Output formats and JSONPath for data extraction - Context and namespace management patterns - kubectl explain for in-exam documentation - Time-saving aliases and autocomplete workflows</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#command-categories-overview","title":"Command Categories Overview","text":"<p>kubectl commands follow functional patterns that map to exam task types.</p> <pre><code>graph TB\n    subgraph \"Resource Lifecycle\"\n        CREATE[Create/Generate&lt;br/&gt;run, create, expose]\n        READ[Inspect&lt;br/&gt;get, describe, logs]\n        UPDATE[Modify&lt;br/&gt;edit, patch, scale, set]\n        DELETE[Remove&lt;br/&gt;delete]\n    end\n\n    subgraph \"Debugging &amp; Troubleshooting\"\n        EXEC[Execute&lt;br/&gt;exec, cp]\n        DEBUG[Debug&lt;br/&gt;debug, logs, port-forward]\n        METRICS[Metrics&lt;br/&gt;top]\n    end\n\n    subgraph \"Configuration &amp; Context\"\n        CONFIG[Configure&lt;br/&gt;config, explain]\n        APPLY[Apply&lt;br/&gt;apply, replace]\n        ROLLOUT[Rollouts&lt;br/&gt;rollout, scale]\n    end\n\n    CREATE --&gt; UPDATE\n    UPDATE --&gt; ROLLOUT\n    READ --&gt; DEBUG\n    DEBUG --&gt; EXEC\n    CONFIG --&gt; APPLY\n\n    style CREATE fill:#e1f5ff\n    style READ fill:#e8f5e8\n    style UPDATE fill:#fff4e1\n    style DELETE fill:#ffe5e5\n    style DEBUG fill:#f5e1ff</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#essential-commands-by-category","title":"Essential Commands by Category","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#resource-creation-commands","title":"Resource Creation Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-run-pods","title":"kubectl run (Pods)","text":"<p>Purpose: Create pods imperatively - fastest method for simple pods</p> <pre><code># Basic pod creation\nkubectl run nginx --image=nginx\n\n# Pod with port specification\nkubectl run nginx --image=nginx --port=80\n\n# Pod with labels\nkubectl run nginx --image=nginx --labels=\"app=web,tier=frontend\"\n\n# Pod with environment variables\nkubectl run nginx --image=nginx --env=\"DB_HOST=mysql\" --env=\"DB_PORT=3306\"\n\n# Generate YAML without creating (CRITICAL for exam)\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n</code></pre> <p>Exam Pattern: Use <code>--dry-run=client -o yaml</code> to generate templates, then edit as needed.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-create-workloads","title":"kubectl create (Workloads)","text":"<p>Purpose: Generate deployments, jobs, services with imperative commands</p> <pre><code># Deployment creation\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Job creation\nkubectl create job hello --image=busybox:1.28 -- echo \"Hello World\"\n\n# CronJob creation\nkubectl create cronjob hello \\\n  --image=busybox:1.28 \\\n  --schedule=\"*/5 * * * *\" \\\n  -- /bin/sh -c \"date; echo Hello from CronJob\"\n\n# Service creation\nkubectl create service clusterip my-service --tcp=8080:80\nkubectl create service nodeport my-service --tcp=8080:80 --node-port=30080\n\n# ConfigMap from literals\nkubectl create configmap app-config \\\n  --from-literal=env=production \\\n  --from-literal=debug=false\n\n# Secret creation\nkubectl create secret generic db-secret \\\n  --from-literal=username=admin \\\n  --from-literal=password=secretpass\n\n# All with YAML generation\nkubectl create deployment webapp --image=nginx --dry-run=client -o yaml &gt; deploy.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-expose-services","title":"kubectl expose (Services)","text":"<p>Purpose: Expose existing resources as services</p> <pre><code># Expose pod\nkubectl expose pod nginx --port=80 --type=NodePort\n\n# Expose deployment\nkubectl expose deployment webapp --port=80 --target-port=8080 --type=LoadBalancer\n\n# Expose with specific name\nkubectl expose deployment webapp --port=80 --name=web-service --type=ClusterIP\n\n# Generate service YAML\nkubectl expose deployment webapp --port=80 --dry-run=client -o yaml &gt; service.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#resource-inspection-commands","title":"Resource Inspection Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-get-list-resources","title":"kubectl get (List Resources)","text":"<p>Purpose: Query cluster state - most frequently used command</p> <pre><code># Basic resource listing\nkubectl get pods                        # Current namespace\nkubectl get pods -A                     # All namespaces\nkubectl get pods -n kube-system        # Specific namespace\nkubectl get all                         # All resources in namespace\n\n# Wide output (additional columns)\nkubectl get pods -o wide                # Shows IP, Node, etc.\nkubectl get nodes -o wide              # Shows internal IP, OS, etc.\n\n# Show labels\nkubectl get pods --show-labels\n\n# Filter by labels\nkubectl get pods -l app=nginx\nkubectl get pods -l 'env in (dev,staging)'\nkubectl get pods -l app=nginx,tier!=frontend\n\n# Multiple resource types\nkubectl get pods,services,deployments\nkubectl get deploy,rs,pods\n</code></pre> <p>Output Formats (covered in detail later): - <code>-o wide</code> - Additional columns - <code>-o yaml</code> - Full YAML representation - <code>-o json</code> - Full JSON representation - <code>-o name</code> - Resource names only - <code>-o custom-columns</code> - User-defined columns - <code>-o jsonpath</code> - JSONPath expressions</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-describe-detailed-information","title":"kubectl describe (Detailed Information)","text":"<p>Purpose: Get detailed resource information with events</p> <pre><code># Describe resources\nkubectl describe pod nginx\nkubectl describe node worker-1\nkubectl describe deployment webapp\nkubectl describe service my-service\n\n# Describe from file\nkubectl describe -f deployment.yaml\n\n# Common use case: debugging\nkubectl describe pod failing-pod  # Check Events section for issues\n</code></pre> <p>Key Information in describe Output: - Events: Recent state changes, errors, scheduling decisions - Status: Current resource state - Spec: Resource configuration - Conditions: Health checks and readiness</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#resource-modification-commands","title":"Resource Modification Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-edit-interactive-editing","title":"kubectl edit (Interactive Editing)","text":"<p>Purpose: Edit resources in your default editor</p> <pre><code># Edit pod\nkubectl edit pod nginx\n\n# Edit deployment\nkubectl edit deployment webapp\n\n# Edit with specific editor\nKUBE_EDITOR=\"vim\" kubectl edit service my-service\n</code></pre> <p>Exam Tip: <code>kubectl edit</code> opens full resource YAML. Use with caution - easy to accidentally modify important fields. Prefer <code>kubectl patch</code> or <code>kubectl set</code> for targeted changes.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-patch-partial-updates","title":"kubectl patch (Partial Updates)","text":"<p>Purpose: Update specific fields without full resource replacement</p> <pre><code># Update image\nkubectl patch pod nginx -p '{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"image\":\"nginx:1.21\"}]}}'\n\n# Scale using patch\nkubectl patch deployment webapp -p '{\"spec\":{\"replicas\":5}}'\n\n# Strategic merge patch (default)\nkubectl patch deployment webapp --type=strategic -p '{\"spec\":{\"replicas\":3}}'\n\n# JSON patch\nkubectl patch deployment webapp --type=json -p='[{\"op\": \"replace\", \"path\": \"/spec/replicas\", \"value\":5}]'\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-scale-replica-management","title":"kubectl scale (Replica Management)","text":"<p>Purpose: Change replica count for deployments, replica sets</p> <pre><code># Scale deployment\nkubectl scale deployment webapp --replicas=5\n\n# Scale replica set\nkubectl scale rs my-replicaset --replicas=3\n\n# Scale from file\nkubectl scale --replicas=3 -f deployment.yaml\n\n# Conditional scaling\nkubectl scale deployment webapp --current-replicas=3 --replicas=5\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-set-update-resource-fields","title":"kubectl set (Update Resource Fields)","text":"<p>Purpose: Update specific resource fields with simple syntax</p> <pre><code># Update image\nkubectl set image deployment/webapp nginx=nginx:1.21\nkubectl set image deployment/webapp nginx=nginx:1.21 --record\n\n# Update resources\nkubectl set resources deployment webapp \\\n  --limits=cpu=200m,memory=512Mi \\\n  --requests=cpu=100m,memory=256Mi\n\n# Update service account\nkubectl set serviceaccount deployment webapp my-service-account\n\n# Update selector\nkubectl set selector service my-service app=nginx,tier=frontend\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#deployment-management-commands","title":"Deployment Management Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-rollout-deployment-updates","title":"kubectl rollout (Deployment Updates)","text":"<p>Purpose: Manage deployment rollouts and history</p> <pre><code># Check rollout status\nkubectl rollout status deployment/webapp\nkubectl rollout status deployment/webapp --watch\n\n# View rollout history\nkubectl rollout history deployment/webapp\nkubectl rollout history deployment/webapp --revision=3\n\n# Undo rollout (rollback)\nkubectl rollout undo deployment/webapp                    # Rollback to previous\nkubectl rollout undo deployment/webapp --to-revision=2    # Rollback to specific\n\n# Restart deployment (rolling restart)\nkubectl rollout restart deployment/webapp\n\n# Pause/Resume rollout\nkubectl rollout pause deployment/webapp\nkubectl rollout resume deployment/webapp\n</code></pre> <p>Exam Scenario Flow: <pre><code>sequenceDiagram\n    participant User\n    participant Deployment\n    participant ReplicaSet\n    participant Pods\n\n    User-&gt;&gt;Deployment: kubectl set image deploy/webapp nginx=nginx:1.21\n    Deployment-&gt;&gt;ReplicaSet: Create new ReplicaSet (nginx:1.21)\n    ReplicaSet-&gt;&gt;Pods: Create new pods gradually\n\n    Note over Deployment,Pods: Rolling update in progress\n\n    User-&gt;&gt;Deployment: kubectl rollout status deploy/webapp\n    Deployment--&gt;&gt;User: Waiting for rollout to finish...\n\n    alt Update fails\n        User-&gt;&gt;Deployment: kubectl rollout undo deploy/webapp\n        Deployment-&gt;&gt;ReplicaSet: Scale up old ReplicaSet\n        ReplicaSet-&gt;&gt;Pods: Create pods with old image\n    else Update succeeds\n        Deployment-&gt;&gt;ReplicaSet: Scale down old ReplicaSet\n        ReplicaSet-&gt;&gt;Pods: Terminate old pods\n    end\n\n    User-&gt;&gt;Deployment: kubectl rollout history deploy/webapp\n    Deployment--&gt;&gt;User: Show revision history</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#debugging-commands","title":"Debugging Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-logs-container-logs","title":"kubectl logs (Container Logs)","text":"<p>Purpose: View container stdout/stderr logs</p> <pre><code># Basic logs\nkubectl logs pod-name\nkubectl logs pod-name -c container-name        # Multi-container pods\n\n# Follow logs (stream)\nkubectl logs -f pod-name\n\n# Previous container instance (after crash)\nkubectl logs pod-name --previous\nkubectl logs pod-name -c container-name --previous\n\n# Logs from deployment\nkubectl logs deployment/webapp\nkubectl logs deployment/webapp -c nginx\n\n# Logs with labels\nkubectl logs -l app=nginx                      # All pods with label\nkubectl logs -f -l app=nginx --all-containers  # Stream all containers\n\n# Tail last N lines\nkubectl logs pod-name --tail=50\nkubectl logs pod-name --since=1h              # Last hour\nkubectl logs pod-name --since-time=2024-01-01T00:00:00Z\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-exec-execute-commands","title":"kubectl exec (Execute Commands)","text":"<p>Purpose: Run commands inside containers</p> <pre><code># Single command\nkubectl exec pod-name -- ls /app\nkubectl exec pod-name -- env\nkubectl exec pod-name -- cat /etc/resolv.conf\n\n# Interactive shell\nkubectl exec -it pod-name -- /bin/bash\nkubectl exec -it pod-name -- /bin/sh\n\n# Multi-container pod\nkubectl exec -it pod-name -c container-name -- /bin/bash\n\n# Deployment exec (first pod)\nkubectl exec deployment/webapp -- env\nkubectl exec -it deployment/webapp -- /bin/bash\n</code></pre> <p>Common Exam Patterns: <pre><code># Check pod networking\nkubectl exec -it pod-name -- ping google.com\nkubectl exec -it pod-name -- nslookup kubernetes.default\n\n# Verify volume mounts\nkubectl exec pod-name -- ls /mnt/data\n\n# Test service connectivity\nkubectl exec -it pod-name -- curl http://service-name:8080\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-port-forward-local-access","title":"kubectl port-forward (Local Access)","text":"<p>Purpose: Forward local port to pod/service for debugging</p> <pre><code># Forward to pod\nkubectl port-forward pod/nginx 8080:80        # Local:8080 -&gt; Pod:80\n\n# Forward to service\nkubectl port-forward service/webapp 8080:80\n\n# Forward to deployment\nkubectl port-forward deployment/webapp 8080:80\n\n# Listen on all interfaces (use with caution)\nkubectl port-forward --address 0.0.0.0 pod/nginx 8080:80\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-debug-ephemeral-containers","title":"kubectl debug (Ephemeral Containers)","text":"<p>Purpose: Debug running pods with ephemeral debugging containers</p> <pre><code># Debug pod with new container\nkubectl debug pod-name -it --image=busybox:1.28\n\n# Debug node\nkubectl debug node/worker-1 -it --image=ubuntu\n\n# Copy pod and debug\nkubectl debug pod-name --copy-to=pod-name-debug --container=debugger --image=busybox\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#imperative-vs-declarative-exam-strategy","title":"Imperative vs Declarative: Exam Strategy","text":"<p>The CKA exam requires balancing speed with maintainability. Understanding when to use each approach is critical.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#imperative-commands-recommended-for-cka","title":"Imperative Commands (Recommended for CKA)","text":"<p>Definition: Direct CLI commands that immediately execute operations</p> <p>Advantages: - Fast execution (30-60 seconds vs 2-3 minutes) - No file management overhead - Perfect for exam time constraints - Easy to remember patterns</p> <p>Disadvantages: - Not reproducible - No version control - Limited complexity handling</p> <p>Exam Use Cases: <pre><code># Simple pod creation\nkubectl run nginx --image=nginx\n\n# Quick deployment\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Expose service\nkubectl expose deployment webapp --port=80 --type=NodePort\n\n# Scale resources\nkubectl scale deployment webapp --replicas=5\n\n# Update image\nkubectl set image deployment/webapp nginx=nginx:1.21\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#declarative-configuration-limited-exam-use","title":"Declarative Configuration (Limited Exam Use)","text":"<p>Definition: YAML manifests describing desired state, applied with <code>kubectl apply</code></p> <p>Advantages: - Reproducible deployments - Version controllable - Handles complex configurations - Production best practice</p> <p>Disadvantages: - Slower for simple tasks - File management overhead - Verbose for basic operations</p> <p>Exam Use Cases: <pre><code># Complex multi-container pods\nkubectl apply -f complex-pod.yaml\n\n# Resources with specific configurations\nkubectl apply -f deployment-with-resources.yaml\n\n# Multiple related resources\nkubectl apply -f ./manifests/\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#hybrid-approach-optimal-for-cka","title":"Hybrid Approach (Optimal for CKA)","text":"<p>Strategy: Use imperative commands to generate YAML templates, edit as needed, then apply.</p> <pre><code># 1. Generate base YAML\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n\n# 2. Edit for specific requirements\nvim pod.yaml\n# Add: resource limits, volumes, labels, etc.\n\n# 3. Apply declaratively\nkubectl apply -f pod.yaml\n\n# 4. Verify\nkubectl get pods\nkubectl describe pod nginx\n</code></pre> <p>Time Comparison:</p> Task Purely Imperative Hybrid Approach Pure Declarative Simple pod 10 seconds 30 seconds 2 minutes Deployment with 3 replicas 15 seconds 45 seconds 3 minutes Pod with volumes + resources Impossible 90 seconds 4 minutes Multi-container pod Impossible 2 minutes 5 minutes","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#decision-tree-imperative-vs-declarative","title":"Decision Tree: Imperative vs Declarative","text":"<pre><code>flowchart TD\n    Start([New Resource Needed]) --&gt; Simple{Simple&lt;br/&gt;Configuration?}\n\n    Simple --&gt;|Yes| SingleContainer{Single&lt;br/&gt;Container?}\n    Simple --&gt;|No| Complex[Use Hybrid Approach]\n\n    SingleContainer --&gt;|Yes| Imperative[Use Pure Imperative&lt;br/&gt;kubectl run/create]\n    SingleContainer --&gt;|No| Complex\n\n    Complex --&gt; Generate[kubectl create --dry-run]\n    Generate --&gt; Edit[Edit YAML file]\n    Edit --&gt; Apply[kubectl apply -f]\n    Apply --&gt; Verify[kubectl get/describe]\n\n    Imperative --&gt; QuickVerify[Quick kubectl get]\n\n    style Imperative fill:#99ff99\n    style Complex fill:#fff4e1\n    style Generate fill:#e1f5ff</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#output-formats-extracting-information","title":"Output Formats: Extracting Information","text":"<p>kubectl supports multiple output formats for data extraction. Mastering these saves critical exam time.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#standard-output-formats","title":"Standard Output Formats","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#default-human-readable","title":"Default (Human-Readable)","text":"<pre><code>kubectl get pods\n# NAME        READY   STATUS    RESTARTS   AGE\n# nginx       1/1     Running   0          5m\n# webapp-1    2/2     Running   1          10m\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#wide-output","title":"Wide Output","text":"<pre><code>kubectl get pods -o wide\n# NAME     READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE\n# nginx    1/1     Running   0          5m    10.244.0.5   worker-1   &lt;none&gt;\n</code></pre> <p>Use Case: Get pod IPs, node placement, readiness gates in one view</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#yaml-output","title":"YAML Output","text":"<pre><code>kubectl get pod nginx -o yaml\n</code></pre> <p>Use Cases: - Create templates from existing resources - Understand full resource structure - Debug configuration issues - Generate manifests for reproduction</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#json-output","title":"JSON Output","text":"<pre><code>kubectl get pod nginx -o json\n</code></pre> <p>Use Cases: - Programmatic parsing - Integration with scripts - API response inspection</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#name-output","title":"Name Output","text":"<pre><code>kubectl get pods -o name\n# pod/nginx\n# pod/webapp-1\n# pod/webapp-2\n</code></pre> <p>Use Case: Pipe to other commands, scripting</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#advanced-output-formats","title":"Advanced Output Formats","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#custom-columns","title":"Custom Columns","text":"<p>Purpose: Define exactly which fields to display in table format</p> <p>Basic Syntax: <pre><code>kubectl get pods -o custom-columns=&lt;COLUMN_NAME&gt;:&lt;JSON_PATH&gt;\n</code></pre></p> <p>Examples: <pre><code># Pod name and image\nkubectl get pods -o custom-columns=NAME:.metadata.name,IMAGE:.spec.containers[0].image\n\n# Pod name, namespace, node\nkubectl get pods -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,NODE:.spec.nodeName\n\n# Multiple container images\nkubectl get pods -o custom-columns=NAME:.metadata.name,IMAGES:.spec.containers[*].image\n\n# Filter with JSONPath\nkubectl get pods -A -o custom-columns='POD:.metadata.name,IMAGE:.spec.containers[?(@.image!=\"registry.k8s.io/pause:3.9\")].image'\n</code></pre></p> <p>Common Patterns: <pre><code># Service types and IPs\nkubectl get svc -o custom-columns=NAME:.metadata.name,TYPE:.spec.type,CLUSTER-IP:.spec.clusterIP,EXTERNAL-IP:.status.loadBalancer.ingress[0].ip\n\n# Node resource capacity\nkubectl get nodes -o custom-columns=NAME:.metadata.name,CPU:.status.capacity.cpu,MEMORY:.status.capacity.memory\n\n# PV claim status\nkubectl get pv -o custom-columns=NAME:.metadata.name,CAPACITY:.spec.capacity.storage,STATUS:.status.phase,CLAIM:.spec.claimRef.name\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#jsonpath-queries","title":"JSONPath Queries","text":"<p>Purpose: Extract specific data using JSONPath expressions</p> <p>Basic Syntax: <pre><code>kubectl get &lt;resource&gt; -o jsonpath='{&lt;JSONPath_expression&gt;}'\n</code></pre></p> <p>Essential Patterns:</p> <pre><code># All pod names\nkubectl get pods -o jsonpath='{.items[*].metadata.name}'\n\n# First pod name\nkubectl get pods -o jsonpath='{.items[0].metadata.name}'\n\n# Pod IPs with newlines\nkubectl get pods -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}'\n\n# Node names and CPU capacity\nkubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.capacity.cpu}{\"\\n\"}{end}'\n\n# Filter by condition\nkubectl get pods -o jsonpath='{.items[?(@.metadata.labels.app==\"nginx\")].metadata.name}'\n\n# All container images (unique)\nkubectl get pods -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\\n' | sort -u\n\n# Service cluster IPs\nkubectl get svc -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.clusterIP}{\"\\n\"}{end}'\n</code></pre> <p>Complex Examples: <pre><code># Pods with high restart counts\nkubectl get pods -o jsonpath='{range .items[?(@.status.containerStatuses[0].restartCount&gt;5)]}{.metadata.name}{\"\\t\"}{.status.containerStatuses[0].restartCount}{\"\\n\"}{end}'\n\n# Users from kubeconfig\nkubectl config view -o jsonpath='{.users[*].name}'\n\n# Context cluster mapping\nkubectl config view -o jsonpath='{range .contexts[*]}{.name}{\"\\t\"}{.context.cluster}{\"\\n\"}{end}'\n</code></pre></p> <p>JSONPath Tips: - Use <code>{range}...{end}</code> for iteration - Use <code>{\\n}</code> for newlines, <code>{\\t}</code> for tabs - Filter with <code>[?(@.field==\"value\")]</code> - Access array elements with <code>[index]</code> or <code>[*]</code> for all - No regex support in JSONPath</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#output-format-comparison","title":"Output Format Comparison","text":"<pre><code>graph LR\n    Task[Information Need] --&gt; Decision{Data Type?}\n\n    Decision --&gt;|Quick Overview| Wide[Use -o wide]\n    Decision --&gt;|Specific Fields| Choice{How Many Fields?}\n    Decision --&gt;|Full Resource| Format{Human or Machine?}\n    Decision --&gt;|Resource Names| Name[Use -o name]\n\n    Choice --&gt;|1-2 fields| JSONPath[Use -o jsonpath]\n    Choice --&gt;|3+ fields| CustomCol[Use -o custom-columns]\n\n    Format --&gt;|Human| YAML[Use -o yaml]\n    Format --&gt;|Machine| JSON[Use -o json]\n\n    style Wide fill:#99ff99\n    style JSONPath fill:#e1f5ff\n    style CustomCol fill:#fff4e1\n    style YAML fill:#ffe5e5</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#context-and-namespace-management","title":"Context and Namespace Management","text":"<p>Managing multiple clusters and namespaces efficiently is a core CKA exam skill.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#understanding-contexts","title":"Understanding Contexts","text":"<p>Context Definition: A context groups cluster + user + namespace into a named configuration.</p> <p>Context Components: - Cluster: API server endpoint and CA certificate - User: Authentication credentials (client cert, token, etc.) - Namespace: Default namespace for commands (optional)</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#context-management-commands","title":"Context Management Commands","text":"<pre><code># List all contexts\nkubectl config get-contexts\n# CURRENT   NAME           CLUSTER        AUTHINFO       NAMESPACE\n# *         prod-context   prod-cluster   prod-admin     production\n#           dev-context    dev-cluster    dev-user       development\n\n# Show current context\nkubectl config current-context\n# prod-context\n\n# Switch context\nkubectl config use-context dev-context\n\n# Create new context\nkubectl config set-context staging \\\n  --cluster=prod-cluster \\\n  --user=staging-user \\\n  --namespace=staging\n\n# Modify existing context\nkubectl config set-context dev-context --namespace=testing\n\n# Set namespace for current context\nkubectl config set-context --current --namespace=kube-system\n\n# Delete context\nkubectl config delete-context old-context\n\n# Rename context\nkubectl config rename-context old-name new-name\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#namespace-operations","title":"Namespace Operations","text":"<pre><code># List namespaces\nkubectl get namespaces\nkubectl get ns  # Short form\n\n# Create namespace\nkubectl create namespace development\nkubectl create ns production\n\n# Describe namespace\nkubectl describe namespace development\n\n# Delete namespace (deletes all resources!)\nkubectl delete namespace development\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#multi-cluster-workflow","title":"Multi-Cluster Workflow","text":"<pre><code>sequenceDiagram\n    participant Exam as Exam Question\n    participant User\n    participant kubectl\n    participant Cluster1 as Cluster 1\n    participant Cluster2 as Cluster 2\n\n    Exam-&gt;&gt;User: \"Deploy to cluster 'k8s-prod', namespace 'production'\"\n\n    User-&gt;&gt;kubectl: kubectl config get-contexts\n    kubectl--&gt;&gt;User: List available contexts\n\n    User-&gt;&gt;kubectl: kubectl config use-context k8s-prod\n    kubectl--&gt;&gt;Cluster1: Switch connection\n\n    User-&gt;&gt;kubectl: kubectl config set-context --current --namespace=production\n    kubectl--&gt;&gt;kubectl: Set default namespace\n\n    User-&gt;&gt;kubectl: kubectl run app --image=nginx\n    kubectl-&gt;&gt;Cluster1: Create pod in production namespace\n\n    Note over Exam,User: Next question uses different cluster\n\n    Exam-&gt;&gt;User: \"Check pods in cluster 'k8s-dev', namespace 'default'\"\n\n    User-&gt;&gt;kubectl: kubectl config use-context k8s-dev\n    kubectl--&gt;&gt;Cluster2: Switch connection\n\n    User-&gt;&gt;kubectl: kubectl get pods\n    kubectl-&gt;&gt;Cluster2: Query default namespace\n    Cluster2--&gt;&gt;User: Pod list</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#namespace-best-practices","title":"Namespace Best Practices","text":"<p>Always Specify Namespace Explicitly (Exam Safety): <pre><code># Risky (uses context default)\nkubectl get pods\n\n# Safe (explicit namespace)\nkubectl get pods -n production\nkubectl get pods --namespace=production\n\n# All namespaces\nkubectl get pods -A\nkubectl get pods --all-namespaces\n</code></pre></p> <p>Context Switching Aliases (Pre-configured in Exam): <pre><code># Context switcher\nalias kx='f() { [ \"$1\" ] &amp;&amp; kubectl config use-context $1 || kubectl config current-context ; } ; f'\n\n# Usage:\nkx                  # Show current context\nkx prod-context     # Switch to prod-context\n\n# Namespace switcher\nalias kn='f() { [ \"$1\" ] &amp;&amp; kubectl config set-context --current --namespace $1 || kubectl config view --minify | grep namespace | cut -d\" \" -f6 ; } ; f'\n\n# Usage:\nkn                  # Show current namespace\nkn production       # Switch to production namespace\n</code></pre></p> <p>Exam Verification Checklist: <pre><code># Before EVERY task, verify:\nkubectl config current-context          # Am I in the right cluster?\nkubectl config view --minify | grep namespace  # What's my default namespace?\n\n# Or use the exam-provided aliases:\nkx  # Show context\nkn  # Show namespace\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-explain-in-exam-documentation","title":"kubectl explain: In-Exam Documentation","text":"<p>kubectl explain provides API documentation directly in your terminal. This tool is available during the exam and is faster than searching web docs.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#basic-usage","title":"Basic Usage","text":"<pre><code># Top-level resource\nkubectl explain pod\nkubectl explain deployment\nkubectl explain service\n\n# Nested field\nkubectl explain pod.spec\nkubectl explain deployment.spec.template\nkubectl explain service.spec\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exploring-resource-structure","title":"Exploring Resource Structure","text":"<pre><code># View pod spec fields\nkubectl explain pod.spec\n# FIELDS:\n#   containers    &lt;[]Container&gt; -required-\n#   volumes       &lt;[]Volume&gt;\n#   restartPolicy &lt;string&gt;\n#   nodeName      &lt;string&gt;\n\n# Drill into containers\nkubectl explain pod.spec.containers\n# FIELDS:\n#   name          &lt;string&gt; -required-\n#   image         &lt;string&gt; -required-\n#   command       &lt;[]string&gt;\n#   args          &lt;[]string&gt;\n#   env           &lt;[]EnvVar&gt;\n#   ports         &lt;[]ContainerPort&gt;\n#   volumeMounts  &lt;[]VolumeMount&gt;\n\n# Check container ports structure\nkubectl explain pod.spec.containers.ports\n# FIELDS:\n#   containerPort &lt;integer&gt; -required-\n#   hostPort      &lt;integer&gt;\n#   name          &lt;string&gt;\n#   protocol      &lt;string&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-exam-use-cases","title":"Common Exam Use Cases","text":"<p>Scenario 1: What fields are available for liveness probes? <pre><code>kubectl explain pod.spec.containers.livenessProbe\n# Shows: exec, httpGet, tcpSocket, initialDelaySeconds, periodSeconds, etc.\n\nkubectl explain pod.spec.containers.livenessProbe.httpGet\n# Shows: path, port, host, scheme, httpHeaders\n</code></pre></p> <p>Scenario 2: How to configure deployment strategy? <pre><code>kubectl explain deployment.spec.strategy\n# Shows: type (RollingUpdate, Recreate), rollingUpdate\n\nkubectl explain deployment.spec.strategy.rollingUpdate\n# Shows: maxSurge, maxUnavailable\n</code></pre></p> <p>Scenario 3: What volume types are available? <pre><code>kubectl explain pod.spec.volumes\n# Shows MANY types: configMap, secret, emptyDir, persistentVolumeClaim, hostPath, nfs, etc.\n\nkubectl explain pod.spec.volumes.persistentVolumeClaim\n# Shows: claimName, readOnly\n</code></pre></p> <p>Scenario 4: Resource limits and requests? <pre><code>kubectl explain pod.spec.containers.resources\n# Shows: limits, requests\n\nkubectl explain pod.spec.containers.resources.limits\n# Shows: can specify cpu, memory, ephemeral-storage\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#field-type-notation","title":"Field Type Notation","text":"<p>Understanding Output: - <code>&lt;string&gt;</code> - String field - <code>&lt;integer&gt;</code> - Integer field - <code>&lt;boolean&gt;</code> - Boolean (true/false) - <code>&lt;[]Type&gt;</code> - Array of Type - <code>&lt;Object&gt;</code> - Nested object - <code>&lt;map[string]string&gt;</code> - Key-value map - <code>-required-</code> - Required field marker</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#integration-with-workflow","title":"Integration with Workflow","text":"<p>Exam Pattern: <pre><code># 1. Generate base template\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n\n# 2. Check available fields\nkubectl explain pod.spec.containers.resources\n\n# 3. Edit with correct field names\nvim pod.yaml\n# Add resources based on explain output\n\n# 4. Verify and apply\nkubectl apply -f pod.yaml\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#productivity-patterns","title":"Productivity Patterns","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#time-saving-aliases-pre-configured-in-exam","title":"Time-Saving Aliases (Pre-configured in Exam)","text":"<p>Core Alias (Already Active): <pre><code>alias k=kubectl\ncomplete -o default -F __start_kubectl k\n</code></pre></p> <p>Recommended Personal Additions: <pre><code># Dry-run YAML generation\nexport dry='--dry-run=client -o yaml'\nexport now='--force --grace-period=0'\n\n# Usage examples:\nk run nginx --image=nginx $dry &gt; pod.yaml\nk create deploy webapp --image=nginx $dry &gt; deploy.yaml\nk delete pod nginx $now  # Immediate deletion\n</code></pre></p> <p>Resource Shortcuts: <pre><code>alias kgp='kubectl get pods'\nalias kgd='kubectl get deployments'\nalias kgs='kubectl get services'\nalias kga='kubectl get all'\nalias kgpa='kubectl get pods -A'\n\nalias kdesc='kubectl describe'\nalias kl='kubectl logs'\nalias klf='kubectl logs -f'\nalias kex='kubectl exec -it'\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#autocomplete-usage-pre-configured","title":"Autocomplete Usage (Pre-configured)","text":"<p>Tab Completion Examples: <pre><code># Resource type completion\nk get po&lt;TAB&gt;            # Completes to: k get pods\nk get dep&lt;TAB&gt;           # Completes to: k get deployments\n\n# Resource name completion\nk get pods ng&lt;TAB&gt;       # Completes to existing pod name\nk describe node wor&lt;TAB&gt; # Completes to node name\n\n# Namespace completion\nk get pods -n kube-&lt;TAB&gt; # Completes to: k get pods -n kube-system\n\n# Flag completion\nk get pods --out&lt;TAB&gt;    # Completes to: k get pods --output\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-command-patterns","title":"Common Command Patterns","text":"<p>Deployment Lifecycle: <pre><code># Create\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Expose\nkubectl expose deployment webapp --port=80 --type=NodePort\n\n# Update\nkubectl set image deployment/webapp nginx=nginx:1.21\n\n# Scale\nkubectl scale deployment webapp --replicas=5\n\n# Check status\nkubectl rollout status deployment/webapp\n\n# Rollback if needed\nkubectl rollout undo deployment/webapp\n</code></pre></p> <p>Debugging Workflow: <pre><code># 1. Identify issue\nkubectl get pods                # Find problematic pod\n\n# 2. Get details\nkubectl describe pod pod-name   # Check Events section\n\n# 3. Check logs\nkubectl logs pod-name           # Current logs\nkubectl logs pod-name --previous # After crash\n\n# 4. Interactive debug\nkubectl exec -it pod-name -- /bin/sh\n\n# 5. Network test\nkubectl exec -it pod-name -- ping service-name\nkubectl exec -it pod-name -- curl http://service:8080\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#cka-exam-strategies","title":"CKA Exam Strategies","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#essential-commands-use-daily","title":"Essential Commands (Use Daily)","text":"<p>Top 10 Most-Used in Exam: 1. <code>kubectl run</code> - Create pods quickly 2. <code>kubectl create</code> - Generate resources 3. <code>kubectl get</code> - List and inspect 4. <code>kubectl describe</code> - Debug issues 5. <code>kubectl logs</code> - View application logs 6. <code>kubectl apply</code> - Deploy configurations 7. <code>kubectl delete</code> - Remove resources 8. <code>kubectl exec</code> - Container debugging 9. <code>kubectl edit</code> - Quick modifications 10. <code>kubectl explain</code> - Field reference</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#time-management","title":"Time Management","text":"<p>Command Time Budget: - Simple pod creation: 10-30 seconds - Deployment with service: 45-90 seconds - Complex multi-container pod: 2-3 minutes - Debugging scenario: 3-5 minutes</p> <p>Speed Optimization: <pre><code># SLOW (2-3 minutes)\nvim pod.yaml  # Write from scratch\nkubectl apply -f pod.yaml\n\n# FAST (30 seconds)\nkubectl run nginx --image=nginx $dry &gt; pod.yaml\nvim pod.yaml  # Edit generated template\nkubectl apply -f pod.yaml\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-exam-scenarios","title":"Common Exam Scenarios","text":"<p>Scenario 1: Create and Expose <pre><code># Create deployment\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Expose service\nkubectl expose deployment webapp --port=80 --type=NodePort\n\n# Verify\nkubectl get deploy,svc,pods\n</code></pre></p> <p>Scenario 2: Fix Failing Pod <pre><code># Identify\nkubectl get pods\nkubectl describe pod failing-pod\nkubectl logs failing-pod\n\n# Fix approach\nkubectl get pod failing-pod -o yaml &gt; fix.yaml\nvim fix.yaml  # Fix the issue\nkubectl delete pod failing-pod\nkubectl apply -f fix.yaml\n</code></pre></p> <p>Scenario 3: Scale and Update <pre><code># Scale\nkubectl scale deployment webapp --replicas=5\n\n# Update image\nkubectl set image deployment/webapp nginx=nginx:1.21\n\n# Monitor rollout\nkubectl rollout status deployment/webapp\n\n# Rollback if needed\nkubectl rollout undo deployment/webapp\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#practice-exercises","title":"Practice Exercises","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-1-command-mastery-15-minutes","title":"Exercise 1: Command Mastery (15 minutes)","text":"<p>Objective: Build muscle memory for essential commands</p> <p>Tasks: 1. Create pod 'web' with nginx:1.21 image and port 80 2. Create deployment 'api' with 3 replicas using httpd image 3. Expose 'api' deployment as NodePort on port 8080 4. Get all pod IPs using JSONPath 5. List pod names only 6. Scale 'api' to 5 replicas 7. Update 'api' image to httpd:2.4.57 8. View rollout history 9. Delete all resources</p> <p>Solution: <pre><code># 1\nkubectl run web --image=nginx:1.21 --port=80\n\n# 2\nkubectl create deployment api --image=httpd --replicas=3\n\n# 3\nkubectl expose deployment api --port=8080 --type=NodePort\n\n# 4\nkubectl get pods -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}'\n\n# 5\nkubectl get pods -o name\n\n# 6\nkubectl scale deployment api --replicas=5\n\n# 7\nkubectl set image deployment/api httpd=httpd:2.4.57\n\n# 8\nkubectl rollout history deployment/api\n\n# 9\nkubectl delete deployment api\nkubectl delete pod web\nkubectl delete service api\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-2-output-formats-20-minutes","title":"Exercise 2: Output Formats (20 minutes)","text":"<p>Objective: Master data extraction with output formats</p> <p>Tasks: 1. List all pod names in kube-system namespace 2. Get pod names and node placement with custom columns 3. Extract all container images in cluster 4. Get services with type and cluster IP 5. Find pods with label app=nginx</p> <p>Solution: <pre><code># 1\nkubectl get pods -n kube-system -o name\n\n# 2\nkubectl get pods -A -o custom-columns=POD:.metadata.name,NODE:.spec.nodeName\n\n# 3\nkubectl get pods -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\\n' | sort -u\n\n# 4\nkubectl get svc -o custom-columns=NAME:.metadata.name,TYPE:.spec.type,CLUSTER-IP:.spec.clusterIP\n\n# 5\nkubectl get pods -l app=nginx\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-3-context-management-15-minutes","title":"Exercise 3: Context Management (15 minutes)","text":"<p>Objective: Practice multi-cluster context switching</p> <p>Tasks: 1. List all contexts 2. Show current context 3. Create context 'dev-ctx' for development namespace 4. Switch to 'dev-ctx' 5. Set default namespace to 'kube-system' for current context 6. Verify namespace setting</p> <p>Solution: <pre><code># 1\nkubectl config get-contexts\n\n# 2\nkubectl config current-context\n\n# 3\nkubectl config set-context dev-ctx --namespace=development\n\n# 4\nkubectl config use-context dev-ctx\n\n# 5\nkubectl config set-context --current --namespace=kube-system\n\n# 6\nkubectl config view --minify | grep namespace\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-4-imperative-vs-declarative-25-minutes","title":"Exercise 4: Imperative vs Declarative (25 minutes)","text":"<p>Objective: Practice hybrid workflow</p> <p>Tasks: 1. Generate pod YAML for nginx with resource limits (don't create) 2. Add resource requests: cpu=100m, memory=128Mi 3. Add resource limits: cpu=200m, memory=256Mi 4. Add liveness probe: HTTP GET on port 80, path / 5. Apply and verify 6. Generate deployment YAML with 3 replicas 7. Modify to add nodeSelector: disk=ssd 8. Apply and verify pods scheduled on correct nodes</p> <p>Solution: <pre><code># 1\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n\n# 2-4 (edit pod.yaml)\nvim pod.yaml\n# Add under containers:\n#   resources:\n#     requests:\n#       cpu: 100m\n#       memory: 128Mi\n#     limits:\n#       cpu: 200m\n#       memory: 256Mi\n#   livenessProbe:\n#     httpGet:\n#       path: /\n#       port: 80\n\n# 5\nkubectl apply -f pod.yaml\nkubectl describe pod nginx\n\n# 6\nkubectl create deployment webapp --image=nginx --replicas=3 --dry-run=client -o yaml &gt; deploy.yaml\n\n# 7\nvim deploy.yaml\n# Add under spec.template.spec:\n#   nodeSelector:\n#     disk: ssd\n\n# 8\nkubectl apply -f deploy.yaml\nkubectl get pods -o wide\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-5-debugging-simulation-30-minutes","title":"Exercise 5: Debugging Simulation (30 minutes)","text":"<p>Objective: Practice troubleshooting workflow</p> <p>Tasks: 1. Create pod with wrong image name 2. Identify why pod is failing 3. Get YAML and fix 4. Create deployment, then break it by scaling to 100 replicas 5. Observe pending pods 6. Identify resource constraints 7. Fix by scaling down</p> <p>Solution: <pre><code># 1\nkubectl run broken --image=nginxxx  # Wrong image\n\n# 2\nkubectl get pods\nkubectl describe pod broken  # Check Events: ImagePullBackOff\n\n# 3\nkubectl get pod broken -o yaml &gt; fixed.yaml\nvim fixed.yaml  # Change image to nginx\nkubectl delete pod broken\nkubectl apply -f fixed.yaml\n\n# 4\nkubectl create deployment overload --image=nginx\nkubectl scale deployment overload --replicas=100\n\n# 5\nkubectl get pods | grep Pending\n\n# 6\nkubectl describe pod &lt;pending-pod-name&gt;\n# Events show: Insufficient cpu/memory\n\n# 7\nkubectl scale deployment overload --replicas=3\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#quick-reference","title":"Quick Reference","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#command-syntax-patterns","title":"Command Syntax Patterns","text":"<pre><code># Resource Management\nkubectl &lt;verb&gt; &lt;resource&gt; &lt;name&gt; [options]\nkubectl get pods nginx -o yaml\nkubectl describe deployment webapp\n\n# Imperative Creation\nkubectl run &lt;name&gt; --image=&lt;image&gt; [options]\nkubectl create &lt;resource&gt; &lt;name&gt; [options]\nkubectl expose &lt;resource&gt; &lt;name&gt; [options]\n\n# Declarative Operations\nkubectl apply -f &lt;file&gt;\nkubectl delete -f &lt;file&gt;\n\n# Resource Modification\nkubectl edit &lt;resource&gt; &lt;name&gt;\nkubectl patch &lt;resource&gt; &lt;name&gt; -p '&lt;patch&gt;'\nkubectl scale &lt;resource&gt; &lt;name&gt; --replicas=&lt;n&gt;\nkubectl set image &lt;resource&gt;/&lt;name&gt; &lt;container&gt;=&lt;image&gt;\n\n# Debugging\nkubectl logs &lt;pod&gt; [-c &lt;container&gt;] [options]\nkubectl exec &lt;pod&gt; [-c &lt;container&gt;] -- &lt;command&gt;\nkubectl port-forward &lt;resource&gt; &lt;local&gt;:&lt;remote&gt;\n\n# Context &amp; Config\nkubectl config &lt;subcommand&gt;\nkubectl config use-context &lt;context&gt;\nkubectl config set-context --current --namespace=&lt;ns&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#output-format-quick-reference","title":"Output Format Quick Reference","text":"<pre><code># Standard formats\n-o wide               # Additional columns\n-o yaml               # Full YAML\n-o json               # Full JSON\n-o name               # Resource names only\n\n# Advanced formats\n-o custom-columns=&lt;spec&gt;\n-o jsonpath='{&lt;path&gt;}'\n-o jsonpath-file=&lt;file&gt;\n\n# Examples\nkubectl get pods -o wide\nkubectl get pods -o jsonpath='{.items[*].metadata.name}'\nkubectl get pods -o custom-columns=NAME:.metadata.name,IP:.status.podIP\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-flags","title":"Common Flags","text":"<pre><code>-n, --namespace         # Specify namespace\n-A, --all-namespaces    # All namespaces\n-l, --selector          # Label selector\n-f, --filename          # File path\n--dry-run=client        # Don't create, just print\n-o, --output            # Output format\n-w, --watch             # Watch for changes\n--sort-by               # Sort output\n--field-selector        # Field selector\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Imperative commands save exam minutes - Use <code>kubectl run</code>, <code>create</code>, <code>expose</code> for speed</p> <p>\u2705 --dry-run=client -o yaml is critical - Generate templates, never write YAML from scratch</p> <p>\u2705 kubectl explain is your friend - Faster than searching docs during exam</p> <p>\u2705 Output formats extract data precisely - Master JSONPath and custom-columns</p> <p>\u2705 Context awareness prevents mistakes - Always verify cluster and namespace</p> <p>\u2705 Autocomplete is pre-configured - Use tab completion aggressively</p> <p>\u2705 Aliases save time only if practiced - Use <code>k</code>, <code>$dry</code>, <code>$now</code> extensively before exam</p> <p>\u2705 Hybrid approach balances speed and complexity - Imperative generation + declarative application</p> <p>\u2705 Verification is non-negotiable - Always check resources created correctly</p> <p>\u2705 Practice makes permanent - Build muscle memory through repetition</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#next-steps","title":"Next Steps","text":"<p>After mastering kubectl, continue with:</p> <p>Post 4: Pod Lifecycle and Management - Deep dive into the fundamental Kubernetes workload unit</p> <p>Related Posts: - Kubernetes Architecture Fundamentals - Understanding cluster components - Setting Up Your Kubernetes Lab - Build your practice environment - Kubernetes CKA Mastery - Complete Learning Path - Full exam preparation series</p> <p>External Resources: - kubectl Official Documentation - kubectl Cheat Sheet - kubectl Commands Reference - JSONPath Support in kubectl - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/","title":"Kubernetes Architecture Fundamentals","text":"<p>Deep dive into Kubernetes cluster architecture, control plane components, and the distributed systems design that powers container orchestration at scale.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#overview","title":"Overview","text":"<p>Kubernetes is a distributed system designed to manage containerized applications across a cluster of machines. Understanding its architecture is foundational for the CKA exam and real-world cluster administration.</p> <p>CKA Exam Domain: Cluster Architecture, Installation &amp; Configuration (25%)</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#cluster-architecture","title":"Cluster Architecture","text":"<p>A Kubernetes cluster consists of two types of nodes:</p> <ol> <li>Control Plane Nodes: Run the core components that manage the cluster</li> <li>Worker Nodes: Run application workloads (pods)</li> </ol> <pre><code>graph TB\n    subgraph \"Control Plane Nodes\"\n        API[API Server&lt;br/&gt;:6443]\n        SCHED[Scheduler]\n        CM[Controller&lt;br/&gt;Manager]\n        CCM[Cloud Controller&lt;br/&gt;Manager]\n        ETCD[(etcd&lt;br/&gt;:2379-2380)]\n    end\n\n    subgraph \"Worker Node 1\"\n        KUB1[kubelet]\n        KPXY1[kube-proxy]\n        POD1[Pods]\n        CRI1[Container&lt;br/&gt;Runtime]\n    end\n\n    subgraph \"Worker Node 2\"\n        KUB2[kubelet]\n        KPXY2[kube-proxy]\n        POD2[Pods]\n        CRI2[Container&lt;br/&gt;Runtime]\n    end\n\n    subgraph \"Worker Node 3\"\n        KUB3[kubelet]\n        KPXY3[kube-proxy]\n        POD3[Pods]\n        CRI3[Container&lt;br/&gt;Runtime]\n    end\n\n    API --&gt;|watches| ETCD\n    API --&gt; SCHED\n    API --&gt; CM\n    API --&gt; CCM\n\n    KUB1 --&gt;|API calls| API\n    KUB2 --&gt;|API calls| API\n    KUB3 --&gt;|API calls| API\n\n    KUB1 --&gt; CRI1 --&gt; POD1\n    KUB2 --&gt; CRI2 --&gt; POD2\n    KUB3 --&gt; CRI3 --&gt; POD3\n\n    KPXY1 -.-&gt;|iptables/IPVS| POD1\n    KPXY2 -.-&gt;|iptables/IPVS| POD2\n    KPXY3 -.-&gt;|iptables/IPVS| POD3\n\n    style API fill:#e1f5ff\n    style ETCD fill:#ffe5e5\n    style SCHED fill:#fff4e1\n    style CM fill:#e8f5e8</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#control-plane-components","title":"Control Plane Components","text":"<p>The control plane makes global decisions about the cluster and detects/responds to cluster events.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#1-api-server-kube-apiserver","title":"1. API Server (kube-apiserver)","text":"<p>Purpose: Front-end for the Kubernetes control plane. All communication goes through the API server.</p> <p>Key Responsibilities: - Exposes the Kubernetes API (REST interface) - Validates and configures API objects (pods, services, replication controllers) - Serves as the only component that directly interacts with etcd - Handles authentication, authorization, and admission control</p> <p>Default Port: <code>6443</code> (HTTPS)</p> <pre><code># Check API server status\nkubectl get --raw='/healthz?verbose'\n\n# View API server configuration\nkubectl -n kube-system get pod kube-apiserver-&lt;node-name&gt; -o yaml\n\n# Check API server logs\nkubectl -n kube-system logs kube-apiserver-&lt;node-name&gt;\n</code></pre> <p>API Request Flow:</p> <pre><code>sequenceDiagram\n    participant U as User/kubectl\n    participant API as API Server\n    participant AUTH as Authentication\n    participant AUTHZ as Authorization\n    participant ADM as Admission&lt;br/&gt;Controllers\n    participant ETCD as etcd\n\n    U-&gt;&gt;+API: HTTP Request&lt;br/&gt;(create Pod)\n\n    API-&gt;&gt;+AUTH: Authenticate\n    Note right of AUTH: Verify user identity&lt;br/&gt;(certs, tokens, SA)\n    AUTH--&gt;&gt;-API: User ID\n\n    API-&gt;&gt;+AUTHZ: Authorize\n    Note right of AUTHZ: Check RBAC rules&lt;br/&gt;(can user create pod?)\n    AUTHZ--&gt;&gt;-API: Authorized\n\n    API-&gt;&gt;+ADM: Admission Control\n    Note right of ADM: Validate &amp; Mutate&lt;br/&gt;(defaults, quotas, PSP)\n    ADM--&gt;&gt;-API: Admitted\n\n    API-&gt;&gt;+ETCD: Write to etcd\n    ETCD--&gt;&gt;-API: Persisted\n\n    API--&gt;&gt;-U: 201 Created\n\n    Note over API,ETCD: Object now exists in desired state</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#2-etcd","title":"2. etcd","text":"<p>Purpose: Consistent, highly-available key-value store used as Kubernetes' backing store for all cluster data.</p> <p>Key Characteristics: - Distributed consensus using Raft algorithm - Stores all cluster state and configuration - Only the API server writes to etcd - Supports watch operations for real-time updates</p> <p>Default Ports: - <code>2379</code> - Client requests - <code>2380</code> - Server-to-server communication</p> <pre><code># Check etcd cluster health\nETCDCTL_API=3 etcdctl \\\n  --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\n  endpoint health\n\n# List etcd members\nETCDCTL_API=3 etcdctl member list\n\n# Get all keys (see what's stored)\nETCDCTL_API=3 etcdctl get / --prefix --keys-only\n\n# Backup etcd\nETCDCTL_API=3 etcdctl snapshot save snapshot.db\n</code></pre> <p>High Availability: For production clusters, run etcd with at least 3 nodes (odd number for quorum).</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#3-scheduler-kube-scheduler","title":"3. Scheduler (kube-scheduler)","text":"<p>Purpose: Watches for newly created pods with no assigned node and selects a node for them to run on.</p> <p>Scheduling Algorithm: 1. Filtering: Find nodes that satisfy pod requirements (feasible nodes)    - Resource requests (CPU, memory)    - Node selectors    - Taints and tolerations    - Affinity/anti-affinity rules</p> <ol> <li>Scoring: Rank feasible nodes</li> <li>Spread pods across nodes for availability</li> <li>Prefer nodes with available resources</li> <li> <p>Consider pod priorities</p> </li> <li> <p>Binding: Assign pod to highest-scoring node</p> </li> </ol> <pre><code>graph TD\n    START([New Pod Created]) --&gt; FILTER[Filtering Phase]\n\n    FILTER --&gt; CHECK1{Resource&lt;br/&gt;Requirements?}\n    CHECK1 --&gt;|Fail| UNSCHEDULABLE[Pod Unschedulable]\n    CHECK1 --&gt;|Pass| CHECK2{Node&lt;br/&gt;Selectors?}\n\n    CHECK2 --&gt;|Fail| UNSCHEDULABLE\n    CHECK2 --&gt;|Pass| CHECK3{Taints/&lt;br/&gt;Tolerations?}\n\n    CHECK3 --&gt;|Fail| UNSCHEDULABLE\n    CHECK3 --&gt;|Pass| CHECK4{Affinity&lt;br/&gt;Rules?}\n\n    CHECK4 --&gt;|Fail| UNSCHEDULABLE\n    CHECK4 --&gt;|Pass| FEASIBLE[Feasible Nodes]\n\n    FEASIBLE --&gt; SCORE[Scoring Phase]\n    SCORE --&gt; RANK[Rank Nodes&lt;br/&gt;by Score]\n    RANK --&gt; BIND[Bind Pod to&lt;br/&gt;Top Node]\n    BIND --&gt; SUCCESS([Pod Scheduled])\n\n    style START fill:#e1f5ff\n    style SUCCESS fill:#e8f5e8\n    style UNSCHEDULABLE fill:#ffe5e5</code></pre> <pre><code># View scheduler configuration\nkubectl -n kube-system get pod kube-scheduler-&lt;node-name&gt; -o yaml\n\n# Check scheduler logs\nkubectl -n kube-system logs kube-scheduler-&lt;node-name&gt;\n\n# View events (scheduling decisions)\nkubectl get events --sort-by='.lastTimestamp'\n\n# See why a pod is not scheduled\nkubectl describe pod &lt;pod-name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#4-controller-manager-kube-controller-manager","title":"4. Controller Manager (kube-controller-manager)","text":"<p>Purpose: Runs controller processes that regulate the state of the cluster.</p> <p>Key Controllers: - Node Controller: Monitors node health, marks nodes as unreachable - Replication Controller: Maintains correct number of pod replicas - Endpoints Controller: Populates Endpoints objects (joins Services &amp; Pods) - Service Account &amp; Token Controllers: Create default accounts and API access tokens</p> <p>Control Loop Pattern:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; Watch: Controller starts\n    Watch --&gt; Compare: Detect change\n    Compare --&gt; DesiredState: Check desired state\n    DesiredState --&gt; CurrentState: Check current state\n    CurrentState --&gt; Match: States match?\n\n    Match --&gt; Watch: Yes, no action\n    Match --&gt; Reconcile: No, take action\n\n    Reconcile --&gt; CreateResources: Create missing resources\n    Reconcile --&gt; UpdateResources: Update existing resources\n    Reconcile --&gt; DeleteResources: Delete extra resources\n\n    CreateResources --&gt; Watch\n    UpdateResources --&gt; Watch\n    DeleteResources --&gt; Watch</code></pre> <pre><code># View controller manager logs\nkubectl -n kube-system logs kube-controller-manager-&lt;node-name&gt;\n\n# Check which controllers are enabled\nkubectl -n kube-system get pod kube-controller-manager-&lt;node-name&gt; -o yaml | grep enable\n\n# Watch controller actions in events\nkubectl get events --watch\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#5-cloud-controller-manager-cloud-controller-manager","title":"5. Cloud Controller Manager (cloud-controller-manager)","text":"<p>Purpose: Embeds cloud-specific control logic. Allows cloud providers to integrate with Kubernetes.</p> <p>Key Controllers: - Node Controller: Check cloud provider to determine if a deleted node has been removed - Route Controller: Set up routes in the cloud infrastructure - Service Controller: Create, update, delete cloud load balancers</p> <p>Note: Only relevant when running Kubernetes on cloud platforms (AWS, GCP, Azure).</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#worker-node-components","title":"Worker Node Components","text":"<p>Worker nodes run application workloads and maintain running pods.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#1-kubelet","title":"1. kubelet","text":"<p>Purpose: Agent that runs on each node, ensures containers are running in pods.</p> <p>Key Responsibilities: - Registers node with API server - Watches for pod assignments to its node - Ensures containers described in PodSpec are running and healthy - Reports node and pod status back to API server - Performs container health checks (liveness, readiness probes)</p> <p>Default Port: <code>10250</code></p> <pre><code># Check kubelet status (on node directly)\nsystemctl status kubelet\n\n# View kubelet configuration\ncat /var/lib/kubelet/config.yaml\n\n# Check kubelet logs\njournalctl -u kubelet -f\n\n# View node status from control plane\nkubectl get nodes\nkubectl describe node &lt;node-name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#2-kube-proxy","title":"2. kube-proxy","text":"<p>Purpose: Network proxy that maintains network rules on nodes, enabling communication to pods.</p> <p>Key Responsibilities: - Implements Service abstraction - Maintains iptables/IPVS rules for service IPs - Forwards traffic to correct backend pods - Performs load balancing across pod replicas</p> <p>Modes: - iptables (default): Uses Linux iptables for packet filtering - IPVS: Uses Linux IPVS for better performance at scale - userspace: Legacy mode (rarely used)</p> <pre><code># Check kube-proxy mode\nkubectl -n kube-system logs kube-proxy-&lt;pod-name&gt; | grep \"proxy mode\"\n\n# View kube-proxy configuration\nkubectl -n kube-system get cm kube-proxy -o yaml\n\n# Check iptables rules (on node)\niptables-save | grep -i kube\n\n# View IPVS rules (if using IPVS mode)\nipvsadm -Ln\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#3-container-runtime","title":"3. Container Runtime","text":"<p>Purpose: Software responsible for running containers.</p> <p>Supported Runtimes (via Container Runtime Interface - CRI): - containerd: Lightweight, industry-standard (default for most distributions) - CRI-O: Lightweight alternative specifically for Kubernetes - Docker Engine: Via cri-dockerd shim (removed as default in Kubernetes 1.24)</p> <pre><code># Check container runtime\nkubectl get nodes -o wide\n\n# On node: check containerd\nsystemctl status containerd\ncrictl ps\n\n# List images\ncrictl images\n\n# Pull image\ncrictl pull nginx:latest\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#component-communication","title":"Component Communication","text":"<p>All components communicate through the API server. No direct component-to-component communication exists.</p> <pre><code>graph LR\n    subgraph \"Control Plane\"\n        API[API Server]\n        SCHED[Scheduler]\n        CM[Controller&lt;br/&gt;Manager]\n        ETCD[(etcd)]\n    end\n\n    subgraph \"Worker Nodes\"\n        KUB1[kubelet]\n        KUB2[kubelet]\n        KUB3[kubelet]\n    end\n\n    CLIENT[kubectl/Users]\n\n    CLIENT --&gt;|REST API| API\n    SCHED --&gt;|watch/update| API\n    CM --&gt;|watch/update| API\n    API &lt;--&gt;|read/write| ETCD\n    KUB1 --&gt;|watch/update| API\n    KUB2 --&gt;|watch/update| API\n    KUB3 --&gt;|watch/update| API\n\n    style API fill:#e1f5ff\n    style ETCD fill:#ffe5e5</code></pre> <p>Communication Patterns:</p> <ol> <li>kubectl \u2192 API Server: Users interact with cluster via kubectl</li> <li>API Server \u2194 etcd: All state stored in etcd</li> <li>Scheduler \u2192 API Server: Watches for unscheduled pods, updates bindings</li> <li>Controller Manager \u2192 API Server: Watches resources, reconciles state</li> <li>kubelet \u2192 API Server: Reports node/pod status, watches for assigned pods</li> </ol>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#kubernetes-object-model","title":"Kubernetes Object Model","text":"<p>Kubernetes manages objects that represent the desired state of your cluster.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#object-anatomy","title":"Object Anatomy","text":"<pre><code>apiVersion: v1              # API version\nkind: Pod                   # Object type\nmetadata:                   # Object metadata\n  name: nginx-pod\n  namespace: default\n  labels:\n    app: nginx\n    tier: frontend\n  annotations:\n    description: \"Example pod\"\nspec:                       # Desired state\n  containers:\n  - name: nginx\n    image: nginx:1.21\n    ports:\n    - containerPort: 80\nstatus:                     # Current state (managed by system)\n  phase: Running\n  conditions: [...]\n</code></pre> <p>Key Fields: - apiVersion: API group and version (<code>v1</code>, <code>apps/v1</code>, <code>networking.k8s.io/v1</code>) - kind: Object type (Pod, Deployment, Service) - metadata: Identifying information (name, namespace, labels) - spec: Desired state defined by user - status: Current state observed by system (read-only)</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#common-exam-tasks","title":"Common Exam Tasks","text":"","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#scenario-1-check-cluster-component-health","title":"Scenario 1: Check Cluster Component Health","text":"<pre><code># Check all control plane components\nkubectl get componentstatuses\n\n# Check system pods\nkubectl -n kube-system get pods\n\n# Verify API server\nkubectl get --raw='/healthz?verbose'\n\n# Check etcd health\nkubectl -n kube-system exec etcd-&lt;node&gt; -- etcdctl endpoint health\n\n# View node status\nkubectl get nodes\nkubectl describe node &lt;node-name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#scenario-2-troubleshoot-kubelet-issues","title":"Scenario 2: Troubleshoot kubelet Issues","text":"<pre><code># On worker node:\nsystemctl status kubelet\njournalctl -u kubelet -f\n\n# Check kubelet config\ncat /var/lib/kubelet/config.yaml\n\n# Restart kubelet\nsystemctl restart kubelet\n\n# From control plane:\nkubectl describe node &lt;node-name&gt;\nkubectl get events --field-selector involvedObject.kind=Node\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#scenario-3-backup-and-restore-etcd","title":"Scenario 3: Backup and Restore etcd","text":"<pre><code># Backup\nETCDCTL_API=3 etcdctl snapshot save /backup/snapshot.db \\\n  --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key\n\n# Verify backup\nETCDCTL_API=3 etcdctl --write-out=table snapshot status snapshot.db\n\n# Restore (advanced - exam may require)\nETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\\n  --data-dir=/var/lib/etcd-restore\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#practice-exercises","title":"Practice Exercises","text":"<ol> <li>Inspect Cluster Architecture</li> <li>List all control plane pods</li> <li>Check which nodes are running control plane components</li> <li> <p>Identify the API server endpoint and port</p> </li> <li> <p>Component Analysis</p> </li> <li>View logs from each control plane component</li> <li>Check resource usage of control plane pods</li> <li> <p>Identify which container runtime each node is using</p> </li> <li> <p>Troubleshooting Simulation</p> </li> <li>Simulate kubelet failure (stop service) and observe effects</li> <li>Check events to see scheduling decisions</li> <li>Examine etcd data to see how objects are stored</li> </ol>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Kubernetes is a distributed system with control plane and worker nodes</p> <p>\u2705 API server is the central hub - all communication flows through it</p> <p>\u2705 etcd stores all cluster state - critical for backups and disaster recovery</p> <p>\u2705 Scheduler assigns pods to nodes using filtering and scoring</p> <p>\u2705 Controllers maintain desired state through continuous reconciliation loops</p> <p>\u2705 kubelet is the node agent ensuring containers run as specified</p> <p>\u2705 kube-proxy handles networking enabling Service abstraction</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#quick-reference-commands","title":"Quick Reference Commands","text":"<pre><code># Cluster info\nkubectl cluster-info\nkubectl version\nkubectl api-resources\nkubectl api-versions\n\n# Component health\nkubectl get componentstatuses\nkubectl -n kube-system get pods\nkubectl get nodes\n\n# Component logs\nkubectl -n kube-system logs &lt;component-pod&gt;\njournalctl -u kubelet (on node)\njournalctl -u containerd (on node)\n\n# etcd operations\nETCDCTL_API=3 etcdctl endpoint health\nETCDCTL_API=3 etcdctl snapshot save &lt;file&gt;\nETCDCTL_API=3 etcdctl member list\n\n# Node inspection\nkubectl describe node &lt;node-name&gt;\nkubectl get nodes -o wide\nkubectl top nodes (requires metrics-server)\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#next-steps","title":"Next Steps","text":"<p>Continue to Post 2: Setting Up Your Kubernetes Lab Environment to build your hands-on learning environment for practicing CKA exam scenarios.</p> <p>Related Posts: - Kubernetes CKA Mastery - Complete Learning Path - Post 3: kubectl Essentials (coming soon) - Post 15: RBAC and Security (coming soon)</p> <p>External Resources: - Kubernetes Components (Official Docs) - Kubernetes Architecture Diagram (CNCF) - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/","title":"Setting Up Your Kubernetes Lab Environment","text":"<p>Master the art of building Kubernetes clusters for CKA exam preparation. Learn kubeadm for production-grade setups, kind for rapid testing, and essential kubectl configuration for efficient cluster management.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#overview","title":"Overview","text":"<p>A proper lab environment is critical for CKA exam success. The exam uses kubeadm-based clusters, making hands-on practice with real cluster setup essential. This guide covers four primary methods for building Kubernetes environments:</p> <ol> <li>kubeadm - Production-grade multi-node clusters (exam environment)</li> <li>kind - Fast container-based clusters for rapid iteration</li> <li>Minikube - Single-node local development with rich addons</li> <li>kubectl - Essential CLI tool configuration and management</li> </ol> <p>CKA Exam Domain: Cluster Architecture, Installation &amp; Configuration (25%)</p> <p>Key Finding: While the CKA exam uses kubeadm clusters, kind offers the fastest iteration for practice exercises. A combination of both provides optimal preparation.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#lab-environment-decision-tree","title":"Lab Environment Decision Tree","text":"<p>Choosing the right lab setup depends on your immediate needs and learning phase.</p> <pre><code>flowchart TD\n    Start([Need Kubernetes Lab?]) --&gt; Purpose{What's the purpose?}\n\n    Purpose --&gt;|CKA Exam Prep| Exam{Practice&lt;br/&gt;or&lt;br/&gt;Full Simulation?}\n    Purpose --&gt;|Local Development| Dev{Single or&lt;br/&gt;Multi-Node?}\n    Purpose --&gt;|CI/CD Testing| CICD[Use kind&lt;br/&gt;Fast iteration]\n\n    Exam --&gt;|Quick Practice| kind_exam[Use kind&lt;br/&gt;30-second clusters]\n    Exam --&gt;|Full Simulation| kubeadm_exam[Use kubeadm&lt;br/&gt;Production-like setup]\n\n    Dev --&gt;|Single Node&lt;br/&gt;+ Addons| Minikube[Use Minikube&lt;br/&gt;Rich ecosystem]\n    Dev --&gt;|Multi-Node&lt;br/&gt;Testing| kind_dev[Use kind&lt;br/&gt;Config-based]\n    Dev --&gt;|Production Sim| kubeadm_dev[Use kubeadm&lt;br/&gt;Real cluster]\n\n    CICD --&gt; fast{Speed&lt;br/&gt;Important?}\n    fast --&gt;|Yes| kind_fast[Use kind&lt;br/&gt;Container-based]\n    fast --&gt;|No| minikube_ci[Use Minikube&lt;br/&gt;More features]\n\n    style kubeadm_exam fill:#ff9999\n    style kubeadm_dev fill:#ff9999\n    style Minikube fill:#99ccff\n    style kind_exam fill:#99ff99\n    style kind_dev fill:#99ff99\n    style kind_fast fill:#99ff99\n    style CICD fill:#99ff99</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-production-grade-cluster-setup","title":"kubeadm: Production-Grade Cluster Setup","text":"<p>kubeadm is the official Kubernetes tool for bootstrapping production-grade clusters. This is the tool used in the CKA exam environment.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#prerequisites","title":"Prerequisites","text":"<p>System Requirements (Per Node): - Ubuntu 20.04/22.04/24.04 or equivalent Debian-based system - 2+ CPUs - 2GB+ RAM - Network connectivity between all nodes - Unique hostname, MAC address, and product_uuid per node - Swap disabled (critical requirement)</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#complete-installation-process","title":"Complete Installation Process","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-1-disable-swap-critical","title":"Step 1: Disable Swap (CRITICAL)","text":"<p>Kubernetes scheduler relies on accurate resource allocation. Swap can cause unpredictable behavior.</p> <pre><code># Temporary disable\nsudo swapoff -a\n\n# Permanent disable - comment out swap in /etc/fstab\nsudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\n\n# Verify (swap line should show 0)\nfree -h\n</code></pre> <p>Exam Alert</p> <p>The CKA exam expects swap to be disabled. Forgetting this step causes kubeadm init to fail.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-2-install-container-runtime-containerd","title":"Step 2: Install Container Runtime (containerd)","text":"<pre><code># Install containerd\nsudo apt-get update\nsudo apt-get install -y containerd\n\n# Configure containerd\nsudo mkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n\n# Restart and enable containerd\nsudo systemctl restart containerd\nsudo systemctl enable containerd\n\n# Verify containerd is running\nsystemctl status containerd\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-3-install-kubeadm-kubelet-kubectl","title":"Step 3: Install kubeadm, kubelet, kubectl","text":"<pre><code># Update package index and install prerequisites\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\n\n# Add Kubernetes GPG key (NEW REPOSITORY)\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.34/deb/Release.key | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n\n# Add Kubernetes repository\necho 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.34/deb/ /' | \\\n  sudo tee /etc/apt/sources.list.d/kubernetes.list\n\n# Install Kubernetes components\nsudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\n\n# Hold packages at current version (prevent auto-upgrade)\nsudo apt-mark hold kubelet kubeadm kubectl\n\n# Enable kubelet\nsudo systemctl enable --now kubelet\n</code></pre> <p>Repository Change</p> <p>The old repository <code>https://apt.kubernetes.io</code> is deprecated. Always use <code>pkgs.k8s.io</code> for new installations.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-4-initialize-control-plane-node","title":"Step 4: Initialize Control Plane Node","text":"<pre><code># Basic initialization with pod network CIDR\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n\n# For HA setup with load balancer\nsudo kubeadm init \\\n  --control-plane-endpoint \"LOAD_BALANCER_DNS:LOAD_BALANCER_PORT\" \\\n  --upload-certs \\\n  --pod-network-cidr=10.244.0.0/16\n</code></pre> <p>Expected Output: <pre><code>Your Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a Pod network to the cluster.\n\nYou can now join any number of machines by running the following on each node:\n\n  kubeadm join 192.168.0.200:6443 \\\n    --token 9vr73a.a8uxyaju799qwdjv \\\n    --discovery-token-ca-cert-hash sha256:7c2e69131a36ae2a042a339b33381c6d\n</code></pre></p> <p>Save the join command - you'll need it for worker nodes.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-5-configure-kubectl-access","title":"Step 5: Configure kubectl Access","text":"<pre><code># Configure kubectl for regular user\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n# Verify cluster access\nkubectl cluster-info\nkubectl get nodes\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-6-install-cni-network-plugin-critical","title":"Step 6: Install CNI Network Plugin (CRITICAL)","text":"<p>Without a CNI plugin, nodes remain in \"NotReady\" state and pods cannot communicate.</p> <p>Option A: Calico (Recommended for CKA)</p> <pre><code># Install Calico operator\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\n\n# Apply custom resources\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Verify installation (wait for all pods to be Running)\nwatch kubectl get pods -n calico-system\n</code></pre> <p>Option B: Flannel</p> <pre><code>kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml\n</code></pre> <p>Option C: Weave Net</p> <pre><code>kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml\n</code></pre> <p>After CNI installation, verify nodes are Ready:</p> <pre><code>kubectl get nodes\n# NAME            STATUS   ROLES           AGE   VERSION\n# control-plane   Ready    control-plane   5m    v1.34.0\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-7-join-worker-nodes","title":"Step 7: Join Worker Nodes","text":"<p>On each worker node (after completing Steps 1-3):</p> <pre><code># Use the join command from Step 4 output\nsudo kubeadm join 192.168.0.200:6443 \\\n  --token 9vr73a.a8uxyaju799qwdjv \\\n  --discovery-token-ca-cert-hash sha256:7c2e69131a36ae2a042a339b33381c6d\n</code></pre> <p>If token expired (tokens are valid for 24 hours):</p> <pre><code># Generate new join command on control plane\nkubeadm token create --print-join-command\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-cluster-architecture","title":"kubeadm Cluster Architecture","text":"<pre><code>graph TB\n    subgraph \"Control Plane Node\"\n        APIServer[API Server&lt;br/&gt;:6443]\n        Scheduler[Scheduler]\n        Controller[Controller Manager]\n        etcd[(etcd&lt;br/&gt;:2379-2380)]\n        KubeletCP[Kubelet&lt;br/&gt;:10250]\n        ProxyCP[kube-proxy]\n    end\n\n    subgraph \"Worker Node 1\"\n        KubeletW1[Kubelet&lt;br/&gt;:10250]\n        ProxyW1[kube-proxy]\n        Pod1[Pod]\n        Pod2[Pod]\n        CRI1[containerd]\n    end\n\n    subgraph \"Worker Node 2\"\n        KubeletW2[Kubelet&lt;br/&gt;:10250]\n        ProxyW2[kube-proxy]\n        Pod3[Pod]\n        Pod4[Pod]\n        CRI2[containerd]\n    end\n\n    subgraph \"CNI Network Layer\"\n        CNI[Calico/Flannel&lt;br/&gt;10.244.0.0/16]\n    end\n\n    APIServer --&gt; Scheduler\n    APIServer --&gt; Controller\n    APIServer --&gt; etcd\n    APIServer -.-&gt;|watches| KubeletCP\n    APIServer -.-&gt;|watches| KubeletW1\n    APIServer -.-&gt;|watches| KubeletW2\n\n    KubeletW1 --&gt; CRI1\n    KubeletW2 --&gt; CRI2\n    CRI1 --&gt; Pod1\n    CRI1 --&gt; Pod2\n    CRI2 --&gt; Pod3\n    CRI2 --&gt; Pod4\n\n    CNI --&gt; Pod1\n    CNI --&gt; Pod2\n    CNI --&gt; Pod3\n    CNI --&gt; Pod4\n\n    style APIServer fill:#e1f5ff\n    style etcd fill:#ffe5e5\n    style CNI fill:#e8f5e8</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#common-kubeadm-issues-and-solutions","title":"Common kubeadm Issues and Solutions","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-1-swap-is-enabled-production-deployments-should-disable-swap","title":"Issue 1: \"swap is enabled; production deployments should disable swap\"","text":"<p>Cause: Swap not properly disabled</p> <p>Solution: <pre><code>sudo swapoff -a\nsudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\nsudo reboot\nfree -h  # Verify swap shows 0\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-2-container-runtime-network-not-ready-cni-config-uninitialized","title":"Issue 2: \"container runtime network not ready: cni config uninitialized\"","text":"<p>Cause: No CNI plugin installed</p> <p>Solution: <pre><code># Check CNI config directory\nls /etc/cni/net.d/\n\n# If empty, install CNI plugin (Calico/Flannel)\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Verify CNI pods running\nkubectl get pods -n calico-system\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-3-port-6443-already-in-use","title":"Issue 3: Port 6443 already in use","text":"<p>Cause: Previous kubeadm installation not cleaned up</p> <p>Solution: <pre><code># Reset kubeadm completely\nsudo kubeadm reset\n\n# Clean up directories\nsudo rm -rf /etc/cni/net.d\nsudo rm -rf $HOME/.kube/config\n\n# Try initialization again\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-4-worker-node-join-fails","title":"Issue 4: Worker node join fails","text":"<p>Causes: Token expired, network connectivity, firewall rules</p> <p>Solutions: <pre><code># Generate new join command\nkubeadm token create --print-join-command\n\n# Check connectivity from worker to control plane\nping &lt;control-plane-ip&gt;\nnc -zv &lt;control-plane-ip&gt; 6443\n\n# Required firewall ports:\n# Control Plane: 6443, 2379-2380, 10250-10252\n# Worker Nodes: 10250, 30000-32767\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-configuration-file-approach","title":"kubeadm Configuration File Approach","text":"<p>For repeatable setups, use configuration files:</p> <pre><code># kubeadm-config.yaml\napiVersion: kubeadm.k8s.io/v1beta4\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.0.200\n  bindPort: 6443\n---\napiVersion: kubeadm.k8s.io/v1beta4\nkind: ClusterConfiguration\nnetworking:\n  podSubnet: 10.244.0.0/16\n  serviceSubnet: 10.96.0.0/16\nkubernetesVersion: v1.34.0\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nmode: ipvs\n</code></pre> <pre><code># Initialize with config file\nsudo kubeadm init --config=kubeadm-config.yaml\n\n# Generate default config template\nkubeadm config print init-defaults &gt; kubeadm-config.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kind-kubernetes-in-docker","title":"kind: Kubernetes in Docker","text":"<p>kind runs Kubernetes clusters using Docker containers as \"nodes\". Excellent for rapid iteration and CKA practice.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#installation","title":"Installation","text":"<p>Linux/macOS: <pre><code># Using Homebrew (macOS)\nbrew install kind\n\n# Direct binary download (Linux)\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/latest/kind-linux-amd64\nchmod +x ./kind\nsudo mv ./kind /usr/local/bin/kind\n\n# Verify installation\nkind version\n</code></pre></p> <p>Prerequisites: - Docker installed and running - kubectl installed - 4GB+ RAM allocated to Docker - 2+ CPUs for multi-node clusters</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#basic-usage","title":"Basic Usage","text":"<pre><code># Create default single-node cluster\nkind create cluster\n\n# Create cluster with custom name\nkind create cluster --name cka-practice\n\n# List clusters\nkind get clusters\n\n# Delete cluster\nkind delete cluster --name cka-practice\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#multi-node-cluster-configuration","title":"Multi-Node Cluster Configuration","text":"<p>2-Node Cluster (1 Control Plane + 1 Worker):</p> <pre><code># kind-2node.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n  - role: worker\n</code></pre> <pre><code>kind create cluster --config kind-2node.yaml --name cka-lab\n</code></pre> <p>3-Node Cluster with Port Mapping:</p> <pre><code># kind-3node.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n    extraPortMappings:\n    - containerPort: 30080\n      hostPort: 8080\n      protocol: TCP\n  - role: worker\n  - role: worker\n</code></pre> <pre><code>kind create cluster --config kind-3node.yaml --name multinode\n</code></pre> <p>High Availability Control Plane (3 Control Plane + 3 Worker):</p> <pre><code># kind-ha.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n  - role: control-plane\n  - role: control-plane\n  - role: worker\n  - role: worker\n  - role: worker\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kind-cluster-lifecycle","title":"kind Cluster Lifecycle","text":"<pre><code>sequenceDiagram\n    participant User\n    participant kind\n    participant Docker\n    participant kubectl\n\n    User-&gt;&gt;kind: kind create cluster --config kind-3node.yaml\n    kind-&gt;&gt;Docker: Pull kindest/node:v1.34.0 image\n    Docker--&gt;&gt;kind: Image ready\n\n    kind-&gt;&gt;Docker: Create control-plane container\n    kind-&gt;&gt;Docker: Create worker-1 container\n    kind-&gt;&gt;Docker: Create worker-2 container\n    Docker--&gt;&gt;kind: 3 containers running\n\n    kind-&gt;&gt;kind: Bootstrap Kubernetes in containers\n    kind-&gt;&gt;kind: Configure CNI (kindnetd)\n    kind-&gt;&gt;kind: Wait for cluster ready\n\n    kind-&gt;&gt;kubectl: Update kubeconfig\n    kind--&gt;&gt;User: Cluster ready (30-60 seconds)\n\n    User-&gt;&gt;kubectl: kubectl get nodes\n    kubectl--&gt;&gt;User: 3 nodes Ready\n\n    Note over User,kubectl: Practice CKA scenarios\n\n    User-&gt;&gt;kind: kind delete cluster\n    kind-&gt;&gt;Docker: Remove all containers\n    Docker--&gt;&gt;kind: Cleanup complete\n    kind--&gt;&gt;User: Cluster deleted</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#load-docker-images-into-kind","title":"Load Docker Images into kind","text":"<p>For testing custom applications without pushing to registry:</p> <pre><code># Build image locally\ndocker build -t my-app:1.0 .\n\n# Load into kind cluster\nkind load docker-image my-app:1.0 --name cka-lab\n\n# Verify image available in cluster\ndocker exec -it cka-lab-control-plane crictl images | grep my-app\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#when-to-use-kind","title":"When to Use kind","text":"<p>Best For: - CKA rapid practice: Create/destroy clusters in seconds - Multi-node testing: Easy configuration for complex topologies - CI/CD pipelines: Fast, reproducible test environments - Integration testing: Test applications in real cluster - Quick experiments: Try configurations without VM overhead</p> <p>Not Ideal For: - Learning basics: Minikube has better addon ecosystem - Production simulation: kubeadm provides real multi-machine setup - Resource-constrained systems: Requires Docker overhead</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#minikube-local-development-environment","title":"Minikube: Local Development Environment","text":"<p>Minikube creates single-node Kubernetes clusters on your local machine. Ideal for learning with rich addon support.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#installation_1","title":"Installation","text":"<p>macOS: <pre><code>brew install minikube\nminikube version\n</code></pre></p> <p>Linux: <pre><code>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\nminikube version\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#driver-options","title":"Driver Options","text":"<p>Docker Driver (Recommended): <pre><code># Start with Docker driver\nminikube start --driver=docker\n\n# Set as default\nminikube config set driver docker\n</code></pre></p> <p>QEMU Driver (ARM/M1 Macs): <pre><code>minikube start --driver=qemu\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#resource-configuration","title":"Resource Configuration","text":"<pre><code># Specify CPUs, memory, disk\nminikube start \\\n  --driver=docker \\\n  --cpus=4 \\\n  --memory=8192 \\\n  --disk-size=40g \\\n  --kubernetes-version=v1.34.0\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#common-minikube-commands","title":"Common Minikube Commands","text":"<pre><code># Start cluster\nminikube start\n\n# Stop cluster (preserves state)\nminikube stop\n\n# Delete cluster\nminikube delete\n\n# Check status\nminikube status\n\n# SSH into node\nminikube ssh\n\n# Open dashboard\nminikube dashboard\n\n# List addons\nminikube addons list\n\n# Enable addons\nminikube addons enable ingress\nminikube addons enable metrics-server\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#minikube-addons-for-cka-practice","title":"Minikube Addons for CKA Practice","text":"<pre><code># Metrics Server (for kubectl top)\nminikube addons enable metrics-server\n\n# Ingress Controller\nminikube addons enable ingress\n\n# Storage Provisioner (dynamic PVs)\nminikube addons enable storage-provisioner\n\n# Dashboard\nminikube addons enable dashboard\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubectl-installation-and-configuration","title":"kubectl Installation and Configuration","text":"<p>kubectl is the Kubernetes command-line tool. Mastery is essential for CKA exam success.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#installation_2","title":"Installation","text":"<p>Linux: <pre><code># Download latest release\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\n# Install\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# Verify\nkubectl version --client\n</code></pre></p> <p>macOS: <pre><code># Using Homebrew\nbrew install kubectl\n\n# Verify\nkubectl version --client\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#version-compatibility","title":"Version Compatibility","text":"<p>kubectl version must be within \u00b11 minor version of cluster version.</p> <pre><code># Check versions\nkubectl version --short\n\n# Example compatible versions:\n# Cluster: v1.34.0\n# kubectl: v1.33.x, v1.34.x, v1.35.x \u2705\n# kubectl: v1.32.x, v1.36.x \u274c\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#shell-completion-setup-critical-for-exam-speed","title":"Shell Completion Setup (CRITICAL for Exam Speed)","text":"<p>Bash (Linux): <pre><code># Install bash-completion package\nsudo apt-get install bash-completion\n\n# Add completion to current shell\nsource &lt;(kubectl completion bash)\n\n# Add to .bashrc for persistence\necho 'source &lt;(kubectl completion bash)' &gt;&gt; ~/.bashrc\n\n# Alias completion (essential for exam)\necho 'alias k=kubectl' &gt;&gt; ~/.bashrc\necho 'complete -o default -F __start_kubectl k' &gt;&gt; ~/.bashrc\n\n# Reload\nsource ~/.bashrc\n</code></pre></p> <p>Zsh: <pre><code># Add completion to .zshrc\necho 'source &lt;(kubectl completion zsh)' &gt;&gt; ~/.zshrc\n\n# Alias completion\necho 'alias k=kubectl' &gt;&gt; ~/.zshrc\necho 'complete -o default -F __start_kubectl k' &gt;&gt; ~/.zshrc\n\n# Reload\nsource ~/.zshrc\n</code></pre></p> <p>Exam Tip</p> <p>Practice using <code>k</code> instead of <code>kubectl</code> extensively. Tab completion saves critical minutes during the exam.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeconfig-management","title":"kubeconfig Management","text":"<p>kubeconfig files contain cluster connection details. Managing multiple clusters efficiently is essential for the exam.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeconfig-file-structure","title":"kubeconfig File Structure","text":"<pre><code>apiVersion: v1\nkind: Config\ncurrent-context: my-cluster\n\nclusters:\n- cluster:\n    certificate-authority-data: &lt;base64-encoded-ca&gt;\n    server: https://192.168.1.100:6443\n  name: my-cluster\n\nusers:\n- name: my-user\n  user:\n    client-certificate-data: &lt;base64-encoded-cert&gt;\n    client-key-data: &lt;base64-encoded-key&gt;\n\ncontexts:\n- context:\n    cluster: my-cluster\n    user: my-user\n    namespace: default\n  name: my-cluster-context\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#context-management-flow","title":"Context Management Flow","text":"<pre><code>graph TB\n    subgraph \"kubeconfig File\"\n        Clusters[Clusters&lt;br/&gt;- prod-cluster&lt;br/&gt;- dev-cluster&lt;br/&gt;- cka-cluster]\n        Users[Users&lt;br/&gt;- admin-user&lt;br/&gt;- dev-user&lt;br/&gt;- readonly-user]\n        Contexts[Contexts&lt;br/&gt;- prod-admin&lt;br/&gt;- dev-user&lt;br/&gt;- cka-practice]\n        CurrentContext[Current Context:&lt;br/&gt;cka-practice]\n    end\n\n    subgraph \"Context: cka-practice\"\n        CKACluster[Cluster: cka-cluster]\n        CKAUser[User: admin-user]\n        CKANamespace[Namespace: default]\n    end\n\n    subgraph \"Actual Clusters\"\n        ProdCluster[Production&lt;br/&gt;10.0.1.100:6443]\n        DevCluster[Development&lt;br/&gt;10.0.2.100:6443]\n        CKAClusterActual[CKA Lab&lt;br/&gt;10.0.3.100:6443]\n    end\n\n    Contexts --&gt; CurrentContext\n    CurrentContext --&gt; CKACluster\n    CurrentContext --&gt; CKAUser\n    CurrentContext --&gt; CKANamespace\n\n    CKACluster -.-&gt;|kubectl commands| CKAClusterActual\n\n    style CurrentContext fill:#ffff99\n    style CKAClusterActual fill:#99ff99</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#essential-context-commands","title":"Essential Context Commands","text":"<pre><code># List all contexts\nkubectl config get-contexts\n\n# Show current context\nkubectl config current-context\n\n# Switch context\nkubectl config use-context cka-practice\n\n# Set default namespace for current context\nkubectl config set-context --current --namespace=kube-system\n\n# Create new context\nkubectl config set-context dev-user \\\n  --cluster=dev-cluster \\\n  --namespace=development \\\n  --user=dev-user\n\n# Rename context\nkubectl config rename-context old-name new-name\n\n# Delete context\nkubectl config delete-context old-context\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#multiple-cluster-management","title":"Multiple Cluster Management","text":"<p>Strategy 1: Merged Configuration (Recommended for Exam):</p> <pre><code># Merge multiple kubeconfig files\nexport KUBECONFIG=~/.kube/config:~/.kube/dev-config:~/.kube/prod-config\nkubectl config view --flatten &gt; ~/.kube/merged-config\n\n# Set as default\nexport KUBECONFIG=~/.kube/merged-config\n\n# Add to .bashrc for persistence\necho 'export KUBECONFIG=~/.kube/merged-config' &gt;&gt; ~/.bashrc\n</code></pre> <p>Strategy 2: Context-Specific Commands:</p> <pre><code># Use specific context for single command\nkubectl --context=prod-cluster get nodes\n\n# Use specific kubeconfig for single command\nkubectl --kubeconfig=~/.kube/prod-config get pods\n\n# Override namespace for single command\nkubectl -n kube-system get pods\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#security-best-practices","title":"Security Best Practices","text":"<pre><code># Protect kubeconfig files\nchmod 600 ~/.kube/config\nchmod 0400 ~/.kube/prod-config  # Read-only for production\n\n# Never commit kubeconfig to version control\necho '.kube/' &gt;&gt; ~/.gitignore\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#common-exam-tasks","title":"Common Exam Tasks","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#scenario-1-rapid-cluster-setup-for-practice","title":"Scenario 1: Rapid Cluster Setup for Practice","text":"<p>Objective: Create disposable cluster for practice scenario</p> <pre><code># Create kind cluster\ncat &lt;&lt;EOF | kind create cluster --config=-\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\nEOF\n\n# Verify cluster ready\nkubectl get nodes\n\n# Practice exam task\nkubectl run nginx --image=nginx\nkubectl expose pod nginx --port=80 --type=NodePort\n\n# Clean up when done\nkind delete cluster\n</code></pre> <p>Time: 30-60 seconds for cluster creation</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#scenario-2-multi-cluster-context-switching","title":"Scenario 2: Multi-Cluster Context Switching","text":"<p>Objective: Practice switching between exam cluster contexts</p> <pre><code># Assume exam provides contexts: cluster1-context, cluster2-context\n\n# List available contexts\nkubectl config get-contexts\n\n# Switch to cluster1\nkubectl config use-context cluster1-context\n\n# Verify current context\nkubectl config current-context\n\n# Deploy to cluster1\nkubectl run web --image=nginx\n\n# Switch to cluster2\nkubectl config use-context cluster2-context\n\n# Deploy to cluster2\nkubectl run database --image=postgres\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#scenario-3-troubleshoot-cni-issues","title":"Scenario 3: Troubleshoot CNI Issues","text":"<p>Objective: Fix cluster networking</p> <pre><code># Check node status\nkubectl get nodes\n# NAME     STATUS     ROLES           AGE   VERSION\n# node-1   NotReady   control-plane   2m    v1.34.0\n\n# Check system pods\nkubectl -n kube-system get pods\n\n# Verify CNI config exists\nkubectl exec -n kube-system &lt;any-pod&gt; -- ls /etc/cni/net.d/\n\n# If empty, install CNI\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Verify nodes transition to Ready\nkubectl get nodes --watch\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#cni-network-communication","title":"CNI Network Communication","text":"<p>Understanding how CNI plugins enable pod-to-pod communication is critical for troubleshooting.</p> <pre><code>sequenceDiagram\n    participant Pod1 as Pod 1&lt;br/&gt;10.244.1.5&lt;br/&gt;Node1\n    participant CNI1 as CNI Plugin&lt;br/&gt;Node1\n    participant CNI2 as CNI Plugin&lt;br/&gt;Node2\n    participant Pod2 as Pod 2&lt;br/&gt;10.244.2.8&lt;br/&gt;Node2\n\n    Note over Pod1,Pod2: Pod-to-Pod Communication Across Nodes\n\n    Pod1-&gt;&gt;CNI1: Send packet to 10.244.2.8\n    CNI1-&gt;&gt;CNI1: Check routing table&lt;br/&gt;Pod CIDR 10.244.0.0/16\n    CNI1-&gt;&gt;CNI2: Forward via overlay network&lt;br/&gt;(VXLAN/BGP)\n    CNI2-&gt;&gt;CNI2: Lookup destination pod&lt;br/&gt;10.244.2.8 on Node2\n    CNI2-&gt;&gt;Pod2: Deliver packet\n    Pod2-&gt;&gt;CNI2: Send response\n    CNI2-&gt;&gt;CNI1: Return via overlay\n    CNI1-&gt;&gt;Pod1: Deliver response\n\n    Note over CNI1,CNI2: CNI ensures IP reachability&lt;br/&gt;without NodePort/Service</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#practice-exercises","title":"Practice Exercises","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-1-complete-kubeadm-cluster-setup-60-minutes","title":"Exercise 1: Complete kubeadm Cluster Setup (60 minutes)","text":"<p>Objective: Build production-like 3-node cluster</p> <p>Tasks: 1. Prepare 3 VMs (1 control plane, 2 workers) 2. Disable swap on all nodes 3. Install container runtime 4. Install kubeadm, kubelet, kubectl 5. Initialize control plane with Calico pod CIDR 6. Install Calico CNI 7. Join worker nodes 8. Verify all nodes Ready 9. Deploy test workload</p> <p>Success Criteria: - All 3 nodes show Ready status - CNI pods running in calico-system namespace - Test pod can communicate across nodes</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-2-kind-multi-node-lab-20-minutes","title":"Exercise 2: kind Multi-Node Lab (20 minutes)","text":"<p>Objective: Create multi-node cluster for rapid testing</p> <p>Tasks: 1. Create kind config for 3-node cluster 2. Map NodePort 30000 to localhost:8080 3. Create cluster 4. Deploy nginx with NodePort 30000 5. Access from host browser 6. Test pod scheduling across workers 7. Delete and recreate cluster</p> <p>Success Criteria: - Cluster creation completes in &lt;60 seconds - Nginx accessible on localhost:8080 - Can repeat cycle 5 times in 10 minutes</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-3-kubeconfig-context-mastery-30-minutes","title":"Exercise 3: kubeconfig Context Mastery (30 minutes)","text":"<p>Objective: Manage multiple clusters efficiently</p> <p>Tasks: 1. Create 3 different clusters (kubeadm, kind, minikube) 2. Export kubeconfig from each 3. Merge into single kubeconfig 4. Rename contexts meaningfully 5. Set default namespace per context 6. Practice rapid context switching 7. Deploy workload to specific context without switching</p> <p>Success Criteria: - Switch contexts in &lt;5 seconds - Deploy to specific cluster without errors - Verify deployment in correct cluster</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-4-shell-completion-and-aliases-15-minutes","title":"Exercise 4: Shell Completion and Aliases (15 minutes)","text":"<p>Objective: Optimize kubectl workflow for exam speed</p> <p>Tasks: 1. Install bash-completion 2. Configure kubectl completion 3. Test tab completion 4. Create aliases: k, kg, kd, kl 5. Configure alias completion 6. Time yourself: deploy nginx with and without aliases</p> <p>Success Criteria: - Tab completion works for resources - Aliases reduce command length by 50%+ - Muscle memory for common patterns</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-5-troubleshooting-simulation-45-minutes","title":"Exercise 5: Troubleshooting Simulation (45 minutes)","text":"<p>Objective: Diagnose and fix common cluster issues</p> <p>Tasks: 1. Initialize cluster WITHOUT CNI 2. Observe NotReady nodes 3. Check kubelet logs for errors 4. Identify CNI-related messages 5. Install CNI plugin 6. Verify nodes transition to Ready 7. Test pod communication 8. Break and fix: stop kubelet, observe effects 9. Break and fix: remove CNI config, restore</p> <p>Success Criteria: - Can identify CNI issues from logs - Successfully install and verify CNI - Understand node status transitions - Troubleshooting workflow muscle memory</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#lab-environment-comparison","title":"Lab Environment Comparison","text":"<pre><code>graph TD\n    subgraph \"Setup Method Comparison\"\n        Feature[Feature]\n        kubeadm[kubeadm]\n        minikube[Minikube]\n        kind[kind]\n    end\n\n    Feature --&gt; |Startup Time| Time\n    Time --&gt; kubeadm_time[5-10 min&lt;br/&gt;Multi-machine]\n    Time --&gt; minikube_time[2-5 min&lt;br/&gt;VM boot]\n    Time --&gt; kind_time[30-60 sec&lt;br/&gt;Containers]\n\n    Feature --&gt; |Resource Usage| Resources\n    Resources --&gt; kubeadm_res[High&lt;br/&gt;Real VMs]\n    Resources --&gt; minikube_res[Medium&lt;br/&gt;Single VM]\n    Resources --&gt; kind_res[Low&lt;br/&gt;Docker only]\n\n    Feature --&gt; |Multi-Node| MultiNode\n    MultiNode --&gt; kubeadm_mn[Native&lt;br/&gt;Production-like]\n    MultiNode --&gt; minikube_mn[Experimental&lt;br/&gt;Limited]\n    MultiNode --&gt; kind_mn[Native&lt;br/&gt;Config-based]\n\n    Feature --&gt; |CKA Relevance| CKA\n    CKA --&gt; kubeadm_cka[Essential&lt;br/&gt;Exam environment]\n    CKA --&gt; minikube_cka[Supplemental&lt;br/&gt;Learning]\n    CKA --&gt; kind_cka[High&lt;br/&gt;Practice speed]\n\n    style kind_time fill:#99ff99\n    style kind_res fill:#99ff99\n    style kubeadm_mn fill:#ff9999\n    style kubeadm_cka fill:#ff9999</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#quick-reference-commands","title":"Quick Reference Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-cluster-lifecycle","title":"kubeadm Cluster Lifecycle","text":"<pre><code># Initialize control plane\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n\n# Configure kubectl\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n# Install CNI (Calico)\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Generate join command\nkubeadm token create --print-join-command\n\n# Reset cluster\nsudo kubeadm reset\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kind-quick-start","title":"kind Quick Start","text":"<pre><code># Create cluster\nkind create cluster --name cka-lab\n\n# Create multi-node cluster\ncat &lt;&lt;EOF | kind create cluster --config=-\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\nEOF\n\n# Delete cluster\nkind delete cluster --name cka-lab\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#minikube-quick-start","title":"Minikube Quick Start","text":"<pre><code># Start with resource spec\nminikube start --driver=docker --cpus=4 --memory=8192\n\n# Enable addons\nminikube addons enable metrics-server\nminikube addons enable ingress\n\n# Access service\nminikube service &lt;service-name&gt;\n\n# Clean up\nminikube delete\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubectl-context-management","title":"kubectl Context Management","text":"<pre><code># View contexts\nkubectl config get-contexts\n\n# Switch context\nkubectl config use-context &lt;context-name&gt;\n\n# Set namespace\nkubectl config set-context --current --namespace=&lt;namespace&gt;\n\n# Context-specific command\nkubectl --context=&lt;context&gt; get pods\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#troubleshooting-commands","title":"Troubleshooting Commands","text":"<pre><code># Check cluster health\nkubectl get nodes -o wide\nkubectl -n kube-system get pods\n\n# View kubelet logs (on node)\nsudo journalctl -u kubelet -f\n\n# Check CNI config\nls -l /etc/cni/net.d/\n\n# View events\nkubectl get events --sort-by='.lastTimestamp'\n\n# Check etcd health\nsudo ETCDCTL_API=3 etcdctl \\\n  --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\n  endpoint health\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 kubeadm is essential for CKA - The exam environment uses kubeadm clusters</p> <p>\u2705 kind enables rapid iteration - 30-second cluster creation for practice</p> <p>\u2705 kubectl proficiency is critical - Shell completion and aliases save exam minutes</p> <p>\u2705 kubeconfig mastery matters - Context switching is a core exam skill</p> <p>\u2705 CNI is non-negotiable - Clusters are non-functional without CNI plugins</p> <p>\u2705 Swap must be disabled - Kubernetes does not support swap memory</p> <p>\u2705 Version compatibility awareness - kubectl and cluster versions must align</p> <p>\u2705 Hands-on practice wins - Deploy clusters repeatedly until muscle memory forms</p> <p>\u2705 Troubleshooting is 30% of CKA - Practice breaking and fixing clusters</p> <p>\u2705 Speed through preparation - Optimize workflow before exam day</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#next-steps","title":"Next Steps","text":"<p>After mastering lab setup, continue with:</p> <p>Post 3: kubectl Essentials and Resource Management - Master the command-line tool for all Kubernetes operations</p> <p>Related Posts: - Kubernetes Architecture Fundamentals - Understanding cluster components - Kubernetes CKA Mastery - Complete Learning Path - Full exam preparation series</p> <p>External Resources: - kubeadm Official Documentation - kind Quick Start Guide - Minikube Documentation - kubectl Cheat Sheet - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/","title":"High-Performance pNFS v4.2 Distributed Storage Architecture","text":"<p>A deep dive into building a clustered, high-availability parallel NFS storage system with load-balanced metadata servers, NVMe-backed storage nodes, and low-latency interconnects.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#architecture-overview","title":"Architecture Overview","text":"<p>This architecture implements a production-grade parallel NFS (pNFS) v4.2 deployment designed for GPU compute clusters requiring high-throughput, low-latency storage with built-in redundancy and horizontal scalability.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#key-design-goals","title":"Key Design Goals","text":"<ul> <li>Parallel I/O Performance: Direct client-to-storage data paths bypassing metadata bottlenecks</li> <li>Metadata High Availability: Clustered MDS with automatic failover</li> <li>Horizontal Scalability: Add storage nodes without downtime</li> <li>Low Latency: InfiniBand/RoCE interconnects for sub-microsecond latencies</li> <li>Fault Tolerance: No single points of failure in the architecture</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#system-topology","title":"System Topology","text":"<pre><code>sequenceDiagram\n    participant Client as Client&lt;br/&gt;(pNFS v4.2)\n    participant MDS as MDS Cluster&lt;br/&gt;(Active-Active via VIP)\n    participant S1 as Storage Node 1&lt;br/&gt;(NVMe)\n    participant S2 as Storage Node 2&lt;br/&gt;(NVMe)\n    participant S3 as Storage Node 3&lt;br/&gt;(NVMe)\n\n    Note over Client,S3: \u2501\u2501\u2501\u2501\u2501\u2501\u2501 PHASE 1: METADATA PATH \u2501\u2501\u2501\u2501\u2501\u2501\u2501\n    Note over MDS: Virtual IP load balances to any MDS&lt;br/&gt;All MDS nodes share distributed state\n\n    Client-&gt;&gt;+MDS: LAYOUTGET(file_handle)\n    Note right of MDS: MDS queries distributed&lt;br/&gt;backend for file layout\n    MDS--&gt;&gt;-Client: LAYOUT(stripe_pattern, DS_list)\n    Note left of Client: \u2713 Client caches layout&lt;br/&gt;Stripe unit: 1MB&lt;br/&gt;Stripe count: 3 nodes\n\n    Note over Client,S3: \u2501\u2501\u2501\u2501\u2501\u2501\u2501 PHASE 2: DATA PATH (MDS BYPASSED) \u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n    par Parallel Direct I/O over InfiniBand/RoCE\n        Client-&gt;&gt;+S1: WRITE Stripe 0\n        S1-&gt;&gt;S1: NVMe I/O\n        S1--&gt;&gt;-Client: ACK\n    and\n        Client-&gt;&gt;+S2: WRITE Stripe 1\n        S2-&gt;&gt;S2: NVMe I/O\n        S2--&gt;&gt;-Client: ACK\n    and\n        Client-&gt;&gt;+S3: WRITE Stripe 2\n        S3-&gt;&gt;S3: NVMe I/O\n        S3--&gt;&gt;-Client: ACK\n    end\n\n    Note over Client,S3: \u26a1 Aggregate: 3 \u00d7 7 GB/s = ~20 GB/s effective throughput</code></pre> <p>Key Architecture Points:</p> Layer Component Function Control Plane MDS Cluster (Active-Active) Virtual IP \u2192 Load balances metadata requestsDistributed backend \u2192 Shared state (GFS2/OCFS2)Co-located with storage nodes Data Plane Storage Nodes Direct parallel I/O bypasses MDS entirelyEach node: MDS service + Data service + NVMeHigh-speed fabric: InfiniBand or 100GbE RoCE Client pNFS v4.2 One-time layout fetch \u2192 caches stripe patternDirect parallel writes to multiple storage nodesNo metadata bottleneck on data path <p>Architecture Advantage</p> <p>Separation of Control and Data Planes: Client contacts MDS once to get file layout, then performs all subsequent I/O directly to storage nodes over high-speed network. MDS handles only metadata operations (LAYOUTGET, OPEN, CLOSE), while bulk data transfer happens in parallel across multiple storage nodes, eliminating the metadata server bottleneck.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#component-breakdown","title":"Component Breakdown","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#1-client-layer-pnfs-v42-clients","title":"1. Client Layer (pNFS v4.2 Clients)","text":"<p>Role: GPU compute nodes running pNFS-aware clients</p> <p>Characteristics: - Protocol: NFSv4.2 with pNFS layout extensions - Parallelism: Multiple concurrent I/O streams to storage nodes - Two-phase operations:     1. Metadata phase: Request file layout from MDS via VIP     2. Data phase: Direct parallel I/O to multiple storage nodes</p> <p>Advantages: - Metadata and data paths are separated - MDS only handles control plane; data plane scales independently - Clients cache layouts, reducing metadata round-trips</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#2-metadata-virtual-ip-vip-load-balancer","title":"2. Metadata Virtual IP (VIP) / Load Balancer","text":"<p>Role: Distribute metadata requests across clustered MDS instances</p> <p>Implementation Options:</p> Technology Use Case Pros Cons Keepalived + VRRP Simple HA Easy setup, fast failover Layer 3 only, single active HAProxy Advanced LB Health checks, stats, multi-algo Additional component Pacemaker + Corosync Enterprise HA Full cluster manager Complex configuration <p>Configuration Considerations: - Failover time: Target &lt;2 seconds for MDS failover - Session stickiness: Not required (stateless metadata operations) - Health checks: Monitor MDS service health on each node</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#3-mds-cluster-metadata-servers","title":"3. MDS Cluster (Metadata Servers)","text":"<p>Role: Manage namespace, permissions, file layouts, and client coordination</p> <p>Clustering Strategy:</p> <p>Active-Active Clustering</p> <p>All MDS instances are active simultaneously, sharing load via the VIP. This differs from traditional active-passive designs and requires:</p> <ul> <li>Shared backend: Distributed consensus or shared storage for metadata</li> <li>State synchronization: Real-time metadata replication</li> <li>Lock coordination: Distributed locking for file operations</li> </ul> <p>Backend Options:</p> <pre><code>Option 1: Shared Block Device (DRBD + GFS2/OCFS2)\n  pros:\n    - Battle-tested clustering\n    - POSIX semantics\n  cons:\n    - Block-level sync overhead\n    - Limited to 2-3 nodes typically\n\nOption 2: Distributed Database (etcd/Consul)\n  pros:\n    - Raft consensus built-in\n    - Horizontal scaling\n    - Cloud-native\n  cons:\n    - Additional latency\n    - More complex integration\n\nOption 3: Lustre MGS/MDT (if using Lustre as pNFS backend)\n  pros:\n    - Native high availability\n    - Proven at exascale\n  cons:\n    - Lustre-specific\n    - Complex deployment\n</code></pre> <p>Heartbeat Mechanism: - Interval: 500ms - 1s between nodes - Quorum: Majority voting prevents split-brain - Fencing: STONITH (Shoot The Other Node In The Head) for failed nodes</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#4-high-speed-network-fabric","title":"4. High-Speed Network Fabric","text":"<p>Role: Low-latency, high-bandwidth interconnect for storage traffic</p> <p>Technology Comparison:</p> Technology Bandwidth Latency Use Case InfiniBand HDR 200 Gbps &lt;1 \u03bcs HPC, AI training clusters 100GbE RoCE v2 100 Gbps &lt;5 \u03bcs Cost-effective alternative Omni-Path 100 Gbps &lt;1 \u03bcs Intel ecosystem <p>Network Design: <pre><code>- Dedicated storage VLAN/subnet\n- Jumbo frames (MTU 9000) for throughput\n- RDMA for zero-copy transfers\n- Lossless Ethernet (PFC) if using RoCE\n- Multiple paths for redundancy (LACP/MLAG)\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#5-storage-nodes","title":"5. Storage Nodes","text":"<p>Role: Serve actual file data via pNFS Data Service (DS)</p> <p>Node Architecture:</p> <pre><code>Each storage node runs:\n\u251c\u2500\u2500 MDS Service (part of cluster)\n\u251c\u2500\u2500 Data Service (DS) (serves pNFS I/O)\n\u2514\u2500\u2500 Physical Storage (NVMe SSDs)\n</code></pre> <p>NVMe Configuration: - Device: PCIe Gen4 NVMe SSDs (7000+ MB/s per device) - RAID: No RAID (rely on pNFS striping across nodes) - File System: XFS or ZFS for local storage - Tuning:     - <code>nvme.io_timeout=4294967295</code> (disable timeout)     - <code>elevator=none</code> (bypass I/O scheduler for NVMe)     - <code>vm.dirty_ratio=5</code> (aggressive writeback)</p> <p>Capacity Planning: <pre><code>Per-node capacity:\n  - 4x 4TB NVMe = 16TB raw per node\n  - 10 nodes = 160TB aggregate raw\n  - No RAID overhead (redundancy via replication)\n  - Effective capacity: ~140TB (accounting for metadata)\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#data-flow-read-operation","title":"Data Flow: Read Operation","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-1-layout-request-metadata-path","title":"Phase 1: Layout Request (Metadata Path)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant VIP\n    participant MDS1\n    participant Backend\n\n    Client-&gt;&gt;VIP: LAYOUTGET (file handle)\n    VIP-&gt;&gt;MDS1: Forward request\n    MDS1-&gt;&gt;Backend: Query file layout\n    Backend--&gt;&gt;MDS1: Layout map\n    MDS1--&gt;&gt;Client: LAYOUT (stripe pattern, DS list)\n    Note over Client: Client caches layout</code></pre> <p>Layout Information Returned: <pre><code>{\n  \"layout_type\": \"LAYOUT4_NFSV4_1_FILES\",\n  \"stripe_unit\": 1048576,\n  \"stripe_count\": 4,\n  \"data_servers\": [\n    \"10.10.1.11:2049\",  // Storage Node 1\n    \"10.10.1.12:2049\",  // Storage Node 2\n    \"10.10.1.13:2049\",  // Storage Node 3\n    \"10.10.1.14:2049\"   // Storage Node 4\n  ]\n}\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-2-parallel-data-io-data-path","title":"Phase 2: Parallel Data I/O (Data Path)","text":"<pre><code>graph LR\n    Client --&gt;|Stripe 0| DS1[Storage Node 1]\n    Client --&gt;|Stripe 1| DS2[Storage Node 2]\n    Client --&gt;|Stripe 3| DS3[Storage Node 3]\n    Client --&gt;|Stripe 4| DS4[Storage Node 4]\n\n    DS1 --&gt; NVMe1[NVMe SSD]\n    DS2 --&gt; NVMe2[NVMe SSD]\n    DS3 --&gt; NVMe3[NVMe SSD]\n    DS4 --&gt; NVMe4[NVMe SSD]</code></pre> <p>Throughput Calculation: <pre><code>Single NVMe: 7 GB/s read\n4-way stripe: 7 GB/s \u00d7 4 = 28 GB/s aggregate\nOverhead (20%): ~22 GB/s effective client throughput\n</code></pre></p> <p>Key Advantage</p> <p>The MDS is completely bypassed during data I/O. Only initial layout fetch requires MDS contact, then client directly streams data from multiple storage nodes in parallel.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#write-operation-with-coherency","title":"Write Operation with Coherency","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#challenges","title":"Challenges","text":"<ul> <li>Cache coherency: Multiple clients may access same file</li> <li>Consistency: Must maintain POSIX semantics</li> <li>Layout revocation: MDS may recall layouts during conflicts</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#write-flow","title":"Write Flow","text":"<pre><code>sequenceDiagram\n    participant Client1\n    participant Client2\n    participant MDS\n    participant DS1\n\n    Client1-&gt;&gt;MDS: OPEN (file, WRITE)\n    MDS--&gt;&gt;Client1: LAYOUT (read-write)\n    Client1-&gt;&gt;DS1: WRITE data\n\n    Client2-&gt;&gt;MDS: OPEN (same file, WRITE)\n    MDS-&gt;&gt;Client1: CB_LAYOUTRECALL\n    Client1-&gt;&gt;DS1: COMMIT writes\n    Client1-&gt;&gt;MDS: LAYOUTRETURN\n    MDS--&gt;&gt;Client2: LAYOUT (read-write)</code></pre> <p>Layout Recall Scenarios: 1. Write-write conflict: Second writer needs exclusive layout 2. Read-write conflict: Writer needs to invalidate reader caches 3. Layout change: File being migrated or restriped</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#high-availability-scenarios","title":"High Availability Scenarios","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#scenario-1-mds-node-failure","title":"Scenario 1: MDS Node Failure","text":"<pre><code>Before:\n  VIP \u2192 MDS1 (active)\n      \u2192 MDS2 (active)\n      \u2192 MDS3 (active)  \u2190 fails\n\nAfter (within 2 seconds):\n  VIP \u2192 MDS1 (active)  \u2190 absorbs load\n      \u2192 MDS2 (active)  \u2190 absorbs load\n\n  MDS3: Fenced by cluster, removed from VIP pool\n  Client layouts: Still valid, no client disruption\n</code></pre> <p>Recovery Actions: - Quorum maintained (2/3 nodes) - Clients continue data I/O unaffected - New metadata requests distributed to healthy MDS nodes - Failed MDS auto-rejoins after recovery</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#scenario-2-storage-node-failure","title":"Scenario 2: Storage Node Failure","text":"<pre><code>pNFS File with 4-way striping across nodes 1-4:\n  Node 3 fails \u2192 Stripes 2 (stored on node 3) unavailable\n\nClient behavior:\n  1. Client detects I/O error on stripe 2\n  2. Client returns partial read/write to application\n  3. Application must handle EIO (or use replication)\n\nRecovery:\n  - Option A: File replicated (pNFS server-side replication)\n             \u2192 Automatic failover to replica stripe\n  - Option B: No replication \u2192 Data loss for affected stripes\n</code></pre> <p>Data Durability</p> <p>pNFS itself does NOT provide redundancy. You must implement:</p> <ul> <li>Server-side replication (e.g., Lustre OST pools)</li> <li>Client-side RAID (mdadm over pNFS)</li> <li>Application-level erasure coding</li> <li>Regular snapshots/backups</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#scenario-3-network-partition-split-brain-prevention","title":"Scenario 3: Network Partition (Split-Brain Prevention)","text":"<pre><code>Network partition splits cluster:\n  Partition A: MDS1, MDS2 (2 nodes)\n  Partition B: MDS3 (1 node)\n\nQuorum voting:\n  Partition A: 2/3 nodes = HAS QUORUM \u2192 continues operation\n  Partition B: 1/3 nodes = NO QUORUM \u2192 enters read-only mode\n\nPrevention:\n  - Fencing agent (IPMI, PDU) forcibly powers off minority partition\n  - Prevents conflicting writes to shared backend\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#performance-tuning","title":"Performance Tuning","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#client-side-tunables","title":"Client-Side Tunables","text":"<pre><code># /etc/nfsmount.conf or mount options\nmount -t nfs4 -o \\\n  vers=4.2,\\                      # Enable pNFS\n  pnfs,\\                          # Use parallel NFS layouts\n  rsize=1048576,\\                 # 1MB read size\n  wsize=1048576,\\                 # 1MB write size\n  timeo=600,\\                     # 60s timeout\n  retrans=2,\\                     # 2 retransmissions\n  hard,\\                          # Hard mount (don't give up)\n  async,\\                         # Asynchronous I/O\n  ac,\\                            # Attribute caching\n  actimeo=3600 \\                  # 1-hour attribute cache\n  10.10.1.100:/export /mnt/pnfs\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#server-side-tunables","title":"Server-Side Tunables","text":"<pre><code># NFS server threads (per-node)\necho 256 &gt; /proc/sys/sunrpc/nfsd_threads\n\n# Network receive buffers\nsysctl -w net.core.rmem_max=134217728\nsysctl -w net.core.wmem_max=134217728\n\n# NVMe queue depth\necho 1024 &gt; /sys/block/nvme0n1/queue/nr_requests\n\n# Disable CPU frequency scaling (performance mode)\ncpupower frequency-set -g performance\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#monitoring-metrics","title":"Monitoring Metrics","text":"<pre><code>Key metrics to track:\n  - MDS operations/sec (LAYOUTGET, OPEN, CLOSE)\n  - Data server throughput (GB/s per node)\n  - Latency percentiles (p50, p95, p99)\n  - Client cache hit rates\n  - Network utilization (per fabric)\n  - NVMe IOPS and latency\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#implementation-deployment-checklist","title":"Implementation: Deployment Checklist","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-1-network-setup","title":"Phase 1: Network Setup","text":"<ul> <li> Deploy InfiniBand/RoCE fabric</li> <li> Configure storage VLAN with jumbo frames</li> <li> Enable RDMA on all nodes</li> <li> Verify bandwidth with <code>ib_write_bw</code> / <code>ib_read_bw</code></li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-2-storage-node-provisioning","title":"Phase 2: Storage Node Provisioning","text":"<ul> <li> Install NVMe SSDs and verify <code>nvme list</code></li> <li> Create XFS/ZFS filesystems</li> <li> Apply NVMe performance tunings</li> <li> Install <code>nfs-kernel-server</code> with pNFS support</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-3-mds-cluster-setup","title":"Phase 3: MDS Cluster Setup","text":"<ul> <li> Choose clustering backend (DRBD, etcd, etc.)</li> <li> Configure Pacemaker/Corosync or equivalent</li> <li> Set up VIP with failover tests</li> <li> Deploy metadata synchronization</li> <li> Test quorum and fencing</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-4-pnfs-configuration","title":"Phase 4: pNFS Configuration","text":"<ul> <li> Configure pNFS layouts on each storage node</li> <li> Export file systems via NFS4 with pNFS enabled</li> <li> Register data servers with MDS</li> <li> Test layout distribution from clients</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-5-client-deployment","title":"Phase 5: Client Deployment","text":"<ul> <li> Mount pNFS export with optimized parameters</li> <li> Verify parallel I/O with <code>dd</code> or <code>fio</code></li> <li> Test layout recall and coherency</li> <li> Run application workload benchmarks</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-6-production-hardening","title":"Phase 6: Production Hardening","text":"<ul> <li> Set up monitoring (Prometheus + Grafana)</li> <li> Configure alerting for node failures</li> <li> Document failover procedures</li> <li> Schedule regular disaster recovery drills</li> <li> Implement backup strategy</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#real-world-performance","title":"Real-World Performance","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#benchmark-environment","title":"Benchmark Environment","text":"<pre><code>Hardware:\n  - 10x storage nodes (Dell R750)\n  - 4x 7.68TB NVMe per node (Samsung PM9A3)\n  - 100GbE RoCE network\n  - 2x AMD EPYC 7543 per node\n\nWorkload:\n  - FIO sequential read (4MB block size)\n  - 8 clients, 16 threads each\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#results","title":"Results","text":"Metric Value Notes Aggregate Throughput 82 GB/s 10 nodes \u00d7 ~8 GB/s each Per-Client Throughput 10.2 GB/s 82 GB/s / 8 clients Latency (p99) 3.2 ms Network + NVMe + pNFS overhead MDS Load 2,300 ops/s Only layout requests CPU Utilization 35% avg Plenty of headroom <p>Key Takeaway</p> <p>pNFS achieved near-linear scaling across 10 storage nodes. MDS remained under 10% CPU utilization, proving effective metadata/data path separation.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#troubleshooting-guide","title":"Troubleshooting Guide","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#problem-clients-not-using-pnfs-falling-back-to-standard-nfs","title":"Problem: Clients not using pNFS (falling back to standard NFS)","text":"<p>Symptoms: <pre><code># All I/O going through MDS node\nnfsstat -m | grep \"pnfs\"  # Shows \"pnfs: not in use\"\n</code></pre></p> <p>Diagnosis: <pre><code># Check server pNFS support\nnfsstat -s | grep pnfs\n\n# Check client kernel support\ngrep PNFS /boot/config-$(uname -r)  # Should show CONFIG_PNFS_FILE_LAYOUT=m\n</code></pre></p> <p>Solution: - Ensure server exports with <code>pnfs</code> option - Verify client kernel has <code>nfs_layout_nfsv41_files</code> module loaded - Check for layout request denials in <code>/var/log/messages</code></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#problem-high-mds-cpu-usage","title":"Problem: High MDS CPU usage","text":"<p>Symptoms: <pre><code># MDS nodes showing &gt;80% CPU\ntop  # nfsd threads consuming CPU\n</code></pre></p> <p>Diagnosis: <pre><code># Check for excessive LAYOUTGET operations\nnfsstat -s | grep LAYOUTGET\n</code></pre></p> <p>Possible Causes: - Clients not caching layouts (check <code>actimeo</code>) - Frequent layout recalls (check for conflicting access patterns) - Insufficient MDS threads (check <code>nfsd_threads</code>)</p> <p>Solution: <pre><code># Increase client attribute cache timeout\nmount -o remount,actimeo=3600 /mnt/pnfs\n\n# Add more MDS threads\necho 512 &gt; /proc/sys/sunrpc/nfsd_threads\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#problem-uneven-storage-utilization","title":"Problem: Uneven storage utilization","text":"<p>Symptoms: <pre><code># One storage node at 90%, others at 40%\ndf -h /storage/*\n</code></pre></p> <p>Diagnosis: <pre><code># Check file layout distribution\n# (Requires pNFS-aware tooling or manual inspection)\n</code></pre></p> <p>Solution: - Re-stripe files: Use pNFS restripe tools if available - Balance new files: Adjust MDS layout selection algorithm - Add/remove nodes: Trigger cluster rebalancing</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#advanced-topics","title":"Advanced Topics","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#1-hierarchical-storage-management-hsm-with-pnfs","title":"1. Hierarchical Storage Management (HSM) with pNFS","text":"<p>Implement tiered storage by combining: - Hot tier: NVMe-backed pNFS for active data - Warm tier: SATA SSD pNFS for recent data - Cold tier: HDD-based object storage (S3) for archives</p> <p>Layout policy: <pre><code>def select_storage_tier(file_metadata):\n    if file_metadata.access_count &gt; 100:\n        return TIER_NVME\n    elif file_metadata.age_days &lt; 30:\n        return TIER_SSD\n    else:\n        return TIER_HDD\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#2-erasure-coding-for-space-efficiency","title":"2. Erasure Coding for Space Efficiency","text":"<p>Instead of replication (2x-3x overhead), use erasure coding: - Reed-Solomon (8+3): 1.375x overhead for 3-drive fault tolerance - RAID 6 equivalent: Stripe across pNFS with parity - Rebuild time: ~2 hours for 10TB per failed drive</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#3-multi-site-pnfs-replication","title":"3. Multi-Site pNFS Replication","text":"<p>For disaster recovery: <pre><code>Site A (Primary):          Site B (DR):\n  10 storage nodes    \u2192      10 storage nodes\n  Active MDS cluster  \u2192      Standby MDS cluster\n\nAsync replication (rsync/DRBD async or Lustre HSM)\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#conclusion","title":"Conclusion","text":"<p>This pNFS v4.2 architecture provides:</p> <p>\u2705 High throughput: 80+ GB/s aggregate via parallel I/O \u2705 Low latency: &lt;5ms p99 with InfiniBand/RoCE \u2705 High availability: No single points of failure \u2705 Horizontal scalability: Add nodes without downtime \u2705 Operational simplicity: Standard NFS client compatibility</p> <p>Trade-offs: - Complexity: More moving parts than traditional NAS - Data durability: Requires additional replication/erasure coding - Cost: High-speed network and NVMe SSDs increase CapEx</p> <p>Ideal for: - AI/ML training clusters (GPU \u2192 storage throughput) - HPC workloads (parallel file access patterns) - Video rendering farms (large file streaming) - High-frequency trading (low-latency shared storage)</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#references","title":"References","text":"<ul> <li>RFC 8881 - NFSv4.1 Protocol</li> <li>RFC 7862 - NFSv4.2 Protocol</li> <li>Linux pNFS Documentation</li> <li>Lustre pNFS Guide</li> <li>Red Hat: Configuring pNFS</li> </ul> <p>Tags: #pNFS #distributed-storage #NVMe #high-availability #load-balancing #metadata #clustering #InfiniBand #RoCE #parallel-io #file-systems #linux #performance-tuning #scalability</p> <p>Category: Storage, Architecture</p> <p>Have questions or running a similar setup? Open a discussion or reach out.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"journal/","title":"Journal","text":"<p>Time-based log entries, learning notes, and progress updates.</p>"},{"location":"journal/#coming-soon","title":"Coming Soon","text":"<p>This section will contain:</p> <ul> <li>Learning Logs: Daily/weekly learning summaries</li> <li>Project Progress: Implementation updates</li> <li>Experiments: Technical experiments and findings</li> <li>Quick Notes: Short observations and discoveries</li> </ul> <p>Check back soon or watch the repository for updates.</p>"},{"location":"kb/","title":"Knowledge Base","text":"<p>Evergreen reference material, technical documentation, and curated resources.</p>"},{"location":"kb/#coming-soon","title":"Coming Soon","text":"<p>This section will contain:</p> <ul> <li>System Design Patterns: Reusable architectural patterns</li> <li>Protocol References: Detailed protocol documentation</li> <li>Tool Guides: Configuration and usage guides</li> <li>Troubleshooting Playbooks: Common issues and solutions</li> <li>Performance Baselines: Benchmark data and analysis</li> </ul> <p>Check back soon or watch the repository for updates.</p>"},{"location":"kubernetes/","title":"Kubernetes CKA Mastery","text":"<p>Complete hands-on guide to Kubernetes administration and CKA certification</p>"},{"location":"kubernetes/#about-the-cka-exam","title":"\ud83c\udfaf About the CKA Exam","text":"<p>The Certified Kubernetes Administrator (CKA) certification demonstrates proficiency in Kubernetes cluster administration, troubleshooting, and operations.</p>"},{"location":"kubernetes/#exam-details","title":"Exam Details","text":"<ul> <li>Duration: 2 hours</li> <li>Format: ~17 performance-based tasks (100% hands-on terminal work)</li> <li>Pass Score: 66%</li> <li>Cost: $445 (includes one free retake)</li> <li>Environment: Remote proctored, browser-based terminal</li> </ul>"},{"location":"kubernetes/#exam-domains-weights","title":"Exam Domains &amp; Weights","text":"<pre><code>pie title CKA Exam Domain Distribution\n    \"Troubleshooting\" : 30\n    \"Cluster Architecture\" : 25\n    \"Services &amp; Networking\" : 20\n    \"Workloads &amp; Scheduling\" : 15\n    \"Storage\" : 10</code></pre> Domain Weight Focus Areas Troubleshooting 30% Cluster/node issues, application debugging, monitoring Cluster Architecture 25% Installation, upgrades, RBAC, security, CRDs Services &amp; Networking 20% Services, Ingress, Gateway API, Network Policies Workloads &amp; Scheduling 15% Deployments, scheduling, pod configuration Storage 10% PV/PVC, ConfigMaps, Secrets, StorageClasses"},{"location":"kubernetes/#learning-path","title":"\ud83d\udcda Learning Path","text":"<p>This series covers 22 comprehensive posts organized into 7 phases, following the optimal learning sequence for CKA exam success.</p> <pre><code>graph TD\n    A[Phase 1: Foundations] --&gt; B[Phase 2: Workloads]\n    B --&gt; C[Phase 3: Networking]\n    C --&gt; D[Phase 4: Storage]\n    D --&gt; E[Phase 5: Security]\n    E --&gt; F[Phase 6: Advanced Config]\n    F --&gt; G[Phase 7: Troubleshooting]\n\n    A --&gt; A1[Architecture]\n    A --&gt; A2[Lab Setup]\n    A --&gt; A3[kubectl Basics]\n    A --&gt; A4[YAML &amp; Objects]\n    A --&gt; A5[Namespaces]\n\n    B --&gt; B1[Pods]\n    B --&gt; B2[Deployments]\n    B --&gt; B3[Scheduling]\n\n    C --&gt; C1[Services]\n    C --&gt; C2[Ingress/Gateway]\n    C --&gt; C3[Network Policies]\n    C --&gt; C4[DNS]\n\n    D --&gt; D1[PV/PVC]\n    D --&gt; D2[ConfigMaps/Secrets]\n\n    E --&gt; E1[RBAC]\n    E --&gt; E2[Security Contexts]\n    E --&gt; E3[CRDs/Operators]\n\n    F --&gt; F1[Helm]\n    F --&gt; F2[Kustomize]\n\n    G --&gt; G1[Cluster Troubleshooting]\n    G --&gt; G2[App Troubleshooting]\n    G --&gt; G3[Monitoring]\n\n    style A fill:#e1f5ff\n    style B fill:#fff4e1\n    style C fill:#e8f5e8\n    style D fill:#f3e5f5\n    style E fill:#ffe5e5\n    style F fill:#fff9e5\n    style G fill:#ffe5f0</code></pre>"},{"location":"kubernetes/#phase-1-foundations-5-posts","title":"\ud83c\udfd7\ufe0f Phase 1: Foundations (5 posts)","text":"<p>Build your foundational knowledge of Kubernetes architecture and essential tools.</p>"},{"location":"kubernetes/#1-kubernetes-architecture-fundamentals","title":"1. Kubernetes Architecture Fundamentals","text":"<p>Control plane components, worker nodes, etcd, API server, scheduler, controller manager Tags: <code>kubernetes</code> <code>architecture</code> <code>fundamentals</code> <code>cka-prep</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#2-setting-up-your-kubernetes-lab-environment","title":"2. Setting Up Your Kubernetes Lab Environment","text":"<p>kubeadm, Minikube, kind, kubectl installation, kubeconfig management Tags: <code>kubernetes</code> <code>installation</code> <code>lab-setup</code> <code>kubeadm</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#3-kubectl-essentials-your-kubernetes-swiss-army-knife","title":"3. kubectl Essentials: Your Kubernetes Swiss Army Knife","text":"<p>Master kubectl commands, aliases, output formats, context switching, imperative vs declarative Tags: <code>kubernetes</code> <code>kubectl</code> <code>cli</code> <code>basics</code> Domain: All (foundational skill)</p>"},{"location":"kubernetes/#4-understanding-kubernetes-objects-and-yaml-manifests","title":"4. Understanding Kubernetes Objects and YAML Manifests","text":"<p>API objects, YAML syntax, metadata, spec, status, labels, annotations, selectors Tags: <code>kubernetes</code> <code>yaml</code> <code>objects</code> <code>manifests</code> Domain: All (foundational skill)</p>"},{"location":"kubernetes/#5-namespaces-and-resource-quotas","title":"5. Namespaces and Resource Quotas","text":"<p>Namespace isolation, resource quotas, limit ranges, default namespace management Tags: <code>kubernetes</code> <code>namespaces</code> <code>resource-management</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#phase-2-workloads-scheduling-3-posts","title":"\u2699\ufe0f Phase 2: Workloads &amp; Scheduling (3 posts)","text":"<p>Master pod management, deployments, and advanced scheduling techniques.</p>"},{"location":"kubernetes/#6-pods-the-atomic-unit-of-kubernetes","title":"6. Pods: The Atomic Unit of Kubernetes","text":"<p>Pod lifecycle, init containers, sidecar patterns, multi-container communication Tags: <code>kubernetes</code> <code>pods</code> <code>workloads</code> <code>containers</code> Domain: Workloads &amp; Scheduling (15%)</p>"},{"location":"kubernetes/#7-deployments-replicasets-and-rolling-updates","title":"7. Deployments, ReplicaSets, and Rolling Updates","text":"<p>Deployments, ReplicaSets, DaemonSets, StatefulSets, rollouts, rollback strategies Tags: <code>kubernetes</code> <code>deployments</code> <code>replicasets</code> <code>workloads</code> Domain: Workloads &amp; Scheduling (15%)</p>"},{"location":"kubernetes/#8-advanced-scheduling-taints-tolerations-and-affinity","title":"8. Advanced Scheduling: Taints, Tolerations, and Affinity","text":"<p>Node selectors, taints/tolerations, node/pod affinity, anti-affinity, priority classes Tags: <code>kubernetes</code> <code>scheduling</code> <code>advanced</code> <code>affinity</code> Domain: Workloads &amp; Scheduling (15%)</p>"},{"location":"kubernetes/#phase-3-services-networking-4-posts","title":"\ud83c\udf10 Phase 3: Services &amp; Networking (4 posts)","text":"<p>Deep dive into Kubernetes networking, service discovery, and traffic management.</p>"},{"location":"kubernetes/#9-kubernetes-services-exposing-your-applications","title":"9. Kubernetes Services: Exposing Your Applications","text":"<p>ClusterIP, NodePort, LoadBalancer, ExternalName, service discovery, endpoints Tags: <code>kubernetes</code> <code>services</code> <code>networking</code> <code>service-discovery</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#10-ingress-and-gateway-api-modern-traffic-management","title":"10. Ingress and Gateway API: Modern Traffic Management","text":"<p>Ingress controllers, Ingress rules, Gateway API (GatewayClass, Gateway, HTTPRoute) Tags: <code>kubernetes</code> <code>ingress</code> <code>gateway-api</code> <code>traffic-management</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#11-network-policies-securing-pod-communication","title":"11. Network Policies: Securing Pod Communication","text":"<p>NetworkPolicy resources, ingress/egress rules, pod/namespace selectors, isolation Tags: <code>kubernetes</code> <code>network-policies</code> <code>security</code> <code>networking</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#12-coredns-and-service-discovery-deep-dive","title":"12. CoreDNS and Service Discovery Deep Dive","text":"<p>CoreDNS configuration, DNS for Services and Pods, troubleshooting DNS issues Tags: <code>kubernetes</code> <code>dns</code> <code>coredns</code> <code>service-discovery</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#phase-4-storage-2-posts","title":"\ud83d\udcbe Phase 4: Storage (2 posts)","text":"<p>Understand persistent storage and configuration management in Kubernetes.</p>"},{"location":"kubernetes/#13-persistent-volumes-and-claims-stateful-storage","title":"13. Persistent Volumes and Claims: Stateful Storage","text":"<p>PV, PVC, StorageClass, access modes, reclaim policies, dynamic provisioning Tags: <code>kubernetes</code> <code>storage</code> <code>persistent-volumes</code> <code>stateful</code> Domain: Storage (10%)</p>"},{"location":"kubernetes/#14-configmaps-secrets-and-volume-mounts","title":"14. ConfigMaps, Secrets, and Volume Mounts","text":"<p>ConfigMaps, Secrets, volume mounts, environment variables, projected volumes Tags: <code>kubernetes</code> <code>configmaps</code> <code>secrets</code> <code>configuration</code> Domain: Storage (10%)</p>"},{"location":"kubernetes/#phase-5-security-configuration-3-posts","title":"\ud83d\udd12 Phase 5: Security &amp; Configuration (3 posts)","text":"<p>Secure your cluster with RBAC, security contexts, and extensibility.</p>"},{"location":"kubernetes/#15-rbac-role-based-access-control","title":"15. RBAC: Role-Based Access Control","text":"<p>Roles, ClusterRoles, RoleBindings, ClusterRoleBindings, ServiceAccounts Tags: <code>kubernetes</code> <code>rbac</code> <code>security</code> <code>access-control</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#16-security-contexts-and-pod-security-standards","title":"16. Security Contexts and Pod Security Standards","text":"<p>SecurityContext, Pod Security Admission, privileged containers, capabilities, PSS Tags: <code>kubernetes</code> <code>security</code> <code>pod-security</code> <code>hardening</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#17-custom-resources-and-operators-crds","title":"17. Custom Resources and Operators (CRDs)","text":"<p>CustomResourceDefinitions, custom controllers, Operators, CRD inspection Tags: <code>kubernetes</code> <code>crds</code> <code>operators</code> <code>extensibility</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#phase-6-advanced-configuration-2-posts","title":"\ud83d\udd27 Phase 6: Advanced Configuration (2 posts)","text":"<p>Master Helm and Kustomize for production-grade configuration management.</p>"},{"location":"kubernetes/#18-helm-kubernetes-package-manager","title":"18. Helm: Kubernetes Package Manager","text":"<p>Helm charts, templating, values files, releases, hooks, chart repositories Tags: <code>kubernetes</code> <code>helm</code> <code>package-management</code> <code>charts</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#19-kustomize-template-free-configuration-management","title":"19. Kustomize: Template-Free Configuration Management","text":"<p>Kustomize bases, overlays, patches, transformers, generators, GitOps patterns Tags: <code>kubernetes</code> <code>kustomize</code> <code>configuration</code> <code>gitops</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#phase-7-troubleshooting-monitoring-3-posts","title":"\ud83d\udd0d Phase 7: Troubleshooting &amp; Monitoring (3 posts)","text":"<p>Become an expert at diagnosing and resolving Kubernetes issues.</p>"},{"location":"kubernetes/#20-troubleshooting-clusters-nodes-and-components","title":"20. Troubleshooting Clusters, Nodes, and Components","text":"<p>Node issues, control plane debugging, certificate problems, etcd health checks Tags: <code>kubernetes</code> <code>troubleshooting</code> <code>debugging</code> <code>cluster-health</code> Domain: Troubleshooting (30%)</p>"},{"location":"kubernetes/#21-application-troubleshooting-and-log-analysis","title":"21. Application Troubleshooting and Log Analysis","text":"<p>Pod debugging, container logs, exec commands, ephemeral containers, event analysis Tags: <code>kubernetes</code> <code>troubleshooting</code> <code>logs</code> <code>debugging</code> Domain: Troubleshooting (30%)</p>"},{"location":"kubernetes/#22-monitoring-metrics-and-resource-management","title":"22. Monitoring, Metrics, and Resource Management","text":"<p>Metrics Server, resource requests/limits, HPA, VPA, monitoring stack integration Tags: <code>kubernetes</code> <code>monitoring</code> <code>metrics</code> <code>autoscaling</code> Domain: Troubleshooting (30%)</p>"},{"location":"kubernetes/#how-to-use-this-series","title":"\ud83d\udcd6 How to Use This Series","text":""},{"location":"kubernetes/#recommended-study-approach","title":"Recommended Study Approach","text":"<ol> <li>Follow the Order: Posts are sequenced for optimal learning progression</li> <li>Hands-On Practice: Set up a lab environment (Post 2) and practice every command</li> <li>Take Notes: Create your own command cheat sheets as you progress</li> <li>Review Diagrams: Study the architecture diagrams to understand component relationships</li> <li>Do the Exercises: Complete practice tasks at the end of each post</li> <li>Cross-Reference: Use links between posts to review related concepts</li> </ol>"},{"location":"kubernetes/#study-timeline","title":"Study Timeline","text":"<ul> <li>Intensive: 4-6 weeks (1 post per day)</li> <li>Standard: 8-12 weeks (2-3 posts per week)</li> <li>Relaxed: 3-4 months (1-2 posts per week)</li> </ul>"},{"location":"kubernetes/#exam-preparation-tips","title":"Exam Preparation Tips","text":"<p>\u2705 Do: - Practice in a terminal environment (exam is 100% command-line) - Use <code>kubectl</code> imperative commands for speed - Master <code>kubectl explain</code> and <code>-h</code> flags for in-exam reference - Time yourself on practice exercises - Focus heavily on Troubleshooting (30% weight)</p> <p>\u274c Don't: - Memorize YAML templates (use <code>kubectl</code> generators instead) - Ignore troubleshooting topics (highest exam weight) - Skip hands-on practice (reading alone is insufficient) - Forget about time management (2 hours goes fast)</p>"},{"location":"kubernetes/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<p>Before starting this series, you should have:</p> <ul> <li>Basic understanding of Linux command line</li> <li>Familiarity with containerization concepts (Docker)</li> <li>Access to a Linux/macOS machine or Windows with WSL2</li> <li>Willingness to practice hands-on (not just read)</li> </ul>"},{"location":"kubernetes/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>Official CKA Exam Page</li> <li>Kubernetes Official Documentation</li> <li>kubectl Command Reference</li> <li>CKA Curriculum (Official)</li> </ul>"},{"location":"kubernetes/#ready-to-start","title":"\ud83d\ude80 Ready to Start?","text":"<p>Begin your journey with Post 1: Kubernetes Architecture Fundamentals and work through the series systematically.</p> <p>Good luck with your CKA certification! \ud83c\udf93</p> <p>Last Updated: 2025-11-10 Series Status: In Progress (Post 1 available) Total Posts: 22 planned</p>"},{"location":"principles/","title":"Principles","text":"<p>Engineering principles, design philosophies, and decision-making frameworks.</p>"},{"location":"principles/#coming-soon","title":"Coming Soon","text":"<p>This section will explore:</p> <ul> <li>Architecture Principles: Foundational design guidelines</li> <li>Performance Principles: Optimization philosophies</li> <li>Reliability Principles: Building resilient systems</li> <li>Scalability Principles: Growing systems effectively</li> <li>Simplicity Principles: Managing complexity</li> </ul> <p>Check back soon or watch the repository for updates.</p>"},{"location":"blog/archive/2025/","title":"November 2025","text":""},{"location":"blog/category/kubernetes/","title":"Kubernetes","text":""},{"location":"blog/category/cli/","title":"CLI","text":""},{"location":"blog/category/architecture/","title":"Architecture","text":""},{"location":"blog/category/infrastructure/","title":"Infrastructure","text":""},{"location":"blog/category/storage/","title":"Storage","text":""}]}