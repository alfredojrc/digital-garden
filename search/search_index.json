{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Digital Garden","text":"<p>A living knowledge base for distributed systems, storage architecture, and infrastructure engineering</p>"},{"location":"#latest-posts","title":"\ud83d\udcdd Latest Posts","text":"<p>\u27a1\ufe0f View All Posts</p>"},{"location":"#kubectl-essentials-your-kubernetes-swiss-army-knife","title":"kubectl Essentials: Your Kubernetes Swiss Army Knife","text":"<p>Kubernetes \u00b7 13 min read</p> <p>Master kubectl commands, output formats, and productivity patterns essential for CKA exam success. Learn imperative vs declarative approaches, JSONPath queries, context management, and time-saving aliases for Kubernetes cluster management.</p> <p>Topics: kubernetes, k8s, cka-prep, kubectl</p> <p>Read more \u2192</p>"},{"location":"#setting-up-your-kubernetes-lab-environment","title":"Setting Up Your Kubernetes Lab Environment","text":"<p>Kubernetes \u00b7 Infrastructure \u00b7 12 min read</p> <p>Complete guide to setting up Kubernetes lab environments for CKA preparation. Covers kubeadm cluster setup, Minikube for local development, kind for testing, kubectl installation, and kubeconfig management with practical examples.</p> <p>Topics: kubernetes, k8s, cka-prep, kubeadm, kubectl, minikube</p> <p>Read more \u2192</p>"},{"location":"#kubernetes-architecture-fundamentals","title":"Kubernetes Architecture Fundamentals","text":"<p>Kubernetes \u00b7 Architecture \u00b7 15 min read</p> <p>Deep dive into Kubernetes cluster architecture, control plane components, and the distributed systems design that powers container orchestration at scale. Essential foundations for CKA certification with comprehensive diagrams, kubectl commands, and hands-on practice exercises.</p> <p>Topics: kubernetes, k8s, cka-prep, architecture, control-plane, kubectl</p> <p>Read more \u2192</p>"},{"location":"#high-performance-pnfs-v42-distributed-storage-architecture","title":"High-Performance pNFS v4.2 Distributed Storage Architecture","text":"<p>Storage \u00b7 Architecture \u00b7 12 min read</p> <p>A deep dive into building a clustered, high-availability parallel NFS storage system with load-balanced metadata servers, NVMe-backed storage nodes, and low-latency interconnects. Features production-grade architecture with InfiniBand/RoCE fabrics, active-active MDS clustering, and parallel data paths achieving 28 GB/s aggregate throughput.</p> <p>Topics: pNFS v4.2, distributed storage, NVMe, InfiniBand, RoCE, high availability, load balancing, metadata clustering</p> <p>Read more \u2192</p>"},{"location":"#browse-by-theme","title":"\ud83d\uddc2\ufe0f Browse by Theme","text":"<ul> <li> <p> Kubernetes CKA Mastery</p> <p>Complete CKA certification prep with 22 comprehensive posts</p> <p>Explore Kubernetes \u2192</p> </li> <li> <p> AI &amp; Automation</p> <p>Agents, MCP servers, tool orchestration, LLM workflows</p> <p>Explore AI \u2192</p> </li> <li> <p> Cloud Infrastructure</p> <p>GCP, Azure, AWS, multi-cloud architectures</p> <p>Explore Cloud \u2192</p> </li> <li> <p> Infrastructure as Code</p> <p>Terraform, Ansible, GitOps, automation</p> <p>Explore IaC \u2192</p> </li> <li> <p> On-Premise Systems</p> <p>Bare metal, datacenter, networking, storage</p> <p>Explore On-Prem \u2192</p> </li> <li> <p> Cybersecurity</p> <p>Security architecture, hardening, compliance</p> <p>Explore Security \u2192</p> </li> <li> <p> Storage &amp; Networking</p> <p>File systems, protocols, high-performance I/O</p> <p>Explore Storage \u2192</p> </li> </ul>"},{"location":"#additional-resources","title":"\ud83e\udded Additional Resources","text":"<ul> <li>Knowledge Base: Curated reference material and evergreen documentation</li> <li>Principles: Engineering principles and design patterns</li> <li>Journal: Progress logs and learning notes</li> <li>Tags: Browse all content by tag</li> </ul> <p>This garden grows continuously \u00b7 Follow on GitHub \u00b7 RSS Feed</p>"},{"location":"blog/","title":"Blog","text":"<p>Technical deep-dives into distributed systems, storage architecture, and infrastructure engineering.</p>"},{"location":"blog/#navigate","title":"Navigate","text":"<ul> <li>Browse by Tags for topic-based exploration</li> <li>View the Archive for chronological browsing</li> <li>Filter by Categories below</li> </ul> <p>All posts include estimated read times and are optimized for both technical depth and practical application.</p>"},{"location":"blog/tags/","title":"Tag Index","text":"<p>Browse all posts by tag. Tags provide fine-grained topic classification across multiple dimensions.</p>"},{"location":"blog/tags/#tag:infiniband","title":"InfiniBand","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:nvme","title":"NVMe","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:roce","title":"RoCE","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:architecture","title":"architecture","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> </ul>"},{"location":"blog/tags/#tag:cka-prep","title":"cka-prep","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Kubernetes Namespaces and Resource Quotas          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:clustering","title":"clustering","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:command-line","title":"command-line","text":"<ul> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:control-plane","title":"control-plane","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> </ul>"},{"location":"blog/tags/#tag:distributed-storage","title":"distributed-storage","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:high-availability","title":"high-availability","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:k8s","title":"k8s","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Kubernetes Namespaces and Resource Quotas          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:kubeadm","title":"kubeadm","text":"<ul> <li>            Setting Up Your Kubernetes Lab Environment          </li> </ul>"},{"location":"blog/tags/#tag:kubectl","title":"kubectl","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:kubernetes","title":"kubernetes","text":"<ul> <li>            Kubernetes Architecture Fundamentals          </li> <li>            Kubernetes Namespaces and Resource Quotas          </li> <li>            Setting Up Your Kubernetes Lab Environment          </li> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> <li>            kubectl Essentials: Your Kubernetes Swiss Army Knife          </li> </ul>"},{"location":"blog/tags/#tag:labels","title":"labels","text":"<ul> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> </ul>"},{"location":"blog/tags/#tag:load-balancing","title":"load-balancing","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:manifests","title":"manifests","text":"<ul> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> </ul>"},{"location":"blog/tags/#tag:metadata","title":"metadata","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:minikube","title":"minikube","text":"<ul> <li>            Setting Up Your Kubernetes Lab Environment          </li> </ul>"},{"location":"blog/tags/#tag:namespaces","title":"namespaces","text":"<ul> <li>            Kubernetes Namespaces and Resource Quotas          </li> </ul>"},{"location":"blog/tags/#tag:objects","title":"objects","text":"<ul> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> </ul>"},{"location":"blog/tags/#tag:pnfs","title":"pNFS","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:parallel-io","title":"parallel-io","text":"<ul> <li>            High-Performance pNFS v4.2 Distributed Storage Architecture          </li> </ul>"},{"location":"blog/tags/#tag:quotas","title":"quotas","text":"<ul> <li>            Kubernetes Namespaces and Resource Quotas          </li> </ul>"},{"location":"blog/tags/#tag:resource-management","title":"resource-management","text":"<ul> <li>            Kubernetes Namespaces and Resource Quotas          </li> </ul>"},{"location":"blog/tags/#tag:selectors","title":"selectors","text":"<ul> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> </ul>"},{"location":"blog/tags/#tag:yaml","title":"yaml","text":"<ul> <li>            Understanding Kubernetes Objects and YAML Manifests          </li> </ul>"},{"location":"blog/tags/#tag-descriptions","title":"Tag Descriptions","text":"<ul> <li>pNFS: Parallel NFS protocol and implementations</li> <li>distributed-storage: Multi-node storage architectures</li> <li>NVMe: Non-Volatile Memory Express technologies</li> <li>high-availability: HA clustering and failover systems</li> <li>load-balancing: Traffic distribution and request routing</li> <li>metadata: Metadata server design and optimization</li> <li>clustering: Cluster management and coordination</li> <li>InfiniBand: InfiniBand networking and RDMA</li> <li>RoCE: RDMA over Converged Ethernet</li> <li>parallel-io: Parallel I/O patterns and optimization</li> <li>file-systems: File system design and internals</li> <li>linux: Linux kernel and system programming</li> <li>performance-tuning: System optimization techniques</li> <li>scalability: Scaling strategies and patterns</li> </ul>"},{"location":"blog/2025/11/11/kubectl-essentials/","title":"kubectl Essentials: Your Kubernetes Swiss Army Knife","text":"<p>Master kubectl for CKA exam success. Learn imperative commands for speed, output formats for precision, and productivity patterns that save critical exam minutes.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#overview","title":"Overview","text":"<p>kubectl is the command-line interface to Kubernetes and your primary tool during the CKA exam. While the exam allows access to official documentation, proficiency with kubectl commands determines whether you finish in time.</p> <p>CKA Exam Domain: All domains (kubectl is used for every task)</p> <p>Key Insight: CKA exam success correlates directly with kubectl speed. Candidates who master imperative commands and output formats consistently score higher and finish with time to spare.</p> <p>What You'll Learn: - Essential kubectl commands by category - Imperative vs declarative approaches for exam efficiency - Output formats and JSONPath for data extraction - Context and namespace management patterns - kubectl explain for in-exam documentation - Time-saving aliases and autocomplete workflows</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#command-categories-overview","title":"Command Categories Overview","text":"<p>kubectl commands follow functional patterns that map to exam task types.</p> <pre><code>graph TB\n    subgraph \"Resource Lifecycle\"\n        CREATE[Create/Generate&lt;br/&gt;run, create, expose]\n        READ[Inspect&lt;br/&gt;get, describe, logs]\n        UPDATE[Modify&lt;br/&gt;edit, patch, scale, set]\n        DELETE[Remove&lt;br/&gt;delete]\n    end\n\n    subgraph \"Debugging &amp; Troubleshooting\"\n        EXEC[Execute&lt;br/&gt;exec, cp]\n        DEBUG[Debug&lt;br/&gt;debug, logs, port-forward]\n        METRICS[Metrics&lt;br/&gt;top]\n    end\n\n    subgraph \"Configuration &amp; Context\"\n        CONFIG[Configure&lt;br/&gt;config, explain]\n        APPLY[Apply&lt;br/&gt;apply, replace]\n        ROLLOUT[Rollouts&lt;br/&gt;rollout, scale]\n    end\n\n    CREATE --&gt; UPDATE\n    UPDATE --&gt; ROLLOUT\n    READ --&gt; DEBUG\n    DEBUG --&gt; EXEC\n    CONFIG --&gt; APPLY\n\n    style CREATE fill:#e1f5ff\n    style READ fill:#e8f5e8\n    style UPDATE fill:#fff4e1\n    style DELETE fill:#ffe5e5\n    style DEBUG fill:#f5e1ff</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#essential-commands-by-category","title":"Essential Commands by Category","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#resource-creation-commands","title":"Resource Creation Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-run-pods","title":"kubectl run (Pods)","text":"<p>Purpose: Create pods imperatively - fastest method for simple pods</p> <pre><code># Basic pod creation\nkubectl run nginx --image=nginx\n\n# Pod with port specification\nkubectl run nginx --image=nginx --port=80\n\n# Pod with labels\nkubectl run nginx --image=nginx --labels=\"app=web,tier=frontend\"\n\n# Pod with environment variables\nkubectl run nginx --image=nginx --env=\"DB_HOST=mysql\" --env=\"DB_PORT=3306\"\n\n# Generate YAML without creating (CRITICAL for exam)\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n</code></pre> <p>Exam Pattern: Use <code>--dry-run=client -o yaml</code> to generate templates, then edit as needed.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-create-workloads","title":"kubectl create (Workloads)","text":"<p>Purpose: Generate deployments, jobs, services with imperative commands</p> <pre><code># Deployment creation\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Job creation\nkubectl create job hello --image=busybox:1.28 -- echo \"Hello World\"\n\n# CronJob creation\nkubectl create cronjob hello \\\n  --image=busybox:1.28 \\\n  --schedule=\"*/5 * * * *\" \\\n  -- /bin/sh -c \"date; echo Hello from CronJob\"\n\n# Service creation\nkubectl create service clusterip my-service --tcp=8080:80\nkubectl create service nodeport my-service --tcp=8080:80 --node-port=30080\n\n# ConfigMap from literals\nkubectl create configmap app-config \\\n  --from-literal=env=production \\\n  --from-literal=debug=false\n\n# Secret creation\nkubectl create secret generic db-secret \\\n  --from-literal=username=admin \\\n  --from-literal=password=secretpass\n\n# All with YAML generation\nkubectl create deployment webapp --image=nginx --dry-run=client -o yaml &gt; deploy.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-expose-services","title":"kubectl expose (Services)","text":"<p>Purpose: Expose existing resources as services</p> <pre><code># Expose pod\nkubectl expose pod nginx --port=80 --type=NodePort\n\n# Expose deployment\nkubectl expose deployment webapp --port=80 --target-port=8080 --type=LoadBalancer\n\n# Expose with specific name\nkubectl expose deployment webapp --port=80 --name=web-service --type=ClusterIP\n\n# Generate service YAML\nkubectl expose deployment webapp --port=80 --dry-run=client -o yaml &gt; service.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#resource-inspection-commands","title":"Resource Inspection Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-get-list-resources","title":"kubectl get (List Resources)","text":"<p>Purpose: Query cluster state - most frequently used command</p> <pre><code># Basic resource listing\nkubectl get pods                        # Current namespace\nkubectl get pods -A                     # All namespaces\nkubectl get pods -n kube-system        # Specific namespace\nkubectl get all                         # All resources in namespace\n\n# Wide output (additional columns)\nkubectl get pods -o wide                # Shows IP, Node, etc.\nkubectl get nodes -o wide              # Shows internal IP, OS, etc.\n\n# Show labels\nkubectl get pods --show-labels\n\n# Filter by labels\nkubectl get pods -l app=nginx\nkubectl get pods -l 'env in (dev,staging)'\nkubectl get pods -l app=nginx,tier!=frontend\n\n# Multiple resource types\nkubectl get pods,services,deployments\nkubectl get deploy,rs,pods\n</code></pre> <p>Output Formats (covered in detail later): - <code>-o wide</code> - Additional columns - <code>-o yaml</code> - Full YAML representation - <code>-o json</code> - Full JSON representation - <code>-o name</code> - Resource names only - <code>-o custom-columns</code> - User-defined columns - <code>-o jsonpath</code> - JSONPath expressions</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-describe-detailed-information","title":"kubectl describe (Detailed Information)","text":"<p>Purpose: Get detailed resource information with events</p> <pre><code># Describe resources\nkubectl describe pod nginx\nkubectl describe node worker-1\nkubectl describe deployment webapp\nkubectl describe service my-service\n\n# Describe from file\nkubectl describe -f deployment.yaml\n\n# Common use case: debugging\nkubectl describe pod failing-pod  # Check Events section for issues\n</code></pre> <p>Key Information in describe Output: - Events: Recent state changes, errors, scheduling decisions - Status: Current resource state - Spec: Resource configuration - Conditions: Health checks and readiness</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#resource-modification-commands","title":"Resource Modification Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-edit-interactive-editing","title":"kubectl edit (Interactive Editing)","text":"<p>Purpose: Edit resources in your default editor</p> <pre><code># Edit pod\nkubectl edit pod nginx\n\n# Edit deployment\nkubectl edit deployment webapp\n\n# Edit with specific editor\nKUBE_EDITOR=\"vim\" kubectl edit service my-service\n</code></pre> <p>Exam Tip: <code>kubectl edit</code> opens full resource YAML. Use with caution - easy to accidentally modify important fields. Prefer <code>kubectl patch</code> or <code>kubectl set</code> for targeted changes.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-patch-partial-updates","title":"kubectl patch (Partial Updates)","text":"<p>Purpose: Update specific fields without full resource replacement</p> <pre><code># Update image\nkubectl patch pod nginx -p '{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"image\":\"nginx:1.21\"}]}}'\n\n# Scale using patch\nkubectl patch deployment webapp -p '{\"spec\":{\"replicas\":5}}'\n\n# Strategic merge patch (default)\nkubectl patch deployment webapp --type=strategic -p '{\"spec\":{\"replicas\":3}}'\n\n# JSON patch\nkubectl patch deployment webapp --type=json -p='[{\"op\": \"replace\", \"path\": \"/spec/replicas\", \"value\":5}]'\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-scale-replica-management","title":"kubectl scale (Replica Management)","text":"<p>Purpose: Change replica count for deployments, replica sets</p> <pre><code># Scale deployment\nkubectl scale deployment webapp --replicas=5\n\n# Scale replica set\nkubectl scale rs my-replicaset --replicas=3\n\n# Scale from file\nkubectl scale --replicas=3 -f deployment.yaml\n\n# Conditional scaling\nkubectl scale deployment webapp --current-replicas=3 --replicas=5\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-set-update-resource-fields","title":"kubectl set (Update Resource Fields)","text":"<p>Purpose: Update specific resource fields with simple syntax</p> <pre><code># Update image\nkubectl set image deployment/webapp nginx=nginx:1.21\nkubectl set image deployment/webapp nginx=nginx:1.21 --record\n\n# Update resources\nkubectl set resources deployment webapp \\\n  --limits=cpu=200m,memory=512Mi \\\n  --requests=cpu=100m,memory=256Mi\n\n# Update service account\nkubectl set serviceaccount deployment webapp my-service-account\n\n# Update selector\nkubectl set selector service my-service app=nginx,tier=frontend\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#deployment-management-commands","title":"Deployment Management Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-rollout-deployment-updates","title":"kubectl rollout (Deployment Updates)","text":"<p>Purpose: Manage deployment rollouts and history</p> <pre><code># Check rollout status\nkubectl rollout status deployment/webapp\nkubectl rollout status deployment/webapp --watch\n\n# View rollout history\nkubectl rollout history deployment/webapp\nkubectl rollout history deployment/webapp --revision=3\n\n# Undo rollout (rollback)\nkubectl rollout undo deployment/webapp                    # Rollback to previous\nkubectl rollout undo deployment/webapp --to-revision=2    # Rollback to specific\n\n# Restart deployment (rolling restart)\nkubectl rollout restart deployment/webapp\n\n# Pause/Resume rollout\nkubectl rollout pause deployment/webapp\nkubectl rollout resume deployment/webapp\n</code></pre> <p>Exam Scenario Flow: <pre><code>sequenceDiagram\n    participant User\n    participant Deployment\n    participant ReplicaSet\n    participant Pods\n\n    User-&gt;&gt;Deployment: kubectl set image deploy/webapp nginx=nginx:1.21\n    Deployment-&gt;&gt;ReplicaSet: Create new ReplicaSet (nginx:1.21)\n    ReplicaSet-&gt;&gt;Pods: Create new pods gradually\n\n    Note over Deployment,Pods: Rolling update in progress\n\n    User-&gt;&gt;Deployment: kubectl rollout status deploy/webapp\n    Deployment--&gt;&gt;User: Waiting for rollout to finish...\n\n    alt Update fails\n        User-&gt;&gt;Deployment: kubectl rollout undo deploy/webapp\n        Deployment-&gt;&gt;ReplicaSet: Scale up old ReplicaSet\n        ReplicaSet-&gt;&gt;Pods: Create pods with old image\n    else Update succeeds\n        Deployment-&gt;&gt;ReplicaSet: Scale down old ReplicaSet\n        ReplicaSet-&gt;&gt;Pods: Terminate old pods\n    end\n\n    User-&gt;&gt;Deployment: kubectl rollout history deploy/webapp\n    Deployment--&gt;&gt;User: Show revision history</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#debugging-commands","title":"Debugging Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-logs-container-logs","title":"kubectl logs (Container Logs)","text":"<p>Purpose: View container stdout/stderr logs</p> <pre><code># Basic logs\nkubectl logs pod-name\nkubectl logs pod-name -c container-name        # Multi-container pods\n\n# Follow logs (stream)\nkubectl logs -f pod-name\n\n# Previous container instance (after crash)\nkubectl logs pod-name --previous\nkubectl logs pod-name -c container-name --previous\n\n# Logs from deployment\nkubectl logs deployment/webapp\nkubectl logs deployment/webapp -c nginx\n\n# Logs with labels\nkubectl logs -l app=nginx                      # All pods with label\nkubectl logs -f -l app=nginx --all-containers  # Stream all containers\n\n# Tail last N lines\nkubectl logs pod-name --tail=50\nkubectl logs pod-name --since=1h              # Last hour\nkubectl logs pod-name --since-time=2024-01-01T00:00:00Z\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-exec-execute-commands","title":"kubectl exec (Execute Commands)","text":"<p>Purpose: Run commands inside containers</p> <pre><code># Single command\nkubectl exec pod-name -- ls /app\nkubectl exec pod-name -- env\nkubectl exec pod-name -- cat /etc/resolv.conf\n\n# Interactive shell\nkubectl exec -it pod-name -- /bin/bash\nkubectl exec -it pod-name -- /bin/sh\n\n# Multi-container pod\nkubectl exec -it pod-name -c container-name -- /bin/bash\n\n# Deployment exec (first pod)\nkubectl exec deployment/webapp -- env\nkubectl exec -it deployment/webapp -- /bin/bash\n</code></pre> <p>Common Exam Patterns: <pre><code># Check pod networking\nkubectl exec -it pod-name -- ping google.com\nkubectl exec -it pod-name -- nslookup kubernetes.default\n\n# Verify volume mounts\nkubectl exec pod-name -- ls /mnt/data\n\n# Test service connectivity\nkubectl exec -it pod-name -- curl http://service-name:8080\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-port-forward-local-access","title":"kubectl port-forward (Local Access)","text":"<p>Purpose: Forward local port to pod/service for debugging</p> <pre><code># Forward to pod\nkubectl port-forward pod/nginx 8080:80        # Local:8080 -&gt; Pod:80\n\n# Forward to service\nkubectl port-forward service/webapp 8080:80\n\n# Forward to deployment\nkubectl port-forward deployment/webapp 8080:80\n\n# Listen on all interfaces (use with caution)\nkubectl port-forward --address 0.0.0.0 pod/nginx 8080:80\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-debug-ephemeral-containers","title":"kubectl debug (Ephemeral Containers)","text":"<p>Purpose: Debug running pods with ephemeral debugging containers</p> <pre><code># Debug pod with new container\nkubectl debug pod-name -it --image=busybox:1.28\n\n# Debug node\nkubectl debug node/worker-1 -it --image=ubuntu\n\n# Copy pod and debug\nkubectl debug pod-name --copy-to=pod-name-debug --container=debugger --image=busybox\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#imperative-vs-declarative-exam-strategy","title":"Imperative vs Declarative: Exam Strategy","text":"<p>The CKA exam requires balancing speed with maintainability. Understanding when to use each approach is critical.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#imperative-commands-recommended-for-cka","title":"Imperative Commands (Recommended for CKA)","text":"<p>Definition: Direct CLI commands that immediately execute operations</p> <p>Advantages: - Fast execution (30-60 seconds vs 2-3 minutes) - No file management overhead - Perfect for exam time constraints - Easy to remember patterns</p> <p>Disadvantages: - Not reproducible - No version control - Limited complexity handling</p> <p>Exam Use Cases: <pre><code># Simple pod creation\nkubectl run nginx --image=nginx\n\n# Quick deployment\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Expose service\nkubectl expose deployment webapp --port=80 --type=NodePort\n\n# Scale resources\nkubectl scale deployment webapp --replicas=5\n\n# Update image\nkubectl set image deployment/webapp nginx=nginx:1.21\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#declarative-configuration-limited-exam-use","title":"Declarative Configuration (Limited Exam Use)","text":"<p>Definition: YAML manifests describing desired state, applied with <code>kubectl apply</code></p> <p>Advantages: - Reproducible deployments - Version controllable - Handles complex configurations - Production best practice</p> <p>Disadvantages: - Slower for simple tasks - File management overhead - Verbose for basic operations</p> <p>Exam Use Cases: <pre><code># Complex multi-container pods\nkubectl apply -f complex-pod.yaml\n\n# Resources with specific configurations\nkubectl apply -f deployment-with-resources.yaml\n\n# Multiple related resources\nkubectl apply -f ./manifests/\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#hybrid-approach-optimal-for-cka","title":"Hybrid Approach (Optimal for CKA)","text":"<p>Strategy: Use imperative commands to generate YAML templates, edit as needed, then apply.</p> <pre><code># 1. Generate base YAML\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n\n# 2. Edit for specific requirements\nvim pod.yaml\n# Add: resource limits, volumes, labels, etc.\n\n# 3. Apply declaratively\nkubectl apply -f pod.yaml\n\n# 4. Verify\nkubectl get pods\nkubectl describe pod nginx\n</code></pre> <p>Time Comparison:</p> Task Purely Imperative Hybrid Approach Pure Declarative Simple pod 10 seconds 30 seconds 2 minutes Deployment with 3 replicas 15 seconds 45 seconds 3 minutes Pod with volumes + resources Impossible 90 seconds 4 minutes Multi-container pod Impossible 2 minutes 5 minutes","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#decision-tree-imperative-vs-declarative","title":"Decision Tree: Imperative vs Declarative","text":"<pre><code>flowchart TD\n    Start([New Resource Needed]) --&gt; Simple{Simple&lt;br/&gt;Configuration?}\n\n    Simple --&gt;|Yes| SingleContainer{Single&lt;br/&gt;Container?}\n    Simple --&gt;|No| Complex[Use Hybrid Approach]\n\n    SingleContainer --&gt;|Yes| Imperative[Use Pure Imperative&lt;br/&gt;kubectl run/create]\n    SingleContainer --&gt;|No| Complex\n\n    Complex --&gt; Generate[kubectl create --dry-run]\n    Generate --&gt; Edit[Edit YAML file]\n    Edit --&gt; Apply[kubectl apply -f]\n    Apply --&gt; Verify[kubectl get/describe]\n\n    Imperative --&gt; QuickVerify[Quick kubectl get]\n\n    style Imperative fill:#99ff99\n    style Complex fill:#fff4e1\n    style Generate fill:#e1f5ff</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#output-formats-extracting-information","title":"Output Formats: Extracting Information","text":"<p>kubectl supports multiple output formats for data extraction. Mastering these saves critical exam time.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#standard-output-formats","title":"Standard Output Formats","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#default-human-readable","title":"Default (Human-Readable)","text":"<pre><code>kubectl get pods\n# NAME        READY   STATUS    RESTARTS   AGE\n# nginx       1/1     Running   0          5m\n# webapp-1    2/2     Running   1          10m\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#wide-output","title":"Wide Output","text":"<pre><code>kubectl get pods -o wide\n# NAME     READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE\n# nginx    1/1     Running   0          5m    10.244.0.5   worker-1   &lt;none&gt;\n</code></pre> <p>Use Case: Get pod IPs, node placement, readiness gates in one view</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#yaml-output","title":"YAML Output","text":"<pre><code>kubectl get pod nginx -o yaml\n</code></pre> <p>Use Cases: - Create templates from existing resources - Understand full resource structure - Debug configuration issues - Generate manifests for reproduction</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#json-output","title":"JSON Output","text":"<pre><code>kubectl get pod nginx -o json\n</code></pre> <p>Use Cases: - Programmatic parsing - Integration with scripts - API response inspection</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#name-output","title":"Name Output","text":"<pre><code>kubectl get pods -o name\n# pod/nginx\n# pod/webapp-1\n# pod/webapp-2\n</code></pre> <p>Use Case: Pipe to other commands, scripting</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#advanced-output-formats","title":"Advanced Output Formats","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#custom-columns","title":"Custom Columns","text":"<p>Purpose: Define exactly which fields to display in table format</p> <p>Basic Syntax: <pre><code>kubectl get pods -o custom-columns=&lt;COLUMN_NAME&gt;:&lt;JSON_PATH&gt;\n</code></pre></p> <p>Examples: <pre><code># Pod name and image\nkubectl get pods -o custom-columns=NAME:.metadata.name,IMAGE:.spec.containers[0].image\n\n# Pod name, namespace, node\nkubectl get pods -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,NODE:.spec.nodeName\n\n# Multiple container images\nkubectl get pods -o custom-columns=NAME:.metadata.name,IMAGES:.spec.containers[*].image\n\n# Filter with JSONPath\nkubectl get pods -A -o custom-columns='POD:.metadata.name,IMAGE:.spec.containers[?(@.image!=\"registry.k8s.io/pause:3.9\")].image'\n</code></pre></p> <p>Common Patterns: <pre><code># Service types and IPs\nkubectl get svc -o custom-columns=NAME:.metadata.name,TYPE:.spec.type,CLUSTER-IP:.spec.clusterIP,EXTERNAL-IP:.status.loadBalancer.ingress[0].ip\n\n# Node resource capacity\nkubectl get nodes -o custom-columns=NAME:.metadata.name,CPU:.status.capacity.cpu,MEMORY:.status.capacity.memory\n\n# PV claim status\nkubectl get pv -o custom-columns=NAME:.metadata.name,CAPACITY:.spec.capacity.storage,STATUS:.status.phase,CLAIM:.spec.claimRef.name\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#jsonpath-queries","title":"JSONPath Queries","text":"<p>Purpose: Extract specific data using JSONPath expressions</p> <p>Basic Syntax: <pre><code>kubectl get &lt;resource&gt; -o jsonpath='{&lt;JSONPath_expression&gt;}'\n</code></pre></p> <p>Essential Patterns:</p> <pre><code># All pod names\nkubectl get pods -o jsonpath='{.items[*].metadata.name}'\n\n# First pod name\nkubectl get pods -o jsonpath='{.items[0].metadata.name}'\n\n# Pod IPs with newlines\nkubectl get pods -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}'\n\n# Node names and CPU capacity\nkubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.capacity.cpu}{\"\\n\"}{end}'\n\n# Filter by condition\nkubectl get pods -o jsonpath='{.items[?(@.metadata.labels.app==\"nginx\")].metadata.name}'\n\n# All container images (unique)\nkubectl get pods -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\\n' | sort -u\n\n# Service cluster IPs\nkubectl get svc -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.clusterIP}{\"\\n\"}{end}'\n</code></pre> <p>Complex Examples: <pre><code># Pods with high restart counts\nkubectl get pods -o jsonpath='{range .items[?(@.status.containerStatuses[0].restartCount&gt;5)]}{.metadata.name}{\"\\t\"}{.status.containerStatuses[0].restartCount}{\"\\n\"}{end}'\n\n# Users from kubeconfig\nkubectl config view -o jsonpath='{.users[*].name}'\n\n# Context cluster mapping\nkubectl config view -o jsonpath='{range .contexts[*]}{.name}{\"\\t\"}{.context.cluster}{\"\\n\"}{end}'\n</code></pre></p> <p>JSONPath Tips: - Use <code>{range}...{end}</code> for iteration - Use <code>{\\n}</code> for newlines, <code>{\\t}</code> for tabs - Filter with <code>[?(@.field==\"value\")]</code> - Access array elements with <code>[index]</code> or <code>[*]</code> for all - No regex support in JSONPath</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#output-format-comparison","title":"Output Format Comparison","text":"<pre><code>graph LR\n    Task[Information Need] --&gt; Decision{Data Type?}\n\n    Decision --&gt;|Quick Overview| Wide[Use -o wide]\n    Decision --&gt;|Specific Fields| Choice{How Many Fields?}\n    Decision --&gt;|Full Resource| Format{Human or Machine?}\n    Decision --&gt;|Resource Names| Name[Use -o name]\n\n    Choice --&gt;|1-2 fields| JSONPath[Use -o jsonpath]\n    Choice --&gt;|3+ fields| CustomCol[Use -o custom-columns]\n\n    Format --&gt;|Human| YAML[Use -o yaml]\n    Format --&gt;|Machine| JSON[Use -o json]\n\n    style Wide fill:#99ff99\n    style JSONPath fill:#e1f5ff\n    style CustomCol fill:#fff4e1\n    style YAML fill:#ffe5e5</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#context-and-namespace-management","title":"Context and Namespace Management","text":"<p>Managing multiple clusters and namespaces efficiently is a core CKA exam skill.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#understanding-contexts","title":"Understanding Contexts","text":"<p>Context Definition: A context groups cluster + user + namespace into a named configuration.</p> <p>Context Components: - Cluster: API server endpoint and CA certificate - User: Authentication credentials (client cert, token, etc.) - Namespace: Default namespace for commands (optional)</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#context-management-commands","title":"Context Management Commands","text":"<pre><code># List all contexts\nkubectl config get-contexts\n# CURRENT   NAME           CLUSTER        AUTHINFO       NAMESPACE\n# *         prod-context   prod-cluster   prod-admin     production\n#           dev-context    dev-cluster    dev-user       development\n\n# Show current context\nkubectl config current-context\n# prod-context\n\n# Switch context\nkubectl config use-context dev-context\n\n# Create new context\nkubectl config set-context staging \\\n  --cluster=prod-cluster \\\n  --user=staging-user \\\n  --namespace=staging\n\n# Modify existing context\nkubectl config set-context dev-context --namespace=testing\n\n# Set namespace for current context\nkubectl config set-context --current --namespace=kube-system\n\n# Delete context\nkubectl config delete-context old-context\n\n# Rename context\nkubectl config rename-context old-name new-name\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#namespace-operations","title":"Namespace Operations","text":"<pre><code># List namespaces\nkubectl get namespaces\nkubectl get ns  # Short form\n\n# Create namespace\nkubectl create namespace development\nkubectl create ns production\n\n# Describe namespace\nkubectl describe namespace development\n\n# Delete namespace (deletes all resources!)\nkubectl delete namespace development\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#multi-cluster-workflow","title":"Multi-Cluster Workflow","text":"<pre><code>sequenceDiagram\n    participant Exam as Exam Question\n    participant User\n    participant kubectl\n    participant Cluster1 as Cluster 1\n    participant Cluster2 as Cluster 2\n\n    Exam-&gt;&gt;User: \"Deploy to cluster 'k8s-prod', namespace 'production'\"\n\n    User-&gt;&gt;kubectl: kubectl config get-contexts\n    kubectl--&gt;&gt;User: List available contexts\n\n    User-&gt;&gt;kubectl: kubectl config use-context k8s-prod\n    kubectl--&gt;&gt;Cluster1: Switch connection\n\n    User-&gt;&gt;kubectl: kubectl config set-context --current --namespace=production\n    kubectl--&gt;&gt;kubectl: Set default namespace\n\n    User-&gt;&gt;kubectl: kubectl run app --image=nginx\n    kubectl-&gt;&gt;Cluster1: Create pod in production namespace\n\n    Note over Exam,User: Next question uses different cluster\n\n    Exam-&gt;&gt;User: \"Check pods in cluster 'k8s-dev', namespace 'default'\"\n\n    User-&gt;&gt;kubectl: kubectl config use-context k8s-dev\n    kubectl--&gt;&gt;Cluster2: Switch connection\n\n    User-&gt;&gt;kubectl: kubectl get pods\n    kubectl-&gt;&gt;Cluster2: Query default namespace\n    Cluster2--&gt;&gt;User: Pod list</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#namespace-best-practices","title":"Namespace Best Practices","text":"<p>Always Specify Namespace Explicitly (Exam Safety): <pre><code># Risky (uses context default)\nkubectl get pods\n\n# Safe (explicit namespace)\nkubectl get pods -n production\nkubectl get pods --namespace=production\n\n# All namespaces\nkubectl get pods -A\nkubectl get pods --all-namespaces\n</code></pre></p> <p>Context Switching Aliases (Pre-configured in Exam): <pre><code># Context switcher\nalias kx='f() { [ \"$1\" ] &amp;&amp; kubectl config use-context $1 || kubectl config current-context ; } ; f'\n\n# Usage:\nkx                  # Show current context\nkx prod-context     # Switch to prod-context\n\n# Namespace switcher\nalias kn='f() { [ \"$1\" ] &amp;&amp; kubectl config set-context --current --namespace $1 || kubectl config view --minify | grep namespace | cut -d\" \" -f6 ; } ; f'\n\n# Usage:\nkn                  # Show current namespace\nkn production       # Switch to production namespace\n</code></pre></p> <p>Exam Verification Checklist: <pre><code># Before EVERY task, verify:\nkubectl config current-context          # Am I in the right cluster?\nkubectl config view --minify | grep namespace  # What's my default namespace?\n\n# Or use the exam-provided aliases:\nkx  # Show context\nkn  # Show namespace\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#kubectl-explain-in-exam-documentation","title":"kubectl explain: In-Exam Documentation","text":"<p>kubectl explain provides API documentation directly in your terminal. This tool is available during the exam and is faster than searching web docs.</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#basic-usage","title":"Basic Usage","text":"<pre><code># Top-level resource\nkubectl explain pod\nkubectl explain deployment\nkubectl explain service\n\n# Nested field\nkubectl explain pod.spec\nkubectl explain deployment.spec.template\nkubectl explain service.spec\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exploring-resource-structure","title":"Exploring Resource Structure","text":"<pre><code># View pod spec fields\nkubectl explain pod.spec\n# FIELDS:\n#   containers    &lt;[]Container&gt; -required-\n#   volumes       &lt;[]Volume&gt;\n#   restartPolicy &lt;string&gt;\n#   nodeName      &lt;string&gt;\n\n# Drill into containers\nkubectl explain pod.spec.containers\n# FIELDS:\n#   name          &lt;string&gt; -required-\n#   image         &lt;string&gt; -required-\n#   command       &lt;[]string&gt;\n#   args          &lt;[]string&gt;\n#   env           &lt;[]EnvVar&gt;\n#   ports         &lt;[]ContainerPort&gt;\n#   volumeMounts  &lt;[]VolumeMount&gt;\n\n# Check container ports structure\nkubectl explain pod.spec.containers.ports\n# FIELDS:\n#   containerPort &lt;integer&gt; -required-\n#   hostPort      &lt;integer&gt;\n#   name          &lt;string&gt;\n#   protocol      &lt;string&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-exam-use-cases","title":"Common Exam Use Cases","text":"<p>Scenario 1: What fields are available for liveness probes? <pre><code>kubectl explain pod.spec.containers.livenessProbe\n# Shows: exec, httpGet, tcpSocket, initialDelaySeconds, periodSeconds, etc.\n\nkubectl explain pod.spec.containers.livenessProbe.httpGet\n# Shows: path, port, host, scheme, httpHeaders\n</code></pre></p> <p>Scenario 2: How to configure deployment strategy? <pre><code>kubectl explain deployment.spec.strategy\n# Shows: type (RollingUpdate, Recreate), rollingUpdate\n\nkubectl explain deployment.spec.strategy.rollingUpdate\n# Shows: maxSurge, maxUnavailable\n</code></pre></p> <p>Scenario 3: What volume types are available? <pre><code>kubectl explain pod.spec.volumes\n# Shows MANY types: configMap, secret, emptyDir, persistentVolumeClaim, hostPath, nfs, etc.\n\nkubectl explain pod.spec.volumes.persistentVolumeClaim\n# Shows: claimName, readOnly\n</code></pre></p> <p>Scenario 4: Resource limits and requests? <pre><code>kubectl explain pod.spec.containers.resources\n# Shows: limits, requests\n\nkubectl explain pod.spec.containers.resources.limits\n# Shows: can specify cpu, memory, ephemeral-storage\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#field-type-notation","title":"Field Type Notation","text":"<p>Understanding Output: - <code>&lt;string&gt;</code> - String field - <code>&lt;integer&gt;</code> - Integer field - <code>&lt;boolean&gt;</code> - Boolean (true/false) - <code>&lt;[]Type&gt;</code> - Array of Type - <code>&lt;Object&gt;</code> - Nested object - <code>&lt;map[string]string&gt;</code> - Key-value map - <code>-required-</code> - Required field marker</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#integration-with-workflow","title":"Integration with Workflow","text":"<p>Exam Pattern: <pre><code># 1. Generate base template\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n\n# 2. Check available fields\nkubectl explain pod.spec.containers.resources\n\n# 3. Edit with correct field names\nvim pod.yaml\n# Add resources based on explain output\n\n# 4. Verify and apply\nkubectl apply -f pod.yaml\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#productivity-patterns","title":"Productivity Patterns","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#time-saving-aliases-pre-configured-in-exam","title":"Time-Saving Aliases (Pre-configured in Exam)","text":"<p>Core Alias (Already Active): <pre><code>alias k=kubectl\ncomplete -o default -F __start_kubectl k\n</code></pre></p> <p>Recommended Personal Additions: <pre><code># Dry-run YAML generation\nexport dry='--dry-run=client -o yaml'\nexport now='--force --grace-period=0'\n\n# Usage examples:\nk run nginx --image=nginx $dry &gt; pod.yaml\nk create deploy webapp --image=nginx $dry &gt; deploy.yaml\nk delete pod nginx $now  # Immediate deletion\n</code></pre></p> <p>Resource Shortcuts: <pre><code>alias kgp='kubectl get pods'\nalias kgd='kubectl get deployments'\nalias kgs='kubectl get services'\nalias kga='kubectl get all'\nalias kgpa='kubectl get pods -A'\n\nalias kdesc='kubectl describe'\nalias kl='kubectl logs'\nalias klf='kubectl logs -f'\nalias kex='kubectl exec -it'\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#autocomplete-usage-pre-configured","title":"Autocomplete Usage (Pre-configured)","text":"<p>Tab Completion Examples: <pre><code># Resource type completion\nk get po&lt;TAB&gt;            # Completes to: k get pods\nk get dep&lt;TAB&gt;           # Completes to: k get deployments\n\n# Resource name completion\nk get pods ng&lt;TAB&gt;       # Completes to existing pod name\nk describe node wor&lt;TAB&gt; # Completes to node name\n\n# Namespace completion\nk get pods -n kube-&lt;TAB&gt; # Completes to: k get pods -n kube-system\n\n# Flag completion\nk get pods --out&lt;TAB&gt;    # Completes to: k get pods --output\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-command-patterns","title":"Common Command Patterns","text":"<p>Deployment Lifecycle: <pre><code># Create\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Expose\nkubectl expose deployment webapp --port=80 --type=NodePort\n\n# Update\nkubectl set image deployment/webapp nginx=nginx:1.21\n\n# Scale\nkubectl scale deployment webapp --replicas=5\n\n# Check status\nkubectl rollout status deployment/webapp\n\n# Rollback if needed\nkubectl rollout undo deployment/webapp\n</code></pre></p> <p>Debugging Workflow: <pre><code># 1. Identify issue\nkubectl get pods                # Find problematic pod\n\n# 2. Get details\nkubectl describe pod pod-name   # Check Events section\n\n# 3. Check logs\nkubectl logs pod-name           # Current logs\nkubectl logs pod-name --previous # After crash\n\n# 4. Interactive debug\nkubectl exec -it pod-name -- /bin/sh\n\n# 5. Network test\nkubectl exec -it pod-name -- ping service-name\nkubectl exec -it pod-name -- curl http://service:8080\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#cka-exam-strategies","title":"CKA Exam Strategies","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#essential-commands-use-daily","title":"Essential Commands (Use Daily)","text":"<p>Top 10 Most-Used in Exam: 1. <code>kubectl run</code> - Create pods quickly 2. <code>kubectl create</code> - Generate resources 3. <code>kubectl get</code> - List and inspect 4. <code>kubectl describe</code> - Debug issues 5. <code>kubectl logs</code> - View application logs 6. <code>kubectl apply</code> - Deploy configurations 7. <code>kubectl delete</code> - Remove resources 8. <code>kubectl exec</code> - Container debugging 9. <code>kubectl edit</code> - Quick modifications 10. <code>kubectl explain</code> - Field reference</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#time-management","title":"Time Management","text":"<p>Command Time Budget: - Simple pod creation: 10-30 seconds - Deployment with service: 45-90 seconds - Complex multi-container pod: 2-3 minutes - Debugging scenario: 3-5 minutes</p> <p>Speed Optimization: <pre><code># SLOW (2-3 minutes)\nvim pod.yaml  # Write from scratch\nkubectl apply -f pod.yaml\n\n# FAST (30 seconds)\nkubectl run nginx --image=nginx $dry &gt; pod.yaml\nvim pod.yaml  # Edit generated template\nkubectl apply -f pod.yaml\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-exam-scenarios","title":"Common Exam Scenarios","text":"<p>Scenario 1: Create and Expose <pre><code># Create deployment\nkubectl create deployment webapp --image=nginx --replicas=3\n\n# Expose service\nkubectl expose deployment webapp --port=80 --type=NodePort\n\n# Verify\nkubectl get deploy,svc,pods\n</code></pre></p> <p>Scenario 2: Fix Failing Pod <pre><code># Identify\nkubectl get pods\nkubectl describe pod failing-pod\nkubectl logs failing-pod\n\n# Fix approach\nkubectl get pod failing-pod -o yaml &gt; fix.yaml\nvim fix.yaml  # Fix the issue\nkubectl delete pod failing-pod\nkubectl apply -f fix.yaml\n</code></pre></p> <p>Scenario 3: Scale and Update <pre><code># Scale\nkubectl scale deployment webapp --replicas=5\n\n# Update image\nkubectl set image deployment/webapp nginx=nginx:1.21\n\n# Monitor rollout\nkubectl rollout status deployment/webapp\n\n# Rollback if needed\nkubectl rollout undo deployment/webapp\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#practice-exercises","title":"Practice Exercises","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-1-command-mastery-15-minutes","title":"Exercise 1: Command Mastery (15 minutes)","text":"<p>Objective: Build muscle memory for essential commands</p> <p>Tasks: 1. Create pod 'web' with nginx:1.21 image and port 80 2. Create deployment 'api' with 3 replicas using httpd image 3. Expose 'api' deployment as NodePort on port 8080 4. Get all pod IPs using JSONPath 5. List pod names only 6. Scale 'api' to 5 replicas 7. Update 'api' image to httpd:2.4.57 8. View rollout history 9. Delete all resources</p> <p>Solution: <pre><code># 1\nkubectl run web --image=nginx:1.21 --port=80\n\n# 2\nkubectl create deployment api --image=httpd --replicas=3\n\n# 3\nkubectl expose deployment api --port=8080 --type=NodePort\n\n# 4\nkubectl get pods -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}'\n\n# 5\nkubectl get pods -o name\n\n# 6\nkubectl scale deployment api --replicas=5\n\n# 7\nkubectl set image deployment/api httpd=httpd:2.4.57\n\n# 8\nkubectl rollout history deployment/api\n\n# 9\nkubectl delete deployment api\nkubectl delete pod web\nkubectl delete service api\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-2-output-formats-20-minutes","title":"Exercise 2: Output Formats (20 minutes)","text":"<p>Objective: Master data extraction with output formats</p> <p>Tasks: 1. List all pod names in kube-system namespace 2. Get pod names and node placement with custom columns 3. Extract all container images in cluster 4. Get services with type and cluster IP 5. Find pods with label app=nginx</p> <p>Solution: <pre><code># 1\nkubectl get pods -n kube-system -o name\n\n# 2\nkubectl get pods -A -o custom-columns=POD:.metadata.name,NODE:.spec.nodeName\n\n# 3\nkubectl get pods -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\\n' | sort -u\n\n# 4\nkubectl get svc -o custom-columns=NAME:.metadata.name,TYPE:.spec.type,CLUSTER-IP:.spec.clusterIP\n\n# 5\nkubectl get pods -l app=nginx\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-3-context-management-15-minutes","title":"Exercise 3: Context Management (15 minutes)","text":"<p>Objective: Practice multi-cluster context switching</p> <p>Tasks: 1. List all contexts 2. Show current context 3. Create context 'dev-ctx' for development namespace 4. Switch to 'dev-ctx' 5. Set default namespace to 'kube-system' for current context 6. Verify namespace setting</p> <p>Solution: <pre><code># 1\nkubectl config get-contexts\n\n# 2\nkubectl config current-context\n\n# 3\nkubectl config set-context dev-ctx --namespace=development\n\n# 4\nkubectl config use-context dev-ctx\n\n# 5\nkubectl config set-context --current --namespace=kube-system\n\n# 6\nkubectl config view --minify | grep namespace\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-4-imperative-vs-declarative-25-minutes","title":"Exercise 4: Imperative vs Declarative (25 minutes)","text":"<p>Objective: Practice hybrid workflow</p> <p>Tasks: 1. Generate pod YAML for nginx with resource limits (don't create) 2. Add resource requests: cpu=100m, memory=128Mi 3. Add resource limits: cpu=200m, memory=256Mi 4. Add liveness probe: HTTP GET on port 80, path / 5. Apply and verify 6. Generate deployment YAML with 3 replicas 7. Modify to add nodeSelector: disk=ssd 8. Apply and verify pods scheduled on correct nodes</p> <p>Solution: <pre><code># 1\nkubectl run nginx --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n\n# 2-4 (edit pod.yaml)\nvim pod.yaml\n# Add under containers:\n#   resources:\n#     requests:\n#       cpu: 100m\n#       memory: 128Mi\n#     limits:\n#       cpu: 200m\n#       memory: 256Mi\n#   livenessProbe:\n#     httpGet:\n#       path: /\n#       port: 80\n\n# 5\nkubectl apply -f pod.yaml\nkubectl describe pod nginx\n\n# 6\nkubectl create deployment webapp --image=nginx --replicas=3 --dry-run=client -o yaml &gt; deploy.yaml\n\n# 7\nvim deploy.yaml\n# Add under spec.template.spec:\n#   nodeSelector:\n#     disk: ssd\n\n# 8\nkubectl apply -f deploy.yaml\nkubectl get pods -o wide\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#exercise-5-debugging-simulation-30-minutes","title":"Exercise 5: Debugging Simulation (30 minutes)","text":"<p>Objective: Practice troubleshooting workflow</p> <p>Tasks: 1. Create pod with wrong image name 2. Identify why pod is failing 3. Get YAML and fix 4. Create deployment, then break it by scaling to 100 replicas 5. Observe pending pods 6. Identify resource constraints 7. Fix by scaling down</p> <p>Solution: <pre><code># 1\nkubectl run broken --image=nginxxx  # Wrong image\n\n# 2\nkubectl get pods\nkubectl describe pod broken  # Check Events: ImagePullBackOff\n\n# 3\nkubectl get pod broken -o yaml &gt; fixed.yaml\nvim fixed.yaml  # Change image to nginx\nkubectl delete pod broken\nkubectl apply -f fixed.yaml\n\n# 4\nkubectl create deployment overload --image=nginx\nkubectl scale deployment overload --replicas=100\n\n# 5\nkubectl get pods | grep Pending\n\n# 6\nkubectl describe pod &lt;pending-pod-name&gt;\n# Events show: Insufficient cpu/memory\n\n# 7\nkubectl scale deployment overload --replicas=3\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#quick-reference","title":"Quick Reference","text":"","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#command-syntax-patterns","title":"Command Syntax Patterns","text":"<pre><code># Resource Management\nkubectl &lt;verb&gt; &lt;resource&gt; &lt;name&gt; [options]\nkubectl get pods nginx -o yaml\nkubectl describe deployment webapp\n\n# Imperative Creation\nkubectl run &lt;name&gt; --image=&lt;image&gt; [options]\nkubectl create &lt;resource&gt; &lt;name&gt; [options]\nkubectl expose &lt;resource&gt; &lt;name&gt; [options]\n\n# Declarative Operations\nkubectl apply -f &lt;file&gt;\nkubectl delete -f &lt;file&gt;\n\n# Resource Modification\nkubectl edit &lt;resource&gt; &lt;name&gt;\nkubectl patch &lt;resource&gt; &lt;name&gt; -p '&lt;patch&gt;'\nkubectl scale &lt;resource&gt; &lt;name&gt; --replicas=&lt;n&gt;\nkubectl set image &lt;resource&gt;/&lt;name&gt; &lt;container&gt;=&lt;image&gt;\n\n# Debugging\nkubectl logs &lt;pod&gt; [-c &lt;container&gt;] [options]\nkubectl exec &lt;pod&gt; [-c &lt;container&gt;] -- &lt;command&gt;\nkubectl port-forward &lt;resource&gt; &lt;local&gt;:&lt;remote&gt;\n\n# Context &amp; Config\nkubectl config &lt;subcommand&gt;\nkubectl config use-context &lt;context&gt;\nkubectl config set-context --current --namespace=&lt;ns&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#output-format-quick-reference","title":"Output Format Quick Reference","text":"<pre><code># Standard formats\n-o wide               # Additional columns\n-o yaml               # Full YAML\n-o json               # Full JSON\n-o name               # Resource names only\n\n# Advanced formats\n-o custom-columns=&lt;spec&gt;\n-o jsonpath='{&lt;path&gt;}'\n-o jsonpath-file=&lt;file&gt;\n\n# Examples\nkubectl get pods -o wide\nkubectl get pods -o jsonpath='{.items[*].metadata.name}'\nkubectl get pods -o custom-columns=NAME:.metadata.name,IP:.status.podIP\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#common-flags","title":"Common Flags","text":"<pre><code>-n, --namespace         # Specify namespace\n-A, --all-namespaces    # All namespaces\n-l, --selector          # Label selector\n-f, --filename          # File path\n--dry-run=client        # Don't create, just print\n-o, --output            # Output format\n-w, --watch             # Watch for changes\n--sort-by               # Sort output\n--field-selector        # Field selector\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Imperative commands save exam minutes - Use <code>kubectl run</code>, <code>create</code>, <code>expose</code> for speed</p> <p>\u2705 --dry-run=client -o yaml is critical - Generate templates, never write YAML from scratch</p> <p>\u2705 kubectl explain is your friend - Faster than searching docs during exam</p> <p>\u2705 Output formats extract data precisely - Master JSONPath and custom-columns</p> <p>\u2705 Context awareness prevents mistakes - Always verify cluster and namespace</p> <p>\u2705 Autocomplete is pre-configured - Use tab completion aggressively</p> <p>\u2705 Aliases save time only if practiced - Use <code>k</code>, <code>$dry</code>, <code>$now</code> extensively before exam</p> <p>\u2705 Hybrid approach balances speed and complexity - Imperative generation + declarative application</p> <p>\u2705 Verification is non-negotiable - Always check resources created correctly</p> <p>\u2705 Practice makes permanent - Build muscle memory through repetition</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubectl-essentials/#next-steps","title":"Next Steps","text":"<p>After mastering kubectl, continue with:</p> <p>Post 4: Pod Lifecycle and Management - Deep dive into the fundamental Kubernetes workload unit</p> <p>Related Posts: - Kubernetes Architecture Fundamentals - Understanding cluster components - Setting Up Your Kubernetes Lab - Build your practice environment - Kubernetes CKA Mastery - Complete Learning Path - Full exam preparation series</p> <p>External Resources: - kubectl Official Documentation - kubectl Cheat Sheet - kubectl Commands Reference - JSONPath Support in kubectl - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","kubectl","command-line"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/","title":"Kubernetes Architecture Fundamentals","text":"<p>Deep dive into Kubernetes cluster architecture, control plane components, and the distributed systems design that powers container orchestration at scale.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#overview","title":"Overview","text":"<p>Kubernetes is a distributed system designed to manage containerized applications across a cluster of machines. Understanding its architecture is foundational for the CKA exam and real-world cluster administration.</p> <p>CKA Exam Domain: Cluster Architecture, Installation &amp; Configuration (25%)</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#cluster-architecture","title":"Cluster Architecture","text":"<p>A Kubernetes cluster consists of two types of nodes:</p> <ol> <li>Control Plane Nodes: Run the core components that manage the cluster</li> <li>Worker Nodes: Run application workloads (pods)</li> </ol> <pre><code>graph TB\n    subgraph \"Control Plane Nodes\"\n        API[API Server&lt;br/&gt;:6443]\n        SCHED[Scheduler]\n        CM[Controller&lt;br/&gt;Manager]\n        CCM[Cloud Controller&lt;br/&gt;Manager]\n        ETCD[(etcd&lt;br/&gt;:2379-2380)]\n    end\n\n    subgraph \"Worker Node 1\"\n        KUB1[kubelet]\n        KPXY1[kube-proxy]\n        POD1[Pods]\n        CRI1[Container&lt;br/&gt;Runtime]\n    end\n\n    subgraph \"Worker Node 2\"\n        KUB2[kubelet]\n        KPXY2[kube-proxy]\n        POD2[Pods]\n        CRI2[Container&lt;br/&gt;Runtime]\n    end\n\n    subgraph \"Worker Node 3\"\n        KUB3[kubelet]\n        KPXY3[kube-proxy]\n        POD3[Pods]\n        CRI3[Container&lt;br/&gt;Runtime]\n    end\n\n    API --&gt;|watches| ETCD\n    API --&gt; SCHED\n    API --&gt; CM\n    API --&gt; CCM\n\n    KUB1 --&gt;|API calls| API\n    KUB2 --&gt;|API calls| API\n    KUB3 --&gt;|API calls| API\n\n    KUB1 --&gt; CRI1 --&gt; POD1\n    KUB2 --&gt; CRI2 --&gt; POD2\n    KUB3 --&gt; CRI3 --&gt; POD3\n\n    KPXY1 -.-&gt;|iptables/IPVS| POD1\n    KPXY2 -.-&gt;|iptables/IPVS| POD2\n    KPXY3 -.-&gt;|iptables/IPVS| POD3\n\n    style API fill:#e1f5ff\n    style ETCD fill:#ffe5e5\n    style SCHED fill:#fff4e1\n    style CM fill:#e8f5e8</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#control-plane-components","title":"Control Plane Components","text":"<p>The control plane makes global decisions about the cluster and detects/responds to cluster events.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#1-api-server-kube-apiserver","title":"1. API Server (kube-apiserver)","text":"<p>Purpose: Front-end for the Kubernetes control plane. All communication goes through the API server.</p> <p>Key Responsibilities: - Exposes the Kubernetes API (REST interface) - Validates and configures API objects (pods, services, replication controllers) - Serves as the only component that directly interacts with etcd - Handles authentication, authorization, and admission control</p> <p>Default Port: <code>6443</code> (HTTPS)</p> <pre><code># Check API server status\nkubectl get --raw='/healthz?verbose'\n\n# View API server configuration\nkubectl -n kube-system get pod kube-apiserver-&lt;node-name&gt; -o yaml\n\n# Check API server logs\nkubectl -n kube-system logs kube-apiserver-&lt;node-name&gt;\n</code></pre> <p>API Request Flow:</p> <pre><code>sequenceDiagram\n    participant U as User/kubectl\n    participant API as API Server\n    participant AUTH as Authentication\n    participant AUTHZ as Authorization\n    participant ADM as Admission&lt;br/&gt;Controllers\n    participant ETCD as etcd\n\n    U-&gt;&gt;+API: HTTP Request&lt;br/&gt;(create Pod)\n\n    API-&gt;&gt;+AUTH: Authenticate\n    Note right of AUTH: Verify user identity&lt;br/&gt;(certs, tokens, SA)\n    AUTH--&gt;&gt;-API: User ID\n\n    API-&gt;&gt;+AUTHZ: Authorize\n    Note right of AUTHZ: Check RBAC rules&lt;br/&gt;(can user create pod?)\n    AUTHZ--&gt;&gt;-API: Authorized\n\n    API-&gt;&gt;+ADM: Admission Control\n    Note right of ADM: Validate &amp; Mutate&lt;br/&gt;(defaults, quotas, PSP)\n    ADM--&gt;&gt;-API: Admitted\n\n    API-&gt;&gt;+ETCD: Write to etcd\n    ETCD--&gt;&gt;-API: Persisted\n\n    API--&gt;&gt;-U: 201 Created\n\n    Note over API,ETCD: Object now exists in desired state</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#2-etcd","title":"2. etcd","text":"<p>Purpose: Consistent, highly-available key-value store used as Kubernetes' backing store for all cluster data.</p> <p>Key Characteristics: - Distributed consensus using Raft algorithm - Stores all cluster state and configuration - Only the API server writes to etcd - Supports watch operations for real-time updates</p> <p>Default Ports: - <code>2379</code> - Client requests - <code>2380</code> - Server-to-server communication</p> <pre><code># Check etcd cluster health\nETCDCTL_API=3 etcdctl \\\n  --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\n  endpoint health\n\n# List etcd members\nETCDCTL_API=3 etcdctl member list\n\n# Get all keys (see what's stored)\nETCDCTL_API=3 etcdctl get / --prefix --keys-only\n\n# Backup etcd\nETCDCTL_API=3 etcdctl snapshot save snapshot.db\n</code></pre> <p>High Availability: For production clusters, run etcd with at least 3 nodes (odd number for quorum).</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#3-scheduler-kube-scheduler","title":"3. Scheduler (kube-scheduler)","text":"<p>Purpose: Watches for newly created pods with no assigned node and selects a node for them to run on.</p> <p>Scheduling Algorithm: 1. Filtering: Find nodes that satisfy pod requirements (feasible nodes)    - Resource requests (CPU, memory)    - Node selectors    - Taints and tolerations    - Affinity/anti-affinity rules</p> <ol> <li>Scoring: Rank feasible nodes</li> <li>Spread pods across nodes for availability</li> <li>Prefer nodes with available resources</li> <li> <p>Consider pod priorities</p> </li> <li> <p>Binding: Assign pod to highest-scoring node</p> </li> </ol> <pre><code>graph TD\n    START([New Pod Created]) --&gt; FILTER[Filtering Phase]\n\n    FILTER --&gt; CHECK1{Resource&lt;br/&gt;Requirements?}\n    CHECK1 --&gt;|Fail| UNSCHEDULABLE[Pod Unschedulable]\n    CHECK1 --&gt;|Pass| CHECK2{Node&lt;br/&gt;Selectors?}\n\n    CHECK2 --&gt;|Fail| UNSCHEDULABLE\n    CHECK2 --&gt;|Pass| CHECK3{Taints/&lt;br/&gt;Tolerations?}\n\n    CHECK3 --&gt;|Fail| UNSCHEDULABLE\n    CHECK3 --&gt;|Pass| CHECK4{Affinity&lt;br/&gt;Rules?}\n\n    CHECK4 --&gt;|Fail| UNSCHEDULABLE\n    CHECK4 --&gt;|Pass| FEASIBLE[Feasible Nodes]\n\n    FEASIBLE --&gt; SCORE[Scoring Phase]\n    SCORE --&gt; RANK[Rank Nodes&lt;br/&gt;by Score]\n    RANK --&gt; BIND[Bind Pod to&lt;br/&gt;Top Node]\n    BIND --&gt; SUCCESS([Pod Scheduled])\n\n    style START fill:#e1f5ff\n    style SUCCESS fill:#e8f5e8\n    style UNSCHEDULABLE fill:#ffe5e5</code></pre> <pre><code># View scheduler configuration\nkubectl -n kube-system get pod kube-scheduler-&lt;node-name&gt; -o yaml\n\n# Check scheduler logs\nkubectl -n kube-system logs kube-scheduler-&lt;node-name&gt;\n\n# View events (scheduling decisions)\nkubectl get events --sort-by='.lastTimestamp'\n\n# See why a pod is not scheduled\nkubectl describe pod &lt;pod-name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#4-controller-manager-kube-controller-manager","title":"4. Controller Manager (kube-controller-manager)","text":"<p>Purpose: Runs controller processes that regulate the state of the cluster.</p> <p>Key Controllers: - Node Controller: Monitors node health, marks nodes as unreachable - Replication Controller: Maintains correct number of pod replicas - Endpoints Controller: Populates Endpoints objects (joins Services &amp; Pods) - Service Account &amp; Token Controllers: Create default accounts and API access tokens</p> <p>Control Loop Pattern:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; Watch: Controller starts\n    Watch --&gt; Compare: Detect change\n    Compare --&gt; DesiredState: Check desired state\n    DesiredState --&gt; CurrentState: Check current state\n    CurrentState --&gt; Match: States match?\n\n    Match --&gt; Watch: Yes, no action\n    Match --&gt; Reconcile: No, take action\n\n    Reconcile --&gt; CreateResources: Create missing resources\n    Reconcile --&gt; UpdateResources: Update existing resources\n    Reconcile --&gt; DeleteResources: Delete extra resources\n\n    CreateResources --&gt; Watch\n    UpdateResources --&gt; Watch\n    DeleteResources --&gt; Watch</code></pre> <pre><code># View controller manager logs\nkubectl -n kube-system logs kube-controller-manager-&lt;node-name&gt;\n\n# Check which controllers are enabled\nkubectl -n kube-system get pod kube-controller-manager-&lt;node-name&gt; -o yaml | grep enable\n\n# Watch controller actions in events\nkubectl get events --watch\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#5-cloud-controller-manager-cloud-controller-manager","title":"5. Cloud Controller Manager (cloud-controller-manager)","text":"<p>Purpose: Embeds cloud-specific control logic. Allows cloud providers to integrate with Kubernetes.</p> <p>Key Controllers: - Node Controller: Check cloud provider to determine if a deleted node has been removed - Route Controller: Set up routes in the cloud infrastructure - Service Controller: Create, update, delete cloud load balancers</p> <p>Note: Only relevant when running Kubernetes on cloud platforms (AWS, GCP, Azure).</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#worker-node-components","title":"Worker Node Components","text":"<p>Worker nodes run application workloads and maintain running pods.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#1-kubelet","title":"1. kubelet","text":"<p>Purpose: Agent that runs on each node, ensures containers are running in pods.</p> <p>Key Responsibilities: - Registers node with API server - Watches for pod assignments to its node - Ensures containers described in PodSpec are running and healthy - Reports node and pod status back to API server - Performs container health checks (liveness, readiness probes)</p> <p>Default Port: <code>10250</code></p> <pre><code># Check kubelet status (on node directly)\nsystemctl status kubelet\n\n# View kubelet configuration\ncat /var/lib/kubelet/config.yaml\n\n# Check kubelet logs\njournalctl -u kubelet -f\n\n# View node status from control plane\nkubectl get nodes\nkubectl describe node &lt;node-name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#2-kube-proxy","title":"2. kube-proxy","text":"<p>Purpose: Network proxy that maintains network rules on nodes, enabling communication to pods.</p> <p>Key Responsibilities: - Implements Service abstraction - Maintains iptables/IPVS rules for service IPs - Forwards traffic to correct backend pods - Performs load balancing across pod replicas</p> <p>Modes: - iptables (default): Uses Linux iptables for packet filtering - IPVS: Uses Linux IPVS for better performance at scale - userspace: Legacy mode (rarely used)</p> <pre><code># Check kube-proxy mode\nkubectl -n kube-system logs kube-proxy-&lt;pod-name&gt; | grep \"proxy mode\"\n\n# View kube-proxy configuration\nkubectl -n kube-system get cm kube-proxy -o yaml\n\n# Check iptables rules (on node)\niptables-save | grep -i kube\n\n# View IPVS rules (if using IPVS mode)\nipvsadm -Ln\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#3-container-runtime","title":"3. Container Runtime","text":"<p>Purpose: Software responsible for running containers.</p> <p>Supported Runtimes (via Container Runtime Interface - CRI): - containerd: Lightweight, industry-standard (default for most distributions) - CRI-O: Lightweight alternative specifically for Kubernetes - Docker Engine: Via cri-dockerd shim (removed as default in Kubernetes 1.24)</p> <pre><code># Check container runtime\nkubectl get nodes -o wide\n\n# On node: check containerd\nsystemctl status containerd\ncrictl ps\n\n# List images\ncrictl images\n\n# Pull image\ncrictl pull nginx:latest\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#component-communication","title":"Component Communication","text":"<p>All components communicate through the API server. No direct component-to-component communication exists.</p> <pre><code>graph LR\n    subgraph \"Control Plane\"\n        API[API Server]\n        SCHED[Scheduler]\n        CM[Controller&lt;br/&gt;Manager]\n        ETCD[(etcd)]\n    end\n\n    subgraph \"Worker Nodes\"\n        KUB1[kubelet]\n        KUB2[kubelet]\n        KUB3[kubelet]\n    end\n\n    CLIENT[kubectl/Users]\n\n    CLIENT --&gt;|REST API| API\n    SCHED --&gt;|watch/update| API\n    CM --&gt;|watch/update| API\n    API &lt;--&gt;|read/write| ETCD\n    KUB1 --&gt;|watch/update| API\n    KUB2 --&gt;|watch/update| API\n    KUB3 --&gt;|watch/update| API\n\n    style API fill:#e1f5ff\n    style ETCD fill:#ffe5e5</code></pre> <p>Communication Patterns:</p> <ol> <li>kubectl \u2192 API Server: Users interact with cluster via kubectl</li> <li>API Server \u2194 etcd: All state stored in etcd</li> <li>Scheduler \u2192 API Server: Watches for unscheduled pods, updates bindings</li> <li>Controller Manager \u2192 API Server: Watches resources, reconciles state</li> <li>kubelet \u2192 API Server: Reports node/pod status, watches for assigned pods</li> </ol>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#kubernetes-object-model","title":"Kubernetes Object Model","text":"<p>Kubernetes manages objects that represent the desired state of your cluster.</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#object-anatomy","title":"Object Anatomy","text":"<pre><code>apiVersion: v1              # API version\nkind: Pod                   # Object type\nmetadata:                   # Object metadata\n  name: nginx-pod\n  namespace: default\n  labels:\n    app: nginx\n    tier: frontend\n  annotations:\n    description: \"Example pod\"\nspec:                       # Desired state\n  containers:\n  - name: nginx\n    image: nginx:1.21\n    ports:\n    - containerPort: 80\nstatus:                     # Current state (managed by system)\n  phase: Running\n  conditions: [...]\n</code></pre> <p>Key Fields: - apiVersion: API group and version (<code>v1</code>, <code>apps/v1</code>, <code>networking.k8s.io/v1</code>) - kind: Object type (Pod, Deployment, Service) - metadata: Identifying information (name, namespace, labels) - spec: Desired state defined by user - status: Current state observed by system (read-only)</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#common-exam-tasks","title":"Common Exam Tasks","text":"","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#scenario-1-check-cluster-component-health","title":"Scenario 1: Check Cluster Component Health","text":"<pre><code># Check all control plane components\nkubectl get componentstatuses\n\n# Check system pods\nkubectl -n kube-system get pods\n\n# Verify API server\nkubectl get --raw='/healthz?verbose'\n\n# Check etcd health\nkubectl -n kube-system exec etcd-&lt;node&gt; -- etcdctl endpoint health\n\n# View node status\nkubectl get nodes\nkubectl describe node &lt;node-name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#scenario-2-troubleshoot-kubelet-issues","title":"Scenario 2: Troubleshoot kubelet Issues","text":"<pre><code># On worker node:\nsystemctl status kubelet\njournalctl -u kubelet -f\n\n# Check kubelet config\ncat /var/lib/kubelet/config.yaml\n\n# Restart kubelet\nsystemctl restart kubelet\n\n# From control plane:\nkubectl describe node &lt;node-name&gt;\nkubectl get events --field-selector involvedObject.kind=Node\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#scenario-3-backup-and-restore-etcd","title":"Scenario 3: Backup and Restore etcd","text":"<pre><code># Backup\nETCDCTL_API=3 etcdctl snapshot save /backup/snapshot.db \\\n  --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key\n\n# Verify backup\nETCDCTL_API=3 etcdctl --write-out=table snapshot status snapshot.db\n\n# Restore (advanced - exam may require)\nETCDCTL_API=3 etcdctl snapshot restore snapshot.db \\\n  --data-dir=/var/lib/etcd-restore\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#practice-exercises","title":"Practice Exercises","text":"<ol> <li>Inspect Cluster Architecture</li> <li>List all control plane pods</li> <li>Check which nodes are running control plane components</li> <li> <p>Identify the API server endpoint and port</p> </li> <li> <p>Component Analysis</p> </li> <li>View logs from each control plane component</li> <li>Check resource usage of control plane pods</li> <li> <p>Identify which container runtime each node is using</p> </li> <li> <p>Troubleshooting Simulation</p> </li> <li>Simulate kubelet failure (stop service) and observe effects</li> <li>Check events to see scheduling decisions</li> <li>Examine etcd data to see how objects are stored</li> </ol>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Kubernetes is a distributed system with control plane and worker nodes</p> <p>\u2705 API server is the central hub - all communication flows through it</p> <p>\u2705 etcd stores all cluster state - critical for backups and disaster recovery</p> <p>\u2705 Scheduler assigns pods to nodes using filtering and scoring</p> <p>\u2705 Controllers maintain desired state through continuous reconciliation loops</p> <p>\u2705 kubelet is the node agent ensuring containers run as specified</p> <p>\u2705 kube-proxy handles networking enabling Service abstraction</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#quick-reference-commands","title":"Quick Reference Commands","text":"<pre><code># Cluster info\nkubectl cluster-info\nkubectl version\nkubectl api-resources\nkubectl api-versions\n\n# Component health\nkubectl get componentstatuses\nkubectl -n kube-system get pods\nkubectl get nodes\n\n# Component logs\nkubectl -n kube-system logs &lt;component-pod&gt;\njournalctl -u kubelet (on node)\njournalctl -u containerd (on node)\n\n# etcd operations\nETCDCTL_API=3 etcdctl endpoint health\nETCDCTL_API=3 etcdctl snapshot save &lt;file&gt;\nETCDCTL_API=3 etcdctl member list\n\n# Node inspection\nkubectl describe node &lt;node-name&gt;\nkubectl get nodes -o wide\nkubectl top nodes (requires metrics-server)\n</code></pre>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/kubernetes-architecture-fundamentals/#next-steps","title":"Next Steps","text":"<p>Continue to Post 2: Setting Up Your Kubernetes Lab Environment to build your hands-on learning environment for practicing CKA exam scenarios.</p> <p>Related Posts: - Kubernetes CKA Mastery - Complete Learning Path - Post 3: kubectl Essentials (coming soon) - Post 15: RBAC and Security (coming soon)</p> <p>External Resources: - Kubernetes Components (Official Docs) - Kubernetes Architecture Diagram (CNCF) - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","architecture","control-plane","kubectl"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/","title":"Setting Up Your Kubernetes Lab Environment","text":"<p>Master the art of building Kubernetes clusters for CKA exam preparation. Learn kubeadm for production-grade setups, kind for rapid testing, and essential kubectl configuration for efficient cluster management.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#overview","title":"Overview","text":"<p>A proper lab environment is critical for CKA exam success. The exam uses kubeadm-based clusters, making hands-on practice with real cluster setup essential. This guide covers four primary methods for building Kubernetes environments:</p> <ol> <li>kubeadm - Production-grade multi-node clusters (exam environment)</li> <li>kind - Fast container-based clusters for rapid iteration</li> <li>Minikube - Single-node local development with rich addons</li> <li>kubectl - Essential CLI tool configuration and management</li> </ol> <p>CKA Exam Domain: Cluster Architecture, Installation &amp; Configuration (25%)</p> <p>Key Finding: While the CKA exam uses kubeadm clusters, kind offers the fastest iteration for practice exercises. A combination of both provides optimal preparation.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#lab-environment-decision-tree","title":"Lab Environment Decision Tree","text":"<p>Choosing the right lab setup depends on your immediate needs and learning phase.</p> <pre><code>flowchart TD\n    Start([Need Kubernetes Lab?]) --&gt; Purpose{What's the purpose?}\n\n    Purpose --&gt;|CKA Exam Prep| Exam{Practice&lt;br/&gt;or&lt;br/&gt;Full Simulation?}\n    Purpose --&gt;|Local Development| Dev{Single or&lt;br/&gt;Multi-Node?}\n    Purpose --&gt;|CI/CD Testing| CICD[Use kind&lt;br/&gt;Fast iteration]\n\n    Exam --&gt;|Quick Practice| kind_exam[Use kind&lt;br/&gt;30-second clusters]\n    Exam --&gt;|Full Simulation| kubeadm_exam[Use kubeadm&lt;br/&gt;Production-like setup]\n\n    Dev --&gt;|Single Node&lt;br/&gt;+ Addons| Minikube[Use Minikube&lt;br/&gt;Rich ecosystem]\n    Dev --&gt;|Multi-Node&lt;br/&gt;Testing| kind_dev[Use kind&lt;br/&gt;Config-based]\n    Dev --&gt;|Production Sim| kubeadm_dev[Use kubeadm&lt;br/&gt;Real cluster]\n\n    CICD --&gt; fast{Speed&lt;br/&gt;Important?}\n    fast --&gt;|Yes| kind_fast[Use kind&lt;br/&gt;Container-based]\n    fast --&gt;|No| minikube_ci[Use Minikube&lt;br/&gt;More features]\n\n    style kubeadm_exam fill:#ff9999\n    style kubeadm_dev fill:#ff9999\n    style Minikube fill:#99ccff\n    style kind_exam fill:#99ff99\n    style kind_dev fill:#99ff99\n    style kind_fast fill:#99ff99\n    style CICD fill:#99ff99</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-production-grade-cluster-setup","title":"kubeadm: Production-Grade Cluster Setup","text":"<p>kubeadm is the official Kubernetes tool for bootstrapping production-grade clusters. This is the tool used in the CKA exam environment.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#prerequisites","title":"Prerequisites","text":"<p>System Requirements (Per Node): - Ubuntu 20.04/22.04/24.04 or equivalent Debian-based system - 2+ CPUs - 2GB+ RAM - Network connectivity between all nodes - Unique hostname, MAC address, and product_uuid per node - Swap disabled (critical requirement)</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#complete-installation-process","title":"Complete Installation Process","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-1-disable-swap-critical","title":"Step 1: Disable Swap (CRITICAL)","text":"<p>Kubernetes scheduler relies on accurate resource allocation. Swap can cause unpredictable behavior.</p> <pre><code># Temporary disable\nsudo swapoff -a\n\n# Permanent disable - comment out swap in /etc/fstab\nsudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\n\n# Verify (swap line should show 0)\nfree -h\n</code></pre> <p>Exam Alert</p> <p>The CKA exam expects swap to be disabled. Forgetting this step causes kubeadm init to fail.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-2-install-container-runtime-containerd","title":"Step 2: Install Container Runtime (containerd)","text":"<pre><code># Install containerd\nsudo apt-get update\nsudo apt-get install -y containerd\n\n# Configure containerd\nsudo mkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n\n# Restart and enable containerd\nsudo systemctl restart containerd\nsudo systemctl enable containerd\n\n# Verify containerd is running\nsystemctl status containerd\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-3-install-kubeadm-kubelet-kubectl","title":"Step 3: Install kubeadm, kubelet, kubectl","text":"<pre><code># Update package index and install prerequisites\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\n\n# Add Kubernetes GPG key (NEW REPOSITORY)\ncurl -fsSL https://pkgs.k8s.io/core:/stable:/v1.34/deb/Release.key | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n\n# Add Kubernetes repository\necho 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.34/deb/ /' | \\\n  sudo tee /etc/apt/sources.list.d/kubernetes.list\n\n# Install Kubernetes components\nsudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\n\n# Hold packages at current version (prevent auto-upgrade)\nsudo apt-mark hold kubelet kubeadm kubectl\n\n# Enable kubelet\nsudo systemctl enable --now kubelet\n</code></pre> <p>Repository Change</p> <p>The old repository <code>https://apt.kubernetes.io</code> is deprecated. Always use <code>pkgs.k8s.io</code> for new installations.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-4-initialize-control-plane-node","title":"Step 4: Initialize Control Plane Node","text":"<pre><code># Basic initialization with pod network CIDR\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n\n# For HA setup with load balancer\nsudo kubeadm init \\\n  --control-plane-endpoint \"LOAD_BALANCER_DNS:LOAD_BALANCER_PORT\" \\\n  --upload-certs \\\n  --pod-network-cidr=10.244.0.0/16\n</code></pre> <p>Expected Output: <pre><code>Your Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a Pod network to the cluster.\n\nYou can now join any number of machines by running the following on each node:\n\n  kubeadm join 192.168.0.200:6443 \\\n    --token 9vr73a.a8uxyaju799qwdjv \\\n    --discovery-token-ca-cert-hash sha256:7c2e69131a36ae2a042a339b33381c6d\n</code></pre></p> <p>Save the join command - you'll need it for worker nodes.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-5-configure-kubectl-access","title":"Step 5: Configure kubectl Access","text":"<pre><code># Configure kubectl for regular user\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n# Verify cluster access\nkubectl cluster-info\nkubectl get nodes\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-6-install-cni-network-plugin-critical","title":"Step 6: Install CNI Network Plugin (CRITICAL)","text":"<p>Without a CNI plugin, nodes remain in \"NotReady\" state and pods cannot communicate.</p> <p>Option A: Calico (Recommended for CKA)</p> <pre><code># Install Calico operator\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\n\n# Apply custom resources\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Verify installation (wait for all pods to be Running)\nwatch kubectl get pods -n calico-system\n</code></pre> <p>Option B: Flannel</p> <pre><code>kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml\n</code></pre> <p>Option C: Weave Net</p> <pre><code>kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml\n</code></pre> <p>After CNI installation, verify nodes are Ready:</p> <pre><code>kubectl get nodes\n# NAME            STATUS   ROLES           AGE   VERSION\n# control-plane   Ready    control-plane   5m    v1.34.0\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#step-7-join-worker-nodes","title":"Step 7: Join Worker Nodes","text":"<p>On each worker node (after completing Steps 1-3):</p> <pre><code># Use the join command from Step 4 output\nsudo kubeadm join 192.168.0.200:6443 \\\n  --token 9vr73a.a8uxyaju799qwdjv \\\n  --discovery-token-ca-cert-hash sha256:7c2e69131a36ae2a042a339b33381c6d\n</code></pre> <p>If token expired (tokens are valid for 24 hours):</p> <pre><code># Generate new join command on control plane\nkubeadm token create --print-join-command\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-cluster-architecture","title":"kubeadm Cluster Architecture","text":"<pre><code>graph TB\n    subgraph \"Control Plane Node\"\n        APIServer[API Server&lt;br/&gt;:6443]\n        Scheduler[Scheduler]\n        Controller[Controller Manager]\n        etcd[(etcd&lt;br/&gt;:2379-2380)]\n        KubeletCP[Kubelet&lt;br/&gt;:10250]\n        ProxyCP[kube-proxy]\n    end\n\n    subgraph \"Worker Node 1\"\n        KubeletW1[Kubelet&lt;br/&gt;:10250]\n        ProxyW1[kube-proxy]\n        Pod1[Pod]\n        Pod2[Pod]\n        CRI1[containerd]\n    end\n\n    subgraph \"Worker Node 2\"\n        KubeletW2[Kubelet&lt;br/&gt;:10250]\n        ProxyW2[kube-proxy]\n        Pod3[Pod]\n        Pod4[Pod]\n        CRI2[containerd]\n    end\n\n    subgraph \"CNI Network Layer\"\n        CNI[Calico/Flannel&lt;br/&gt;10.244.0.0/16]\n    end\n\n    APIServer --&gt; Scheduler\n    APIServer --&gt; Controller\n    APIServer --&gt; etcd\n    APIServer -.-&gt;|watches| KubeletCP\n    APIServer -.-&gt;|watches| KubeletW1\n    APIServer -.-&gt;|watches| KubeletW2\n\n    KubeletW1 --&gt; CRI1\n    KubeletW2 --&gt; CRI2\n    CRI1 --&gt; Pod1\n    CRI1 --&gt; Pod2\n    CRI2 --&gt; Pod3\n    CRI2 --&gt; Pod4\n\n    CNI --&gt; Pod1\n    CNI --&gt; Pod2\n    CNI --&gt; Pod3\n    CNI --&gt; Pod4\n\n    style APIServer fill:#e1f5ff\n    style etcd fill:#ffe5e5\n    style CNI fill:#e8f5e8</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#common-kubeadm-issues-and-solutions","title":"Common kubeadm Issues and Solutions","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-1-swap-is-enabled-production-deployments-should-disable-swap","title":"Issue 1: \"swap is enabled; production deployments should disable swap\"","text":"<p>Cause: Swap not properly disabled</p> <p>Solution: <pre><code>sudo swapoff -a\nsudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\nsudo reboot\nfree -h  # Verify swap shows 0\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-2-container-runtime-network-not-ready-cni-config-uninitialized","title":"Issue 2: \"container runtime network not ready: cni config uninitialized\"","text":"<p>Cause: No CNI plugin installed</p> <p>Solution: <pre><code># Check CNI config directory\nls /etc/cni/net.d/\n\n# If empty, install CNI plugin (Calico/Flannel)\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Verify CNI pods running\nkubectl get pods -n calico-system\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-3-port-6443-already-in-use","title":"Issue 3: Port 6443 already in use","text":"<p>Cause: Previous kubeadm installation not cleaned up</p> <p>Solution: <pre><code># Reset kubeadm completely\nsudo kubeadm reset\n\n# Clean up directories\nsudo rm -rf /etc/cni/net.d\nsudo rm -rf $HOME/.kube/config\n\n# Try initialization again\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#issue-4-worker-node-join-fails","title":"Issue 4: Worker node join fails","text":"<p>Causes: Token expired, network connectivity, firewall rules</p> <p>Solutions: <pre><code># Generate new join command\nkubeadm token create --print-join-command\n\n# Check connectivity from worker to control plane\nping &lt;control-plane-ip&gt;\nnc -zv &lt;control-plane-ip&gt; 6443\n\n# Required firewall ports:\n# Control Plane: 6443, 2379-2380, 10250-10252\n# Worker Nodes: 10250, 30000-32767\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-configuration-file-approach","title":"kubeadm Configuration File Approach","text":"<p>For repeatable setups, use configuration files:</p> <pre><code># kubeadm-config.yaml\napiVersion: kubeadm.k8s.io/v1beta4\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.0.200\n  bindPort: 6443\n---\napiVersion: kubeadm.k8s.io/v1beta4\nkind: ClusterConfiguration\nnetworking:\n  podSubnet: 10.244.0.0/16\n  serviceSubnet: 10.96.0.0/16\nkubernetesVersion: v1.34.0\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nmode: ipvs\n</code></pre> <pre><code># Initialize with config file\nsudo kubeadm init --config=kubeadm-config.yaml\n\n# Generate default config template\nkubeadm config print init-defaults &gt; kubeadm-config.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kind-kubernetes-in-docker","title":"kind: Kubernetes in Docker","text":"<p>kind runs Kubernetes clusters using Docker containers as \"nodes\". Excellent for rapid iteration and CKA practice.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#installation","title":"Installation","text":"<p>Linux/macOS: <pre><code># Using Homebrew (macOS)\nbrew install kind\n\n# Direct binary download (Linux)\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/latest/kind-linux-amd64\nchmod +x ./kind\nsudo mv ./kind /usr/local/bin/kind\n\n# Verify installation\nkind version\n</code></pre></p> <p>Prerequisites: - Docker installed and running - kubectl installed - 4GB+ RAM allocated to Docker - 2+ CPUs for multi-node clusters</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#basic-usage","title":"Basic Usage","text":"<pre><code># Create default single-node cluster\nkind create cluster\n\n# Create cluster with custom name\nkind create cluster --name cka-practice\n\n# List clusters\nkind get clusters\n\n# Delete cluster\nkind delete cluster --name cka-practice\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#multi-node-cluster-configuration","title":"Multi-Node Cluster Configuration","text":"<p>2-Node Cluster (1 Control Plane + 1 Worker):</p> <pre><code># kind-2node.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n  - role: worker\n</code></pre> <pre><code>kind create cluster --config kind-2node.yaml --name cka-lab\n</code></pre> <p>3-Node Cluster with Port Mapping:</p> <pre><code># kind-3node.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n    extraPortMappings:\n    - containerPort: 30080\n      hostPort: 8080\n      protocol: TCP\n  - role: worker\n  - role: worker\n</code></pre> <pre><code>kind create cluster --config kind-3node.yaml --name multinode\n</code></pre> <p>High Availability Control Plane (3 Control Plane + 3 Worker):</p> <pre><code># kind-ha.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n  - role: control-plane\n  - role: control-plane\n  - role: worker\n  - role: worker\n  - role: worker\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kind-cluster-lifecycle","title":"kind Cluster Lifecycle","text":"<pre><code>sequenceDiagram\n    participant User\n    participant kind\n    participant Docker\n    participant kubectl\n\n    User-&gt;&gt;kind: kind create cluster --config kind-3node.yaml\n    kind-&gt;&gt;Docker: Pull kindest/node:v1.34.0 image\n    Docker--&gt;&gt;kind: Image ready\n\n    kind-&gt;&gt;Docker: Create control-plane container\n    kind-&gt;&gt;Docker: Create worker-1 container\n    kind-&gt;&gt;Docker: Create worker-2 container\n    Docker--&gt;&gt;kind: 3 containers running\n\n    kind-&gt;&gt;kind: Bootstrap Kubernetes in containers\n    kind-&gt;&gt;kind: Configure CNI (kindnetd)\n    kind-&gt;&gt;kind: Wait for cluster ready\n\n    kind-&gt;&gt;kubectl: Update kubeconfig\n    kind--&gt;&gt;User: Cluster ready (30-60 seconds)\n\n    User-&gt;&gt;kubectl: kubectl get nodes\n    kubectl--&gt;&gt;User: 3 nodes Ready\n\n    Note over User,kubectl: Practice CKA scenarios\n\n    User-&gt;&gt;kind: kind delete cluster\n    kind-&gt;&gt;Docker: Remove all containers\n    Docker--&gt;&gt;kind: Cleanup complete\n    kind--&gt;&gt;User: Cluster deleted</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#load-docker-images-into-kind","title":"Load Docker Images into kind","text":"<p>For testing custom applications without pushing to registry:</p> <pre><code># Build image locally\ndocker build -t my-app:1.0 .\n\n# Load into kind cluster\nkind load docker-image my-app:1.0 --name cka-lab\n\n# Verify image available in cluster\ndocker exec -it cka-lab-control-plane crictl images | grep my-app\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#when-to-use-kind","title":"When to Use kind","text":"<p>Best For: - CKA rapid practice: Create/destroy clusters in seconds - Multi-node testing: Easy configuration for complex topologies - CI/CD pipelines: Fast, reproducible test environments - Integration testing: Test applications in real cluster - Quick experiments: Try configurations without VM overhead</p> <p>Not Ideal For: - Learning basics: Minikube has better addon ecosystem - Production simulation: kubeadm provides real multi-machine setup - Resource-constrained systems: Requires Docker overhead</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#minikube-local-development-environment","title":"Minikube: Local Development Environment","text":"<p>Minikube creates single-node Kubernetes clusters on your local machine. Ideal for learning with rich addon support.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#installation_1","title":"Installation","text":"<p>macOS: <pre><code>brew install minikube\nminikube version\n</code></pre></p> <p>Linux: <pre><code>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\nminikube version\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#driver-options","title":"Driver Options","text":"<p>Docker Driver (Recommended): <pre><code># Start with Docker driver\nminikube start --driver=docker\n\n# Set as default\nminikube config set driver docker\n</code></pre></p> <p>QEMU Driver (ARM/M1 Macs): <pre><code>minikube start --driver=qemu\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#resource-configuration","title":"Resource Configuration","text":"<pre><code># Specify CPUs, memory, disk\nminikube start \\\n  --driver=docker \\\n  --cpus=4 \\\n  --memory=8192 \\\n  --disk-size=40g \\\n  --kubernetes-version=v1.34.0\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#common-minikube-commands","title":"Common Minikube Commands","text":"<pre><code># Start cluster\nminikube start\n\n# Stop cluster (preserves state)\nminikube stop\n\n# Delete cluster\nminikube delete\n\n# Check status\nminikube status\n\n# SSH into node\nminikube ssh\n\n# Open dashboard\nminikube dashboard\n\n# List addons\nminikube addons list\n\n# Enable addons\nminikube addons enable ingress\nminikube addons enable metrics-server\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#minikube-addons-for-cka-practice","title":"Minikube Addons for CKA Practice","text":"<pre><code># Metrics Server (for kubectl top)\nminikube addons enable metrics-server\n\n# Ingress Controller\nminikube addons enable ingress\n\n# Storage Provisioner (dynamic PVs)\nminikube addons enable storage-provisioner\n\n# Dashboard\nminikube addons enable dashboard\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubectl-installation-and-configuration","title":"kubectl Installation and Configuration","text":"<p>kubectl is the Kubernetes command-line tool. Mastery is essential for CKA exam success.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#installation_2","title":"Installation","text":"<p>Linux: <pre><code># Download latest release\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\n# Install\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# Verify\nkubectl version --client\n</code></pre></p> <p>macOS: <pre><code># Using Homebrew\nbrew install kubectl\n\n# Verify\nkubectl version --client\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#version-compatibility","title":"Version Compatibility","text":"<p>kubectl version must be within \u00b11 minor version of cluster version.</p> <pre><code># Check versions\nkubectl version --short\n\n# Example compatible versions:\n# Cluster: v1.34.0\n# kubectl: v1.33.x, v1.34.x, v1.35.x \u2705\n# kubectl: v1.32.x, v1.36.x \u274c\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#shell-completion-setup-critical-for-exam-speed","title":"Shell Completion Setup (CRITICAL for Exam Speed)","text":"<p>Bash (Linux): <pre><code># Install bash-completion package\nsudo apt-get install bash-completion\n\n# Add completion to current shell\nsource &lt;(kubectl completion bash)\n\n# Add to .bashrc for persistence\necho 'source &lt;(kubectl completion bash)' &gt;&gt; ~/.bashrc\n\n# Alias completion (essential for exam)\necho 'alias k=kubectl' &gt;&gt; ~/.bashrc\necho 'complete -o default -F __start_kubectl k' &gt;&gt; ~/.bashrc\n\n# Reload\nsource ~/.bashrc\n</code></pre></p> <p>Zsh: <pre><code># Add completion to .zshrc\necho 'source &lt;(kubectl completion zsh)' &gt;&gt; ~/.zshrc\n\n# Alias completion\necho 'alias k=kubectl' &gt;&gt; ~/.zshrc\necho 'complete -o default -F __start_kubectl k' &gt;&gt; ~/.zshrc\n\n# Reload\nsource ~/.zshrc\n</code></pre></p> <p>Exam Tip</p> <p>Practice using <code>k</code> instead of <code>kubectl</code> extensively. Tab completion saves critical minutes during the exam.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeconfig-management","title":"kubeconfig Management","text":"<p>kubeconfig files contain cluster connection details. Managing multiple clusters efficiently is essential for the exam.</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeconfig-file-structure","title":"kubeconfig File Structure","text":"<pre><code>apiVersion: v1\nkind: Config\ncurrent-context: my-cluster\n\nclusters:\n- cluster:\n    certificate-authority-data: &lt;base64-encoded-ca&gt;\n    server: https://192.168.1.100:6443\n  name: my-cluster\n\nusers:\n- name: my-user\n  user:\n    client-certificate-data: &lt;base64-encoded-cert&gt;\n    client-key-data: &lt;base64-encoded-key&gt;\n\ncontexts:\n- context:\n    cluster: my-cluster\n    user: my-user\n    namespace: default\n  name: my-cluster-context\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#context-management-flow","title":"Context Management Flow","text":"<pre><code>graph TB\n    subgraph \"kubeconfig File\"\n        Clusters[Clusters&lt;br/&gt;- prod-cluster&lt;br/&gt;- dev-cluster&lt;br/&gt;- cka-cluster]\n        Users[Users&lt;br/&gt;- admin-user&lt;br/&gt;- dev-user&lt;br/&gt;- readonly-user]\n        Contexts[Contexts&lt;br/&gt;- prod-admin&lt;br/&gt;- dev-user&lt;br/&gt;- cka-practice]\n        CurrentContext[Current Context:&lt;br/&gt;cka-practice]\n    end\n\n    subgraph \"Context: cka-practice\"\n        CKACluster[Cluster: cka-cluster]\n        CKAUser[User: admin-user]\n        CKANamespace[Namespace: default]\n    end\n\n    subgraph \"Actual Clusters\"\n        ProdCluster[Production&lt;br/&gt;10.0.1.100:6443]\n        DevCluster[Development&lt;br/&gt;10.0.2.100:6443]\n        CKAClusterActual[CKA Lab&lt;br/&gt;10.0.3.100:6443]\n    end\n\n    Contexts --&gt; CurrentContext\n    CurrentContext --&gt; CKACluster\n    CurrentContext --&gt; CKAUser\n    CurrentContext --&gt; CKANamespace\n\n    CKACluster -.-&gt;|kubectl commands| CKAClusterActual\n\n    style CurrentContext fill:#ffff99\n    style CKAClusterActual fill:#99ff99</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#essential-context-commands","title":"Essential Context Commands","text":"<pre><code># List all contexts\nkubectl config get-contexts\n\n# Show current context\nkubectl config current-context\n\n# Switch context\nkubectl config use-context cka-practice\n\n# Set default namespace for current context\nkubectl config set-context --current --namespace=kube-system\n\n# Create new context\nkubectl config set-context dev-user \\\n  --cluster=dev-cluster \\\n  --namespace=development \\\n  --user=dev-user\n\n# Rename context\nkubectl config rename-context old-name new-name\n\n# Delete context\nkubectl config delete-context old-context\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#multiple-cluster-management","title":"Multiple Cluster Management","text":"<p>Strategy 1: Merged Configuration (Recommended for Exam):</p> <pre><code># Merge multiple kubeconfig files\nexport KUBECONFIG=~/.kube/config:~/.kube/dev-config:~/.kube/prod-config\nkubectl config view --flatten &gt; ~/.kube/merged-config\n\n# Set as default\nexport KUBECONFIG=~/.kube/merged-config\n\n# Add to .bashrc for persistence\necho 'export KUBECONFIG=~/.kube/merged-config' &gt;&gt; ~/.bashrc\n</code></pre> <p>Strategy 2: Context-Specific Commands:</p> <pre><code># Use specific context for single command\nkubectl --context=prod-cluster get nodes\n\n# Use specific kubeconfig for single command\nkubectl --kubeconfig=~/.kube/prod-config get pods\n\n# Override namespace for single command\nkubectl -n kube-system get pods\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#security-best-practices","title":"Security Best Practices","text":"<pre><code># Protect kubeconfig files\nchmod 600 ~/.kube/config\nchmod 0400 ~/.kube/prod-config  # Read-only for production\n\n# Never commit kubeconfig to version control\necho '.kube/' &gt;&gt; ~/.gitignore\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#common-exam-tasks","title":"Common Exam Tasks","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#scenario-1-rapid-cluster-setup-for-practice","title":"Scenario 1: Rapid Cluster Setup for Practice","text":"<p>Objective: Create disposable cluster for practice scenario</p> <pre><code># Create kind cluster\ncat &lt;&lt;EOF | kind create cluster --config=-\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\nEOF\n\n# Verify cluster ready\nkubectl get nodes\n\n# Practice exam task\nkubectl run nginx --image=nginx\nkubectl expose pod nginx --port=80 --type=NodePort\n\n# Clean up when done\nkind delete cluster\n</code></pre> <p>Time: 30-60 seconds for cluster creation</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#scenario-2-multi-cluster-context-switching","title":"Scenario 2: Multi-Cluster Context Switching","text":"<p>Objective: Practice switching between exam cluster contexts</p> <pre><code># Assume exam provides contexts: cluster1-context, cluster2-context\n\n# List available contexts\nkubectl config get-contexts\n\n# Switch to cluster1\nkubectl config use-context cluster1-context\n\n# Verify current context\nkubectl config current-context\n\n# Deploy to cluster1\nkubectl run web --image=nginx\n\n# Switch to cluster2\nkubectl config use-context cluster2-context\n\n# Deploy to cluster2\nkubectl run database --image=postgres\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#scenario-3-troubleshoot-cni-issues","title":"Scenario 3: Troubleshoot CNI Issues","text":"<p>Objective: Fix cluster networking</p> <pre><code># Check node status\nkubectl get nodes\n# NAME     STATUS     ROLES           AGE   VERSION\n# node-1   NotReady   control-plane   2m    v1.34.0\n\n# Check system pods\nkubectl -n kube-system get pods\n\n# Verify CNI config exists\nkubectl exec -n kube-system &lt;any-pod&gt; -- ls /etc/cni/net.d/\n\n# If empty, install CNI\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Verify nodes transition to Ready\nkubectl get nodes --watch\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#cni-network-communication","title":"CNI Network Communication","text":"<p>Understanding how CNI plugins enable pod-to-pod communication is critical for troubleshooting.</p> <pre><code>sequenceDiagram\n    participant Pod1 as Pod 1&lt;br/&gt;10.244.1.5&lt;br/&gt;Node1\n    participant CNI1 as CNI Plugin&lt;br/&gt;Node1\n    participant CNI2 as CNI Plugin&lt;br/&gt;Node2\n    participant Pod2 as Pod 2&lt;br/&gt;10.244.2.8&lt;br/&gt;Node2\n\n    Note over Pod1,Pod2: Pod-to-Pod Communication Across Nodes\n\n    Pod1-&gt;&gt;CNI1: Send packet to 10.244.2.8\n    CNI1-&gt;&gt;CNI1: Check routing table&lt;br/&gt;Pod CIDR 10.244.0.0/16\n    CNI1-&gt;&gt;CNI2: Forward via overlay network&lt;br/&gt;(VXLAN/BGP)\n    CNI2-&gt;&gt;CNI2: Lookup destination pod&lt;br/&gt;10.244.2.8 on Node2\n    CNI2-&gt;&gt;Pod2: Deliver packet\n    Pod2-&gt;&gt;CNI2: Send response\n    CNI2-&gt;&gt;CNI1: Return via overlay\n    CNI1-&gt;&gt;Pod1: Deliver response\n\n    Note over CNI1,CNI2: CNI ensures IP reachability&lt;br/&gt;without NodePort/Service</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#practice-exercises","title":"Practice Exercises","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-1-complete-kubeadm-cluster-setup-60-minutes","title":"Exercise 1: Complete kubeadm Cluster Setup (60 minutes)","text":"<p>Objective: Build production-like 3-node cluster</p> <p>Tasks: 1. Prepare 3 VMs (1 control plane, 2 workers) 2. Disable swap on all nodes 3. Install container runtime 4. Install kubeadm, kubelet, kubectl 5. Initialize control plane with Calico pod CIDR 6. Install Calico CNI 7. Join worker nodes 8. Verify all nodes Ready 9. Deploy test workload</p> <p>Success Criteria: - All 3 nodes show Ready status - CNI pods running in calico-system namespace - Test pod can communicate across nodes</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-2-kind-multi-node-lab-20-minutes","title":"Exercise 2: kind Multi-Node Lab (20 minutes)","text":"<p>Objective: Create multi-node cluster for rapid testing</p> <p>Tasks: 1. Create kind config for 3-node cluster 2. Map NodePort 30000 to localhost:8080 3. Create cluster 4. Deploy nginx with NodePort 30000 5. Access from host browser 6. Test pod scheduling across workers 7. Delete and recreate cluster</p> <p>Success Criteria: - Cluster creation completes in &lt;60 seconds - Nginx accessible on localhost:8080 - Can repeat cycle 5 times in 10 minutes</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-3-kubeconfig-context-mastery-30-minutes","title":"Exercise 3: kubeconfig Context Mastery (30 minutes)","text":"<p>Objective: Manage multiple clusters efficiently</p> <p>Tasks: 1. Create 3 different clusters (kubeadm, kind, minikube) 2. Export kubeconfig from each 3. Merge into single kubeconfig 4. Rename contexts meaningfully 5. Set default namespace per context 6. Practice rapid context switching 7. Deploy workload to specific context without switching</p> <p>Success Criteria: - Switch contexts in &lt;5 seconds - Deploy to specific cluster without errors - Verify deployment in correct cluster</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-4-shell-completion-and-aliases-15-minutes","title":"Exercise 4: Shell Completion and Aliases (15 minutes)","text":"<p>Objective: Optimize kubectl workflow for exam speed</p> <p>Tasks: 1. Install bash-completion 2. Configure kubectl completion 3. Test tab completion 4. Create aliases: k, kg, kd, kl 5. Configure alias completion 6. Time yourself: deploy nginx with and without aliases</p> <p>Success Criteria: - Tab completion works for resources - Aliases reduce command length by 50%+ - Muscle memory for common patterns</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#exercise-5-troubleshooting-simulation-45-minutes","title":"Exercise 5: Troubleshooting Simulation (45 minutes)","text":"<p>Objective: Diagnose and fix common cluster issues</p> <p>Tasks: 1. Initialize cluster WITHOUT CNI 2. Observe NotReady nodes 3. Check kubelet logs for errors 4. Identify CNI-related messages 5. Install CNI plugin 6. Verify nodes transition to Ready 7. Test pod communication 8. Break and fix: stop kubelet, observe effects 9. Break and fix: remove CNI config, restore</p> <p>Success Criteria: - Can identify CNI issues from logs - Successfully install and verify CNI - Understand node status transitions - Troubleshooting workflow muscle memory</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#lab-environment-comparison","title":"Lab Environment Comparison","text":"<pre><code>graph TD\n    subgraph \"Setup Method Comparison\"\n        Feature[Feature]\n        kubeadm[kubeadm]\n        minikube[Minikube]\n        kind[kind]\n    end\n\n    Feature --&gt; |Startup Time| Time\n    Time --&gt; kubeadm_time[5-10 min&lt;br/&gt;Multi-machine]\n    Time --&gt; minikube_time[2-5 min&lt;br/&gt;VM boot]\n    Time --&gt; kind_time[30-60 sec&lt;br/&gt;Containers]\n\n    Feature --&gt; |Resource Usage| Resources\n    Resources --&gt; kubeadm_res[High&lt;br/&gt;Real VMs]\n    Resources --&gt; minikube_res[Medium&lt;br/&gt;Single VM]\n    Resources --&gt; kind_res[Low&lt;br/&gt;Docker only]\n\n    Feature --&gt; |Multi-Node| MultiNode\n    MultiNode --&gt; kubeadm_mn[Native&lt;br/&gt;Production-like]\n    MultiNode --&gt; minikube_mn[Experimental&lt;br/&gt;Limited]\n    MultiNode --&gt; kind_mn[Native&lt;br/&gt;Config-based]\n\n    Feature --&gt; |CKA Relevance| CKA\n    CKA --&gt; kubeadm_cka[Essential&lt;br/&gt;Exam environment]\n    CKA --&gt; minikube_cka[Supplemental&lt;br/&gt;Learning]\n    CKA --&gt; kind_cka[High&lt;br/&gt;Practice speed]\n\n    style kind_time fill:#99ff99\n    style kind_res fill:#99ff99\n    style kubeadm_mn fill:#ff9999\n    style kubeadm_cka fill:#ff9999</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#quick-reference-commands","title":"Quick Reference Commands","text":"","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubeadm-cluster-lifecycle","title":"kubeadm Cluster Lifecycle","text":"<pre><code># Initialize control plane\nsudo kubeadm init --pod-network-cidr=10.244.0.0/16\n\n# Configure kubectl\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n# Install CNI (Calico)\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml\n\n# Generate join command\nkubeadm token create --print-join-command\n\n# Reset cluster\nsudo kubeadm reset\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kind-quick-start","title":"kind Quick Start","text":"<pre><code># Create cluster\nkind create cluster --name cka-lab\n\n# Create multi-node cluster\ncat &lt;&lt;EOF | kind create cluster --config=-\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\nEOF\n\n# Delete cluster\nkind delete cluster --name cka-lab\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#minikube-quick-start","title":"Minikube Quick Start","text":"<pre><code># Start with resource spec\nminikube start --driver=docker --cpus=4 --memory=8192\n\n# Enable addons\nminikube addons enable metrics-server\nminikube addons enable ingress\n\n# Access service\nminikube service &lt;service-name&gt;\n\n# Clean up\nminikube delete\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#kubectl-context-management","title":"kubectl Context Management","text":"<pre><code># View contexts\nkubectl config get-contexts\n\n# Switch context\nkubectl config use-context &lt;context-name&gt;\n\n# Set namespace\nkubectl config set-context --current --namespace=&lt;namespace&gt;\n\n# Context-specific command\nkubectl --context=&lt;context&gt; get pods\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#troubleshooting-commands","title":"Troubleshooting Commands","text":"<pre><code># Check cluster health\nkubectl get nodes -o wide\nkubectl -n kube-system get pods\n\n# View kubelet logs (on node)\nsudo journalctl -u kubelet -f\n\n# Check CNI config\nls -l /etc/cni/net.d/\n\n# View events\nkubectl get events --sort-by='.lastTimestamp'\n\n# Check etcd health\nsudo ETCDCTL_API=3 etcdctl \\\n  --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\n  endpoint health\n</code></pre>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 kubeadm is essential for CKA - The exam environment uses kubeadm clusters</p> <p>\u2705 kind enables rapid iteration - 30-second cluster creation for practice</p> <p>\u2705 kubectl proficiency is critical - Shell completion and aliases save exam minutes</p> <p>\u2705 kubeconfig mastery matters - Context switching is a core exam skill</p> <p>\u2705 CNI is non-negotiable - Clusters are non-functional without CNI plugins</p> <p>\u2705 Swap must be disabled - Kubernetes does not support swap memory</p> <p>\u2705 Version compatibility awareness - kubectl and cluster versions must align</p> <p>\u2705 Hands-on practice wins - Deploy clusters repeatedly until muscle memory forms</p> <p>\u2705 Troubleshooting is 30% of CKA - Practice breaking and fixing clusters</p> <p>\u2705 Speed through preparation - Optimize workflow before exam day</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/setting-up-kubernetes-lab/#next-steps","title":"Next Steps","text":"<p>After mastering lab setup, continue with:</p> <p>Post 3: kubectl Essentials and Resource Management - Master the command-line tool for all Kubernetes operations</p> <p>Related Posts: - Kubernetes Architecture Fundamentals - Understanding cluster components - Kubernetes CKA Mastery - Complete Learning Path - Full exam preparation series</p> <p>External Resources: - kubeadm Official Documentation - kind Quick Start Guide - Minikube Documentation - kubectl Cheat Sheet - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","kubeadm","kubectl","minikube"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/","title":"Understanding Kubernetes Objects and YAML Manifests","text":"<p>Master the foundation of Kubernetes declarative configuration. Learn object anatomy, YAML syntax, labels, selectors, and annotations for CKA exam success and production deployments.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#overview","title":"Overview","text":"<p>Kubernetes objects are persistent entities in the Kubernetes system that represent the desired state of your cluster. Understanding object structure and YAML manifests is fundamental to the CKA exam and real-world Kubernetes administration.</p> <p>CKA Exam Domain: All domains (objects are used everywhere)</p> <p>Key Insight: Every Kubernetes resource you create, modify, or delete is an object with a consistent structure. Mastering this structure enables you to work with any Kubernetes resource confidently.</p> <p>What You'll Learn: - Kubernetes API object model and resource types - YAML syntax fundamentals and best practices - Object anatomy: metadata, spec, status structure - Labels and selectors for resource organization - Annotations for non-identifying metadata - Field validation and troubleshooting strategies</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#kubernetes-object-model","title":"Kubernetes Object Model","text":"<p>Kubernetes uses a declarative model where you describe the desired state, and the control plane works continuously to maintain that state.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#what-is-a-kubernetes-object","title":"What is a Kubernetes Object?","text":"<p>Definition: A Kubernetes object is a persistent entity that represents: - What applications are running (and on which nodes) - How many replicas should exist - Which resources are available to applications - Policies around behavior (restart, upgrades, fault-tolerance)</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#object-categories","title":"Object Categories","text":"<pre><code>graph TB\n    subgraph \"Workload Resources\"\n        POD[Pod]\n        DEPLOY[Deployment]\n        RS[ReplicaSet]\n        SS[StatefulSet]\n        DS[DaemonSet]\n        JOB[Job]\n        CRON[CronJob]\n    end\n\n    subgraph \"Service &amp; Networking\"\n        SVC[Service]\n        ING[Ingress]\n        NP[NetworkPolicy]\n        EP[Endpoints]\n    end\n\n    subgraph \"Configuration &amp; Storage\"\n        CM[ConfigMap]\n        SECRET[Secret]\n        PV[PersistentVolume]\n        PVC[PersistentVolumeClaim]\n        SC[StorageClass]\n    end\n\n    subgraph \"Cluster Resources\"\n        NS[Namespace]\n        NODE[Node]\n        SA[ServiceAccount]\n        ROLE[Role/ClusterRole]\n    end\n\n    DEPLOY --&gt; RS\n    RS --&gt; POD\n    SS --&gt; POD\n    DS --&gt; POD\n    SVC --&gt; POD\n    ING --&gt; SVC\n\n    style POD fill:#e1f5ff\n    style DEPLOY fill:#e8f5e8\n    style SVC fill:#fff4e1\n    style CM fill:#f5e1ff</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#object-lifecycle","title":"Object Lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Desired: User creates manifest\n\n    Desired --&gt; Submitted: kubectl apply\n    Submitted --&gt; Validated: API server validates\n\n    Validated --&gt; Rejected: Validation fails\n    Rejected --&gt; [*]\n\n    Validated --&gt; Persisted: Write to etcd\n    Persisted --&gt; Scheduled: Controller processes\n    Scheduled --&gt; Running: Kubelet executes\n\n    Running --&gt; Updated: User modifies\n    Updated --&gt; Validated\n\n    Running --&gt; Deleted: User deletes\n    Deleted --&gt; [*]\n\n    Running --&gt; Running: System reconciles</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#object-anatomy-the-four-essential-fields","title":"Object Anatomy: The Four Essential Fields","text":"<p>Every Kubernetes object manifest contains four top-level fields:</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#complete-object-structure","title":"Complete Object Structure","text":"<pre><code>apiVersion: apps/v1              # 1. API version\nkind: Deployment                 # 2. Object type\nmetadata:                        # 3. Identifying metadata\n  name: nginx-deployment\n  namespace: production\n  labels:\n    app: nginx\n    tier: frontend\n  annotations:\n    description: \"Production web server\"\nspec:                            # 4. Desired state\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n        ports:\n        - containerPort: 80\nstatus:                          # System-managed current state\n  availableReplicas: 3\n  readyReplicas: 3\n  observedGeneration: 1\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#1-apiversion","title":"1. apiVersion","text":"<p>Purpose: Specifies the API group and version for the object type.</p> <p>Format: <code>&lt;group&gt;/&lt;version&gt;</code> or just <code>&lt;version&gt;</code> for core API</p> <p>Common API Versions: <pre><code># Core API (no group)\nv1                              # Pod, Service, ConfigMap, Secret, Namespace\n\n# Apps API\napps/v1                         # Deployment, StatefulSet, DaemonSet, ReplicaSet\n\n# Batch API\nbatch/v1                        # Job, CronJob\n\n# Networking API\nnetworking.k8s.io/v1           # Ingress, NetworkPolicy\n\n# RBAC API\nrbac.authorization.k8s.io/v1   # Role, ClusterRole, RoleBinding\n\n# Storage API\nstorage.k8s.io/v1              # StorageClass, VolumeAttachment\n</code></pre></p> <p>Finding API Versions: <pre><code># List all API resources and versions\nkubectl api-resources\n\n# Check specific resource\nkubectl explain deployment | head -5\n# KIND:       Deployment\n# VERSION:    apps/v1\n\n# List all API versions\nkubectl api-versions\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#2-kind","title":"2. kind","text":"<p>Purpose: Identifies the type of object being created.</p> <p>Common Object Kinds: - Workloads: Pod, Deployment, StatefulSet, DaemonSet, Job, CronJob - Services: Service, Ingress, Endpoints - Configuration: ConfigMap, Secret - Storage: PersistentVolume, PersistentVolumeClaim, StorageClass - Cluster: Namespace, Node, ServiceAccount - Access: Role, ClusterRole, RoleBinding, ClusterRoleBinding</p> <p>Case Sensitivity: Kind names are case-sensitive (must be exact capitalization).</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#3-metadata","title":"3. metadata","text":"<p>Purpose: Data that uniquely identifies the object.</p> <p>Required Fields: - <code>name</code> - Unique within namespace and object type - <code>namespace</code> - (optional for cluster-scoped resources)</p> <p>Common Optional Fields: - <code>labels</code> - Key-value pairs for organization and selection - <code>annotations</code> - Non-identifying metadata - <code>uid</code> - System-generated unique identifier - <code>resourceVersion</code> - Internal version for optimistic concurrency - <code>creationTimestamp</code> - When object was created</p> <p>Metadata Example: <pre><code>metadata:\n  name: webapp                           # Required: object name\n  namespace: production                  # Namespace (required for namespaced resources)\n  labels:                                # Labels for selection\n    app: webapp\n    tier: frontend\n    version: \"2.0\"\n    environment: production\n  annotations:                           # Annotations for metadata\n    description: \"Main production web application\"\n    owner: \"platform-team@company.com\"\n    version: \"2.0.1\"\n    deployment-date: \"2024-01-15\"\n  uid: 12345678-1234-1234-1234-123456789012    # System-generated\n  resourceVersion: \"1234567\"             # System-managed version\n  creationTimestamp: \"2024-01-15T10:30:00Z\"  # System-generated\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#4-spec","title":"4. spec","text":"<p>Purpose: Describes the desired state of the object.</p> <p>Characteristics: - Varies by object <code>kind</code> - User-defined and user-managed - Controller reads spec to understand desired state - Declarative: describes \"what\", not \"how\"</p> <p>Pod Spec Example: <pre><code>spec:\n  containers:\n  - name: nginx\n    image: nginx:1.21\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 200m\n        memory: 256Mi\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 80\n      initialDelaySeconds: 30\n      periodSeconds: 10\n  restartPolicy: Always\n  nodeSelector:\n    disk: ssd\n</code></pre></p> <p>Deployment Spec Example: <pre><code>spec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:                    # Pod template\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#5-status-system-managed","title":"5. status (System-Managed)","text":"<p>Purpose: Describes the current observed state of the object.</p> <p>Characteristics: - Read-only for users - Managed by Kubernetes controllers - Updated continuously by the control plane - Represents actual state vs desired state (spec)</p> <p>Pod Status Example: <pre><code>status:\n  phase: Running               # Pod lifecycle phase\n  conditions:                  # Detailed status conditions\n  - type: Initialized\n    status: \"True\"\n    lastTransitionTime: \"2024-01-15T10:30:05Z\"\n  - type: Ready\n    status: \"True\"\n    lastTransitionTime: \"2024-01-15T10:30:10Z\"\n  - type: ContainersReady\n    status: \"True\"\n    lastTransitionTime: \"2024-01-15T10:30:10Z\"\n  - type: PodScheduled\n    status: \"True\"\n    lastTransitionTime: \"2024-01-15T10:30:00Z\"\n  containerStatuses:\n  - name: nginx\n    ready: true\n    restartCount: 0\n    state:\n      running:\n        startedAt: \"2024-01-15T10:30:08Z\"\n  hostIP: 192.168.1.100\n  podIP: 10.244.1.50\n  startTime: \"2024-01-15T10:30:00Z\"\n</code></pre></p> <p>Deployment Status Example: <pre><code>status:\n  availableReplicas: 3\n  readyReplicas: 3\n  replicas: 3\n  updatedReplicas: 3\n  observedGeneration: 5\n  conditions:\n  - type: Available\n    status: \"True\"\n    reason: MinimumReplicasAvailable\n  - type: Progressing\n    status: \"True\"\n    reason: NewReplicaSetAvailable\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#yaml-syntax-fundamentals","title":"YAML Syntax Fundamentals","text":"<p>YAML (YAML Ain't Markup Language) is the standard format for Kubernetes manifests.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#yaml-basics","title":"YAML Basics","text":"<p>Data Types: <pre><code># Strings\nname: nginx-deployment\ndescription: \"Multi-word string in quotes\"\nmultiline: |\n  This is a multi-line string\n  that preserves newlines\n\n# Numbers\nreplicas: 3\nport: 80\ncpu: 0.5\n\n# Booleans\nenabled: true\ndebug: false\n\n# Lists (arrays)\nargs:\n- \"arg1\"\n- \"arg2\"\n- \"arg3\"\n\n# Or inline\nargs: [\"arg1\", \"arg2\", \"arg3\"]\n\n# Maps (key-value pairs)\nlabels:\n  app: nginx\n  tier: frontend\n\n# Nested structures\nmetadata:\n  labels:\n    app: nginx\n  annotations:\n    description: \"Production app\"\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#indentation-rules","title":"Indentation Rules","text":"<p>Critical: YAML uses spaces only (no tabs) for indentation.</p> <pre><code># CORRECT - 2 spaces per level\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\n    tier: frontend\n\n# CORRECT - 4 spaces also works (be consistent)\nmetadata:\n    name: nginx\n    labels:\n        app: nginx\n\n# WRONG - mixing tabs and spaces\nmetadata:\n    name: nginx        # Tab used (will fail)\n  labels:\n    app: nginx       # Spaces used\n</code></pre> <p>Best Practice: Use 2-space indentation consistently.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#common-yaml-patterns","title":"Common YAML Patterns","text":"<p>Lists of Objects: <pre><code>containers:\n- name: nginx                   # First container\n  image: nginx:1.21\n  ports:\n  - containerPort: 80\n- name: sidecar                 # Second container\n  image: busybox:latest\n  command: [\"sh\", \"-c\", \"sleep 3600\"]\n</code></pre></p> <p>Multi-line Strings: <pre><code># Literal block (preserves newlines)\nscript: |\n  #!/bin/bash\n  echo \"Line 1\"\n  echo \"Line 2\"\n\n# Folded block (newlines become spaces)\ndescription: &gt;\n  This is a very long description\n  that spans multiple lines but\n  will be folded into a single line.\n\n# Result: \"This is a very long description that spans multiple lines...\"\n</code></pre></p> <p>Environment Variables: <pre><code>env:\n- name: DATABASE_HOST\n  value: \"mysql.default.svc.cluster.local\"\n- name: DATABASE_PORT\n  value: \"3306\"\n- name: DATABASE_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: db-secret\n      key: password\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#yaml-validation","title":"YAML Validation","text":"<p>Common Errors:</p> <pre><code># ERROR: Missing colon\nmetadata\n  name: nginx         # Should be \"metadata:\"\n\n# ERROR: Wrong indentation\nmetadata:\n  name: nginx\n labels:              # Misaligned (should be 2 spaces)\n   app: nginx\n\n# ERROR: Missing quotes for special characters\nannotation: \"true\"   # Boolean - needs quotes to be string\nannotation: true     # Boolean value\n\n# ERROR: List item indentation\ncontainers:\n  - name: nginx      # Correct\n- name: sidecar      # Wrong (should align with first item)\n</code></pre> <p>Validation Tools: <pre><code># kubectl validates before applying\nkubectl apply --dry-run=client -f manifest.yaml\n\n# Check syntax only\nkubectl apply --dry-run=server -f manifest.yaml\n\n# Use yamllint for detailed validation\nyamllint manifest.yaml\n\n# Python YAML validation\npython -c 'import yaml, sys; yaml.safe_load(sys.stdin)' &lt; manifest.yaml\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#labels-organizing-and-selecting-resources","title":"Labels: Organizing and Selecting Resources","text":"<p>Labels are key-value pairs attached to objects for identification and grouping.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#label-syntax","title":"Label Syntax","text":"<p>Format: <code>key: value</code></p> <p>Key Syntax: - Optional prefix: <code>&lt;prefix&gt;/&lt;name&gt;</code> (prefix \u2264 253 chars, name \u2264 63 chars) - Name: alphanumeric, <code>-</code>, <code>_</code>, <code>.</code> (must start/end with alphanumeric)</p> <p>Value Syntax: - \u2264 63 characters - Alphanumeric, <code>-</code>, <code>_</code>, <code>.</code> (can be empty)</p> <p>Examples: <pre><code>labels:\n  # Simple labels\n  app: nginx\n  tier: frontend\n  environment: production\n\n  # Prefixed labels (for third-party tools)\n  example.com/team: platform\n  app.kubernetes.io/name: nginx\n  app.kubernetes.io/version: \"1.21\"\n\n  # Valid special characters\n  app.version: \"2.0.1\"\n  team_name: platform-team\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#recommended-labels","title":"Recommended Labels","text":"<p>Kubernetes recommends a standard set of labels for consistency:</p> <pre><code>metadata:\n  labels:\n    # Application identity\n    app.kubernetes.io/name: nginx                    # Application name\n    app.kubernetes.io/instance: nginx-prod           # Unique instance\n    app.kubernetes.io/version: \"1.21.0\"             # Application version\n    app.kubernetes.io/component: webserver           # Component role\n    app.kubernetes.io/part-of: ecommerce-platform   # Parent application\n\n    # Management metadata\n    app.kubernetes.io/managed-by: helm              # Management tool\n\n    # Custom organizational labels\n    team: platform\n    cost-center: engineering\n    environment: production\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#label-use-cases","title":"Label Use Cases","text":"<p>1. Resource Organization: <pre><code># Development pods\nmetadata:\n  labels:\n    environment: dev\n    team: backend\n\n# Production pods\nmetadata:\n  labels:\n    environment: production\n    team: backend\n</code></pre></p> <p>2. Service Selection: <pre><code># Service selects pods with matching labels\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: nginx           # Selects all pods with app=nginx\n    tier: frontend\n  ports:\n  - port: 80\n</code></pre></p> <p>3. Deployment Management: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx        # Deployment manages pods with this label\n  template:\n    metadata:\n      labels:\n        app: nginx      # Pods get this label\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#label-operations","title":"Label Operations","text":"<p>View Labels: <pre><code># Show labels column\nkubectl get pods --show-labels\n\n# Show specific labels as columns\nkubectl get pods -L app,tier,environment\n\n# Filter output\nkubectl get pods -l app=nginx\nkubectl get pods -l 'environment in (dev,staging)'\nkubectl get pods -l app=nginx,tier!=backend\n</code></pre></p> <p>Add/Modify Labels: <pre><code># Add label\nkubectl label pod nginx-pod version=1.0\n\n# Modify label (requires --overwrite)\nkubectl label pod nginx-pod version=2.0 --overwrite\n\n# Add label to all pods\nkubectl label pods --all environment=production\n\n# Remove label\nkubectl label pod nginx-pod version-\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#selectors-matching-resources","title":"Selectors: Matching Resources","text":"<p>Selectors use labels to identify sets of objects.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#selector-types","title":"Selector Types","text":"<pre><code>graph TB\n    SELECTOR[Label Selectors] --&gt; EQUALITY[Equality-Based]\n    SELECTOR --&gt; SET[Set-Based]\n\n    EQUALITY --&gt; EQ[Equal: =, ==]\n    EQUALITY --&gt; NEQ[Not Equal: !=]\n\n    SET --&gt; IN[In: in (...)]\n    SET --&gt; NOTIN[Not In: notin (...)]\n    SET --&gt; EXISTS[Exists: key]\n    SET --&gt; NOTEXISTS[Not Exists: !key]\n\n    style EQUALITY fill:#e1f5ff\n    style SET fill:#e8f5e8</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#equality-based-selectors","title":"Equality-Based Selectors","text":"<p>Syntax: <code>key=value</code> or <code>key!=value</code></p> <p>Command-Line Examples: <pre><code># Single equality\nkubectl get pods -l app=nginx\n\n# Multiple conditions (AND logic)\nkubectl get pods -l app=nginx,tier=frontend\n\n# Not equal\nkubectl get pods -l app=nginx,environment!=production\n</code></pre></p> <p>Manifest Examples: <pre><code># Service selector (equality-based only)\nselector:\n  app: nginx\n  tier: frontend\n\n# Equivalent to:\n# app=nginx AND tier=frontend\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#set-based-selectors","title":"Set-Based Selectors","text":"<p>Syntax: More expressive matching with <code>in</code>, <code>notin</code>, <code>exists</code></p> <p>Command-Line Examples: <pre><code># In set\nkubectl get pods -l 'environment in (dev,staging)'\n\n# Not in set\nkubectl get pods -l 'tier notin (cache,db)'\n\n# Label exists\nkubectl get pods -l app\n\n# Label does not exist\nkubectl get pods -l '!app'\n\n# Complex combination\nkubectl get pods -l 'environment in (prod),tier notin (cache),app'\n</code></pre></p> <p>Manifest Examples: <pre><code># Deployment selector (supports both)\nselector:\n  matchLabels:                    # Equality-based\n    app: nginx\n  matchExpressions:               # Set-based\n  - key: tier\n    operator: In\n    values:\n    - frontend\n    - api\n  - key: environment\n    operator: NotIn\n    values:\n    - testing\n  - key: critical\n    operator: Exists\n  - key: deprecated\n    operator: DoesNotExist\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#selector-operators","title":"Selector Operators","text":"Operator Description Example <code>In</code> Value in set <code>tier in (frontend, api)</code> <code>NotIn</code> Value not in set <code>env notin (test, dev)</code> <code>Exists</code> Label exists <code>critical</code> (key exists) <code>DoesNotExist</code> Label doesn't exist <code>!deprecated</code> (key absent)","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#selector-matching-logic","title":"Selector Matching Logic","text":"<pre><code>flowchart TD\n    START([Resource with Labels]) --&gt; CHECK1{matchLabels&lt;br/&gt;satisfied?}\n\n    CHECK1 --&gt;|No| NOMATCH[No Match]\n    CHECK1 --&gt;|Yes| CHECK2{matchExpressions&lt;br/&gt;all true?}\n\n    CHECK2 --&gt;|No| NOMATCH\n    CHECK2 --&gt;|Yes| MATCH[Match Found]\n\n    MATCH --&gt; SELECTED[Resource Selected]\n    NOMATCH --&gt; IGNORED[Resource Ignored]\n\n    style MATCH fill:#e8f5e8\n    style NOMATCH fill:#ffe5e5</code></pre> <p>Example: <pre><code># Pod labels\nmetadata:\n  labels:\n    app: nginx\n    tier: frontend\n    environment: production\n    version: \"2.0\"\n\n# Selector\nselector:\n  matchLabels:\n    app: nginx                    # \u2705 Match\n  matchExpressions:\n  - key: tier\n    operator: In\n    values: [frontend, api]       # \u2705 Match (tier=frontend)\n  - key: environment\n    operator: NotIn\n    values: [dev, test]           # \u2705 Match (production not in list)\n  - key: version\n    operator: Exists              # \u2705 Match (version label exists)\n\n# Result: Pod matches selector\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#annotations-non-identifying-metadata","title":"Annotations: Non-Identifying Metadata","text":"<p>Annotations store arbitrary metadata that doesn't identify or select objects.</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#annotations-vs-labels","title":"Annotations vs Labels","text":"Aspect Labels Annotations Purpose Identify and select Store metadata Selectable Yes (with selectors) No Size Limit 63 chars (value) 256 KB (total) Structure Simple key-value Can store JSON, YAML Use Case Grouping, selection Documentation, config","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#annotation-syntax","title":"Annotation Syntax","text":"<p>Format: Same as labels but values can be larger and more complex</p> <pre><code>metadata:\n  annotations:\n    # Documentation\n    description: \"Production Nginx deployment with 3 replicas\"\n    owner: \"platform-team@company.com\"\n    documentation: \"https://wiki.company.com/nginx-deployment\"\n\n    # Build information\n    build-version: \"2.0.1\"\n    git-commit: \"a3f2b1c\"\n    ci-pipeline: \"https://jenkins.company.com/job/nginx/123\"\n\n    # Operational metadata\n    deployment-date: \"2024-01-15T10:30:00Z\"\n    last-updated-by: \"john.doe@company.com\"\n\n    # Tool-specific configuration\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9090\"\n    prometheus.io/path: \"/metrics\"\n\n    # JSON configuration\n    custom-config: '{\"timeout\": 30, \"retries\": 3}'\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#common-annotation-use-cases","title":"Common Annotation Use Cases","text":"<p>1. Tool Integration: <pre><code>annotations:\n  # Prometheus monitoring\n  prometheus.io/scrape: \"true\"\n  prometheus.io/port: \"8080\"\n\n  # Nginx Ingress\n  nginx.ingress.kubernetes.io/rewrite-target: \"/\"\n  nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n\n  # Cert-manager\n  cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n\n  # Istio service mesh\n  sidecar.istio.io/inject: \"true\"\n</code></pre></p> <p>2. Change Tracking: <pre><code>annotations:\n  kubernetes.io/change-cause: \"Update nginx to version 1.21\"\n  deployment.kubernetes.io/revision: \"5\"\n</code></pre></p> <p>3. Documentation: <pre><code>annotations:\n  description: |\n    Main production web server deployment.\n\n    Handles customer-facing traffic with:\n    - 3 replicas for high availability\n    - Rolling update strategy\n    - Health checks configured\n\n    Contact: platform-team@company.com\n\n  runbook: \"https://wiki.company.com/runbooks/nginx-troubleshooting\"\n  oncall: \"https://pagerduty.com/schedules/nginx-team\"\n</code></pre></p> <p>4. Configuration Storage: <pre><code>annotations:\n  # Complex JSON configuration\n  fluentd-config: |\n    {\n      \"outputs\": [\n        {\"type\": \"elasticsearch\", \"host\": \"es.logging.svc\"},\n        {\"type\": \"s3\", \"bucket\": \"logs-backup\"}\n      ]\n    }\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#annotation-operations","title":"Annotation Operations","text":"<pre><code># View annotations\nkubectl describe pod nginx-pod | grep -A 10 \"Annotations:\"\n\n# Add annotation\nkubectl annotate pod nginx-pod description=\"Production web server\"\n\n# Update annotation\nkubectl annotate pod nginx-pod description=\"Updated description\" --overwrite\n\n# Remove annotation\nkubectl annotate pod nginx-pod description-\n\n# Annotate all resources of type\nkubectl annotate deployments --all team=platform\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#field-validation-and-troubleshooting","title":"Field Validation and Troubleshooting","text":"","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#required-vs-optional-fields","title":"Required vs Optional Fields","text":"<p>Required Fields (most common): <pre><code># All objects\napiVersion: apps/v1              # Required\nkind: Deployment                 # Required\nmetadata:\n  name: nginx                    # Required\nspec:                            # Required\n\n# Pod spec\nspec:\n  containers:                    # Required\n  - name: nginx                  # Required\n    image: nginx:1.21            # Required\n\n# Service spec\nspec:\n  selector:                      # Required\n    app: nginx\n  ports:                         # Required\n  - port: 80\n</code></pre></p> <p>Determining Required Fields: <pre><code># Use kubectl explain\nkubectl explain pod.spec\n# FIELDS:\n#   containers    &lt;[]Container&gt; -required-\n#   volumes       &lt;[]Volume&gt;\n\nkubectl explain pod.spec.containers\n# FIELDS:\n#   name          &lt;string&gt; -required-\n#   image         &lt;string&gt; -required-\n#   command       &lt;[]string&gt;        # Optional (no -required-)\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#common-validation-errors","title":"Common Validation Errors","text":"<p>1. Missing Required Field: <pre><code># ERROR: Missing image\nspec:\n  containers:\n  - name: nginx\n    # image: nginx:1.21    # Missing required field\n\n# Error message:\n# error: error validating \"pod.yaml\": error validating data:\n# ValidationError(Pod.spec.containers[0]): missing required field \"image\"\n</code></pre></p> <p>2. Invalid Field Name: <pre><code># ERROR: Typo in field name\nmetadata:\n  name: nginx\n  lables:              # Should be \"labels\"\n    app: nginx\n\n# Error message:\n# error: error validating \"pod.yaml\": error validating data:\n# ValidationError(Pod.metadata): unknown field \"lables\"\n</code></pre></p> <p>3. Wrong Data Type: <pre><code># ERROR: String instead of integer\nspec:\n  replicas: \"3\"        # Should be: replicas: 3\n\n# Error message:\n# error: error validating data: ValidationError(Deployment.spec.replicas):\n# invalid type for io.k8s.api.apps.v1.DeploymentSpec.replicas: got \"string\", expected \"integer\"\n</code></pre></p> <p>4. Invalid Value: <pre><code># ERROR: Invalid restart policy\nspec:\n  restartPolicy: OnError    # Valid: Always, OnFailure, Never\n\n# Error message:\n# error: error validating data: ValidationError(Pod.spec.restartPolicy):\n# unsupported value: \"OnError\": supported values: \"Always\", \"OnFailure\", \"Never\"\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#validation-workflow","title":"Validation Workflow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant kubectl\n    participant API\n    participant Validation\n    participant etcd\n\n    User-&gt;&gt;kubectl: kubectl apply -f manifest.yaml\n    kubectl-&gt;&gt;kubectl: Parse YAML syntax\n\n    alt YAML syntax error\n        kubectl--&gt;&gt;User: Syntax error (invalid YAML)\n    end\n\n    kubectl-&gt;&gt;API: Send parsed object\n    API-&gt;&gt;Validation: Validate object\n\n    Validation-&gt;&gt;Validation: Check required fields\n    Validation-&gt;&gt;Validation: Validate field types\n    Validation-&gt;&gt;Validation: Validate field values\n    Validation-&gt;&gt;Validation: Run admission controllers\n\n    alt Validation fails\n        Validation--&gt;&gt;API: Validation error\n        API--&gt;&gt;User: Error message with details\n    else Validation succeeds\n        Validation-&gt;&gt;etcd: Persist object\n        etcd--&gt;&gt;User: Created/Updated confirmation\n    end</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#troubleshooting-commands","title":"Troubleshooting Commands","text":"<pre><code># Validate YAML without creating\nkubectl apply --dry-run=client -f manifest.yaml\n\n# Server-side validation (includes admission controllers)\nkubectl apply --dry-run=server -f manifest.yaml\n\n# Explain field structure\nkubectl explain deployment.spec.template.spec.containers\n\n# Get field path for specific property\nkubectl explain deployment --recursive | grep -A 5 \"replicas\"\n\n# Validate all manifests in directory\nkubectl apply --dry-run=client -f ./manifests/\n\n# Check API resource availability\nkubectl api-resources | grep -i deployment\n\n# View object in YAML (for comparison)\nkubectl get deployment nginx -o yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#complete-object-examples","title":"Complete Object Examples","text":"","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#example-1-multi-container-pod-with-full-metadata","title":"Example 1: Multi-Container Pod with Full Metadata","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: multi-container-pod\n  namespace: production\n  labels:\n    app: webapp\n    tier: frontend\n    environment: production\n    version: \"2.0\"\n  annotations:\n    description: \"Production web application with logging sidecar\"\n    owner: \"platform-team@company.com\"\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9090\"\nspec:\n  containers:\n  - name: webapp\n    image: nginx:1.21\n    ports:\n    - name: http\n      containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 200m\n        memory: 256Mi\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 80\n      initialDelaySeconds: 30\n      periodSeconds: 10\n    env:\n    - name: ENVIRONMENT\n      value: \"production\"\n  - name: log-forwarder\n    image: fluent/fluent-bit:1.9\n    volumeMounts:\n    - name: logs\n      mountPath: /var/log/nginx\n  volumes:\n  - name: logs\n    emptyDir: {}\n  restartPolicy: Always\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#example-2-deployment-with-complete-selectors","title":"Example 2: Deployment with Complete Selectors","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webapp-deployment\n  namespace: production\n  labels:\n    app.kubernetes.io/name: webapp\n    app.kubernetes.io/version: \"2.0.1\"\n    app.kubernetes.io/component: frontend\n    app.kubernetes.io/part-of: ecommerce-platform\n    app.kubernetes.io/managed-by: kubectl\n  annotations:\n    deployment.kubernetes.io/revision: \"3\"\n    kubernetes.io/change-cause: \"Update to version 2.0.1\"\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: webapp\n      tier: frontend\n    matchExpressions:\n    - key: environment\n      operator: In\n      values:\n      - production\n      - staging\n    - key: deprecated\n      operator: DoesNotExist\n  template:\n    metadata:\n      labels:\n        app: webapp\n        tier: frontend\n        environment: production\n        version: \"2.0.1\"\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8080\"\n    spec:\n      containers:\n      - name: webapp\n        image: webapp:2.0.1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 200m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#example-3-service-with-label-selector","title":"Example 3: Service with Label Selector","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: webapp-service\n  namespace: production\n  labels:\n    app: webapp\n    tier: frontend\n  annotations:\n    service.kubernetes.io/topology-aware-hints: \"auto\"\nspec:\n  type: ClusterIP\n  selector:\n    app: webapp           # Selects pods with app=webapp\n    tier: frontend        # AND tier=frontend\n  ports:\n  - name: http\n    port: 80\n    targetPort: 8080\n    protocol: TCP\n  sessionAffinity: ClientIP\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#common-exam-tasks","title":"Common Exam Tasks","text":"","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#scenario-1-create-object-with-labels","title":"Scenario 1: Create Object with Labels","text":"<p>Task: Create a pod named <code>web</code> with nginx image, labels <code>app=web</code> and <code>tier=frontend</code></p> <pre><code># Imperative with labels\nkubectl run web --image=nginx --labels=\"app=web,tier=frontend\"\n\n# Or generate and modify\nkubectl run web --image=nginx --dry-run=client -o yaml &gt; pod.yaml\n# Edit pod.yaml to add labels\nkubectl apply -f pod.yaml\n\n# Verify\nkubectl get pod web --show-labels\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#scenario-2-select-resources-by-labels","title":"Scenario 2: Select Resources by Labels","text":"<p>Task: Get all pods with label <code>environment=production</code> and <code>tier!=backend</code></p> <pre><code># Single label\nkubectl get pods -l environment=production\n\n# Multiple labels (AND)\nkubectl get pods -l environment=production,tier!=backend\n\n# Set-based\nkubectl get pods -l 'environment in (production,staging),tier!=backend'\n\n# Show labels\nkubectl get pods -l environment=production --show-labels\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#scenario-3-addmodify-annotations","title":"Scenario 3: Add/Modify Annotations","text":"<p>Task: Add annotation <code>description=\"Production web server\"</code> to deployment <code>webapp</code></p> <pre><code># Add annotation\nkubectl annotate deployment webapp description=\"Production web server\"\n\n# Modify existing (requires --overwrite)\nkubectl annotate deployment webapp description=\"Updated description\" --overwrite\n\n# Verify\nkubectl describe deployment webapp | grep -A 5 \"Annotations:\"\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#scenario-4-validate-manifest-before-apply","title":"Scenario 4: Validate Manifest Before Apply","text":"<p>Task: Check if <code>deployment.yaml</code> is valid without creating it</p> <pre><code># Client-side validation (YAML syntax + basic structure)\nkubectl apply --dry-run=client -f deployment.yaml\n\n# Server-side validation (includes admission controllers)\nkubectl apply --dry-run=server -f deployment.yaml\n\n# Explain specific fields\nkubectl explain deployment.spec.template.spec.containers.resources\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#scenario-5-extract-object-yaml","title":"Scenario 5: Extract Object YAML","text":"<p>Task: Get running pod's YAML to create template</p> <pre><code># Get full YAML (includes status)\nkubectl get pod nginx -o yaml\n\n# Get YAML without system fields (for template)\nkubectl get pod nginx -o yaml | kubectl neat\n\n# Or manually clean\nkubectl get pod nginx -o yaml &gt; template.yaml\n# Remove status, uid, resourceVersion, creationTimestamp, etc.\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#practice-exercises","title":"Practice Exercises","text":"","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#exercise-1-object-creation-10-minutes","title":"Exercise 1: Object Creation (10 minutes)","text":"<p>Objective: Create objects with proper metadata structure</p> <p>Tasks: 1. Create pod <code>frontend-pod</code> with nginx:1.21 image 2. Add labels: <code>app=frontend</code>, <code>tier=web</code>, <code>env=dev</code> 3. Add annotation: <code>description=\"Development frontend pod\"</code> 4. Verify labels and annotations</p> <p>Solution: <pre><code># Generate template\nkubectl run frontend-pod --image=nginx:1.21 --dry-run=client -o yaml &gt; pod.yaml\n\n# Edit pod.yaml\nvim pod.yaml\n# Add to metadata:\n#   labels:\n#     app: frontend\n#     tier: web\n#     env: dev\n#   annotations:\n#     description: \"Development frontend pod\"\n\n# Apply\nkubectl apply -f pod.yaml\n\n# Verify\nkubectl get pod frontend-pod --show-labels\nkubectl describe pod frontend-pod | grep -A 5 \"Annotations:\"\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#exercise-2-label-selection-15-minutes","title":"Exercise 2: Label Selection (15 minutes)","text":"<p>Objective: Practice label selectors</p> <p>Tasks: 1. Create 5 pods with various labels 2. Select pods with <code>environment=production</code> 3. Select pods with <code>tier</code> in (frontend, api) 4. Select pods with <code>environment=production</code> AND <code>tier!=backend</code> 5. Count pods matching each selector</p> <p>Solution: <pre><code># Create pods with different labels\nkubectl run pod1 --image=nginx --labels=\"app=web,environment=production,tier=frontend\"\nkubectl run pod2 --image=nginx --labels=\"app=api,environment=production,tier=api\"\nkubectl run pod3 --image=nginx --labels=\"app=db,environment=production,tier=backend\"\nkubectl run pod4 --image=nginx --labels=\"app=web,environment=staging,tier=frontend\"\nkubectl run pod5 --image=nginx --labels=\"app=cache,environment=dev,tier=cache\"\n\n# Select by environment\nkubectl get pods -l environment=production\n# Expected: pod1, pod2, pod3\n\n# Select by tier (set-based)\nkubectl get pods -l 'tier in (frontend,api)'\n# Expected: pod1, pod2, pod4\n\n# Complex selector\nkubectl get pods -l environment=production,tier!=backend\n# Expected: pod1, pod2\n\n# Count matches\nkubectl get pods -l environment=production --no-headers | wc -l\n# Expected: 3\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#exercise-3-deployment-with-selectors-20-minutes","title":"Exercise 3: Deployment with Selectors (20 minutes)","text":"<p>Objective: Create deployment with proper label selectors</p> <p>Tasks: 1. Create deployment <code>webapp</code> with 3 replicas 2. Use nginx:1.21 image 3. Add deployment labels: <code>app=webapp</code>, <code>version=v1</code> 4. Pod template labels: <code>app=webapp</code>, <code>tier=frontend</code>, <code>version=v1</code> 5. Configure selector to match pod labels 6. Verify pods are created with correct labels</p> <p>Solution: <pre><code># Generate template\nkubectl create deployment webapp --image=nginx:1.21 --replicas=3 --dry-run=client -o yaml &gt; deployment.yaml\n\n# Edit deployment.yaml\nvim deployment.yaml\n</code></pre></p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webapp\n  labels:\n    app: webapp\n    version: v1\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: webapp\n      tier: frontend\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: webapp\n        tier: frontend\n        version: v1\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n</code></pre> <pre><code># Apply\nkubectl apply -f deployment.yaml\n\n# Verify deployment\nkubectl get deployment webapp\n\n# Verify pods have correct labels\nkubectl get pods --show-labels -l app=webapp\n\n# Verify selector works\nkubectl get pods -l app=webapp,tier=frontend,version=v1\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#exercise-4-annotations-and-documentation-15-minutes","title":"Exercise 4: Annotations and Documentation (15 minutes)","text":"<p>Objective: Use annotations for metadata</p> <p>Tasks: 1. Create deployment with comprehensive annotations 2. Add build info, owner, documentation links 3. Add tool-specific annotations (e.g., Prometheus) 4. Extract and view annotations</p> <p>Solution: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: documented-app\n  annotations:\n    description: \"Production application with comprehensive documentation\"\n    owner: \"platform-team@company.com\"\n    documentation: \"https://wiki.company.com/apps/documented-app\"\n    runbook: \"https://wiki.company.com/runbooks/documented-app\"\n    build-version: \"2.0.1\"\n    git-commit: \"abc123def456\"\n    ci-pipeline: \"https://jenkins.company.com/job/app/123\"\n    deployment-date: \"2024-01-15T10:30:00Z\"\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9090\"\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: documented-app\n  template:\n    metadata:\n      labels:\n        app: documented-app\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"9090\"\n    spec:\n      containers:\n      - name: app\n        image: nginx:1.21\n</code></pre></p> <pre><code># Apply\nkubectl apply -f documented-app.yaml\n\n# View annotations\nkubectl describe deployment documented-app | grep -A 15 \"Annotations:\"\n\n# Get specific annotation\nkubectl get deployment documented-app -o jsonpath='{.metadata.annotations.owner}'\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#exercise-5-validation-and-troubleshooting-20-minutes","title":"Exercise 5: Validation and Troubleshooting (20 minutes)","text":"<p>Objective: Practice validation and error fixing</p> <p>Tasks: 1. Create manifest with intentional errors 2. Use validation to identify errors 3. Fix each error 4. Successfully create object</p> <p>Broken Manifest: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: broken-deploy\n  lables:                          # ERROR: Typo\n    app: broken\nspec:\n  replicas: \"3\"                    # ERROR: String instead of int\n  selector:\n    matchLabels:\n      app: broken\n  template:\n    metadata:\n      labels:\n        app: broken\n    spec:\n      containers:\n      - name: nginx\n        # image: nginx:1.21         # ERROR: Missing required field\n        ports:\n        - containerPort: 80\n        restartPolicy: OnError      # ERROR: Invalid value (wrong location too)\n</code></pre></p> <p>Solution: <pre><code># Try to validate\nkubectl apply --dry-run=client -f broken.yaml\n# See errors for each issue\n\n# Fixed version:\n</code></pre></p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fixed-deploy\n  labels:                          # Fixed: labels (not lables)\n    app: fixed\nspec:\n  replicas: 3                      # Fixed: integer (not string)\n  selector:\n    matchLabels:\n      app: fixed\n  template:\n    metadata:\n      labels:\n        app: fixed\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21          # Fixed: added required field\n        ports:\n        - containerPort: 80\n      restartPolicy: Always        # Fixed: moved to pod spec, valid value\n</code></pre> <pre><code># Validate fixed version\nkubectl apply --dry-run=client -f fixed.yaml\n# Should succeed\n\n# Apply\nkubectl apply -f fixed.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#quick-reference","title":"Quick Reference","text":"","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#object-structure-template","title":"Object Structure Template","text":"<pre><code>apiVersion: &lt;group&gt;/&lt;version&gt;\nkind: &lt;ObjectKind&gt;\nmetadata:\n  name: &lt;object-name&gt;\n  namespace: &lt;namespace&gt;\n  labels:\n    &lt;key&gt;: &lt;value&gt;\n  annotations:\n    &lt;key&gt;: &lt;value&gt;\nspec:\n  # Object-specific desired state\nstatus:\n  # System-managed current state (read-only)\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#common-apiversion-values","title":"Common apiVersion Values","text":"<pre><code>v1                              # Core: Pod, Service, ConfigMap\napps/v1                         # Deployment, StatefulSet, DaemonSet\nbatch/v1                        # Job, CronJob\nnetworking.k8s.io/v1           # Ingress, NetworkPolicy\nrbac.authorization.k8s.io/v1   # Role, ClusterRole, RoleBinding\nstorage.k8s.io/v1              # StorageClass\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#label-selector-syntax","title":"Label Selector Syntax","text":"<pre><code># Equality-based (command-line)\nkubectl get pods -l app=nginx                    # Single label\nkubectl get pods -l app=nginx,tier=frontend      # Multiple (AND)\nkubectl get pods -l app=nginx,tier!=backend      # Not equal\n\n# Set-based (command-line)\nkubectl get pods -l 'environment in (prod,staging)'\nkubectl get pods -l 'tier notin (cache,db)'\nkubectl get pods -l app                          # Label exists\nkubectl get pods -l '!app'                       # Label doesn't exist\n\n# Manifest (YAML)\nselector:\n  matchLabels:                   # Equality-based\n    app: nginx\n  matchExpressions:              # Set-based\n  - key: tier\n    operator: In                 # In, NotIn, Exists, DoesNotExist\n    values: [frontend, api]\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#essential-commands","title":"Essential Commands","text":"<pre><code># Object creation\nkubectl apply -f manifest.yaml\nkubectl create -f manifest.yaml\n\n# Label operations\nkubectl label pod nginx app=web                  # Add\nkubectl label pod nginx app=web --overwrite      # Modify\nkubectl label pod nginx app-                     # Remove\nkubectl get pods --show-labels                   # View\nkubectl get pods -L app,tier                     # Show specific labels\nkubectl get pods -l app=nginx                    # Filter by labels\n\n# Annotation operations\nkubectl annotate pod nginx description=\"Web server\"    # Add\nkubectl annotate pod nginx description- # Remove\nkubectl describe pod nginx                       # View\n\n# Validation\nkubectl apply --dry-run=client -f manifest.yaml  # Client-side\nkubectl apply --dry-run=server -f manifest.yaml  # Server-side\nkubectl explain deployment.spec                  # Field documentation\n\n# Extraction\nkubectl get pod nginx -o yaml                    # Full YAML\nkubectl get pod nginx -o json                    # Full JSON\n</code></pre>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Every Kubernetes resource is an object with consistent structure: apiVersion, kind, metadata, spec</p> <p>\u2705 YAML is the standard format - master 2-space indentation and common patterns</p> <p>\u2705 Four essential fields define objects - apiVersion, kind, metadata (name/namespace/labels), spec</p> <p>\u2705 Labels enable selection - use for grouping, Services, Deployments, and queries</p> <p>\u2705 Selectors match labels - equality-based (simple) and set-based (complex matching)</p> <p>\u2705 Annotations store metadata - documentation, configuration, tool integration (no selection)</p> <p>\u2705 Use kubectl explain extensively - fastest way to discover field structure during exam</p> <p>\u2705 Validation catches errors early - always use --dry-run before applying</p> <p>\u2705 Recommended labels maintain consistency - app.kubernetes.io/* prefix for standard labels</p> <p>\u2705 Master label/annotation operations - critical for exam speed and production work</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/kubernetes-objects-yaml-manifests/#next-steps","title":"Next Steps","text":"<p>Continue your CKA journey with:</p> <p>Post 5: Namespaces and Resource Quotas - Learn cluster resource organization and multi-tenancy</p> <p>Related Posts: - Kubernetes Architecture Fundamentals - Understanding cluster components - kubectl Essentials - Command-line mastery - Kubernetes CKA Mastery - Complete Learning Path - Full exam preparation series</p> <p>External Resources: - Kubernetes Objects (Official Docs) - Labels and Selectors - Annotations - Recommended Labels - Understanding Kubernetes Objects</p>","tags":["kubernetes","k8s","cka-prep","yaml","objects","manifests","labels","selectors"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/","title":"Kubernetes Namespaces and Resource Quotas","text":"<p>Master namespace isolation and resource management for CKA exam success. Learn how to partition clusters, enforce resource limits, and prevent resource exhaustion in multi-tenant environments.</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#overview","title":"Overview","text":"<p>Namespaces provide virtual cluster partitioning within a physical Kubernetes cluster, enabling multi-tenancy, resource isolation, and access control. Resource quotas and limit ranges ensure fair resource distribution and prevent resource starvation.</p> <p>CKA Exam Domain: Workloads &amp; Scheduling (15%), Services &amp; Networking (20%)</p> <p>Key Insight: CKA exam scenarios frequently test namespace-aware operations and resource constraint troubleshooting. Understanding namespace scope and quota enforcement is critical for multi-tenant cluster management.</p> <p>What You'll Learn: - Namespace fundamentals and scope boundaries - Resource quota design and enforcement - Limit ranges for default resource constraints - Multi-tenant isolation strategies - Troubleshooting resource quota issues - CKA exam patterns and time-saving workflows</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#namespace-fundamentals","title":"Namespace Fundamentals","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#what-are-namespaces","title":"What Are Namespaces?","text":"<p>Definition: Namespaces are logical partitions within a Kubernetes cluster that provide scope for resource names and enable resource isolation.</p> <p>Core Concepts: - Resource names must be unique within a namespace, not across cluster - Most Kubernetes resources are namespace-scoped (pods, services, deployments) - Some resources are cluster-scoped (nodes, persistent volumes, namespaces) - Namespaces enable RBAC policies, network policies, and resource quotas</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#namespace-architecture","title":"Namespace Architecture","text":"<pre><code>graph TB\n    subgraph \"Kubernetes Cluster\"\n        subgraph \"default Namespace\"\n            POD1[app-pod-1]\n            SVC1[app-service]\n            DEP1[app-deployment]\n        end\n\n        subgraph \"kube-system Namespace\"\n            POD2[coredns-xxx]\n            SVC2[kube-dns]\n            DEP2[coredns]\n        end\n\n        subgraph \"production Namespace\"\n            POD3[web-pod-1]\n            SVC3[web-service]\n            DEP3[web-deployment]\n            QUOTA1[ResourceQuota]\n            LIMIT1[LimitRange]\n        end\n\n        subgraph \"development Namespace\"\n            POD4[test-pod-1]\n            SVC4[test-service]\n            DEP4[test-deployment]\n            QUOTA2[ResourceQuota]\n            LIMIT2[LimitRange]\n        end\n\n        NODE1[Node: worker-1]\n        NODE2[Node: worker-2]\n        PV[(PersistentVolume)]\n    end\n\n    POD1 -.-&gt; NODE1\n    POD2 -.-&gt; NODE2\n    POD3 -.-&gt; NODE1\n    POD4 -.-&gt; NODE2\n\n    QUOTA1 -.-&gt;|enforces limits| POD3\n    QUOTA2 -.-&gt;|enforces limits| POD4\n\n    PV -.-&gt;|cluster-scoped| POD3\n    PV -.-&gt;|cluster-scoped| POD4\n\n    style default fill:#e1f5ff\n    style kube-system fill:#ffe5e5\n    style production fill:#e8f5e8\n    style development fill:#fff4e1\n    style NODE1 fill:#f5e1ff\n    style PV fill:#ffe5e5</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#default-namespaces","title":"Default Namespaces","text":"<p>Kubernetes creates several namespaces automatically:</p> Namespace Purpose Default Resources default Default namespace for resources without explicit namespace User workloads kube-system Kubernetes system components API server, scheduler, controller manager, DNS kube-public Publicly readable resources Cluster information kube-node-lease Node heartbeat objects for performance Node lease objects","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#namespace-operations","title":"Namespace Operations","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#creating-namespaces","title":"Creating Namespaces","text":"<p>Imperative Method (Fast for CKA): <pre><code># Create namespace\nkubectl create namespace production\nkubectl create ns development  # Short form\n\n# Create with labels\nkubectl create namespace staging --dry-run=client -o yaml | \\\n  kubectl label -f - --local environment=staging -o yaml | \\\n  kubectl apply -f -\n</code></pre></p> <p>Declarative Method: <pre><code># namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: production\n  labels:\n    environment: production\n    team: backend\n</code></pre></p> <pre><code>kubectl apply -f namespace.yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#listing-and-inspecting-namespaces","title":"Listing and Inspecting Namespaces","text":"<pre><code># List all namespaces\nkubectl get namespaces\nkubectl get ns\n\n# Show labels\nkubectl get ns --show-labels\n\n# Describe namespace (shows quota and limits)\nkubectl describe namespace production\n\n# Get namespace details in YAML\nkubectl get ns production -o yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#working-with-namespaced-resources","title":"Working with Namespaced Resources","text":"<pre><code># Create resources in specific namespace\nkubectl run nginx --image=nginx -n production\nkubectl create deployment webapp --image=nginx --replicas=3 -n development\n\n# Get resources from specific namespace\nkubectl get pods -n production\nkubectl get all -n development\n\n# Get resources from all namespaces\nkubectl get pods -A\nkubectl get pods --all-namespaces\n\n# Set default namespace for current context\nkubectl config set-context --current --namespace=production\n\n# Verify current namespace\nkubectl config view --minify | grep namespace\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#deleting-namespaces","title":"Deleting Namespaces","text":"<p>\u26a0\ufe0f WARNING: Deleting a namespace deletes ALL resources within it.</p> <pre><code># Delete namespace (deletes all resources)\nkubectl delete namespace development\n\n# Delete with confirmation\nkubectl delete ns development --force --grace-period=0\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#resource-quotas","title":"Resource Quotas","text":"<p>Resource quotas provide constraints that limit aggregate resource consumption per namespace, preventing resource exhaustion and ensuring fair allocation.</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#resourcequota-types","title":"ResourceQuota Types","text":"<p>Compute Resource Quotas: - <code>requests.cpu</code> - Sum of CPU requests - <code>requests.memory</code> - Sum of memory requests - <code>limits.cpu</code> - Sum of CPU limits - <code>limits.memory</code> - Sum of memory limits - <code>requests.storage</code> - Sum of storage requests</p> <p>Object Count Quotas: - <code>count/pods</code> - Maximum pod count - <code>count/services</code> - Maximum service count - <code>count/configmaps</code> - Maximum ConfigMap count - <code>count/secrets</code> - Maximum secret count - <code>count/persistentvolumeclaims</code> - Maximum PVC count - <code>count/deployments.apps</code> - Maximum deployment count - <code>count/replicasets.apps</code> - Maximum ReplicaSet count</p> <p>Storage Class Quotas: - <code>&lt;storage-class-name&gt;.storageclass.storage.k8s.io/requests.storage</code> - <code>&lt;storage-class-name&gt;.storageclass.storage.k8s.io/persistentvolumeclaims</code></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#creating-resource-quotas","title":"Creating Resource Quotas","text":"<p>Basic Compute Quota: <pre><code># quota-compute.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-quota\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"10\"           # Max 10 CPU cores requested\n    requests.memory: 20Gi        # Max 20Gi memory requested\n    limits.cpu: \"20\"             # Max 20 CPU cores limit\n    limits.memory: 40Gi          # Max 40Gi memory limit\n</code></pre></p> <pre><code>kubectl apply -f quota-compute.yaml\n</code></pre> <p>Object Count Quota: <pre><code># quota-objects.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: object-quota\n  namespace: production\nspec:\n  hard:\n    count/pods: \"100\"\n    count/services: \"50\"\n    count/configmaps: \"20\"\n    count/secrets: \"30\"\n    count/persistentvolumeclaims: \"10\"\n    count/deployments.apps: \"30\"\n    count/replicasets.apps: \"50\"\n</code></pre></p> <p>Combined Quota (CKA Exam Pattern): <pre><code># quota-comprehensive.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: production-quota\n  namespace: production\nspec:\n  hard:\n    # Compute resources\n    requests.cpu: \"50\"\n    requests.memory: 100Gi\n    limits.cpu: \"100\"\n    limits.memory: 200Gi\n\n    # Storage\n    requests.storage: 500Gi\n    persistentvolumeclaims: \"20\"\n\n    # Object counts\n    count/pods: \"200\"\n    count/services: \"50\"\n    count/configmaps: \"50\"\n    count/secrets: \"50\"\n\n    # Workloads\n    count/deployments.apps: \"50\"\n    count/statefulsets.apps: \"10\"\n    count/jobs.batch: \"20\"\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#checking-quota-usage","title":"Checking Quota Usage","text":"<pre><code># View quota details\nkubectl get resourcequota -n production\nkubectl describe resourcequota production-quota -n production\n\n# Output shows:\n# Name:                   production-quota\n# Namespace:              production\n# Resource                Used    Hard\n# --------                ----    ----\n# requests.cpu            5       50\n# requests.memory         10Gi    100Gi\n# limits.cpu              10      100\n# limits.memory           20Gi    200Gi\n# count/pods              15      200\n\n# Get quota in YAML format\nkubectl get quota production-quota -n production -o yaml\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#resourcequota-enforcement-flow","title":"ResourceQuota Enforcement Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant API as API Server\n    participant Admission as Admission Controller\n    participant Quota as ResourceQuota\n    participant Scheduler\n    participant Kubelet\n\n    User-&gt;&gt;API: kubectl apply -f pod.yaml\n    API-&gt;&gt;Admission: Validate request\n    Admission-&gt;&gt;Quota: Check quota limits\n\n    alt Quota Available\n        Quota--&gt;&gt;Admission: \u2705 Within limits\n        Admission--&gt;&gt;API: Approve\n        API-&gt;&gt;Scheduler: Schedule pod\n        Scheduler-&gt;&gt;Kubelet: Assign to node\n        Kubelet--&gt;&gt;User: Pod created\n        Quota-&gt;&gt;Quota: Update used resources\n    else Quota Exceeded\n        Quota--&gt;&gt;Admission: \u274c Quota exceeded\n        Admission--&gt;&gt;API: Reject\n        API--&gt;&gt;User: Error: exceeded quota\n        Note over User,Quota: Pod creation fails\n    end</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#limit-ranges","title":"Limit Ranges","text":"<p>LimitRange objects set default resource requests/limits and enforce min/max constraints for containers and pods within a namespace.</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#limitrange-components","title":"LimitRange Components","text":"<p>Container-Level Constraints: - <code>defaultRequest</code> - Default resource requests if not specified - <code>default</code> - Default resource limits if not specified - <code>min</code> - Minimum allowed resource values - <code>max</code> - Maximum allowed resource values - <code>maxLimitRequestRatio</code> - Max ratio of limit to request</p> <p>Pod-Level Constraints: - Total resource consumption across all containers</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#creating-limit-ranges","title":"Creating Limit Ranges","text":"<p>Container Defaults and Constraints: <pre><code># limitrange-container.yaml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: container-limits\n  namespace: production\nspec:\n  limits:\n  - type: Container\n    default:                      # Default limits\n      cpu: 500m\n      memory: 512Mi\n    defaultRequest:               # Default requests\n      cpu: 100m\n      memory: 128Mi\n    min:                          # Minimum allowed\n      cpu: 50m\n      memory: 64Mi\n    max:                          # Maximum allowed\n      cpu: 2\n      memory: 2Gi\n    maxLimitRequestRatio:         # Max limit/request ratio\n      cpu: 4\n      memory: 4\n</code></pre></p> <p>Pod-Level Constraints: <pre><code># limitrange-pod.yaml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: pod-limits\n  namespace: production\nspec:\n  limits:\n  - type: Pod\n    max:\n      cpu: \"4\"\n      memory: 8Gi\n    min:\n      cpu: 100m\n      memory: 128Mi\n</code></pre></p> <p>PersistentVolumeClaim Constraints: <pre><code># limitrange-pvc.yaml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: pvc-limits\n  namespace: production\nspec:\n  limits:\n  - type: PersistentVolumeClaim\n    max:\n      storage: 100Gi\n    min:\n      storage: 1Gi\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#checking-limit-ranges","title":"Checking Limit Ranges","text":"<pre><code># View limit ranges\nkubectl get limitrange -n production\nkubectl describe limitrange container-limits -n production\n\n# Output shows:\n# Name:       container-limits\n# Namespace:  production\n# Type        Resource  Min   Max   Default Request  Default Limit  Max Limit/Request Ratio\n# ----        --------  ---   ---   ---------------  -------------  -----------------------\n# Container   cpu       50m   2     100m             500m           4\n# Container   memory    64Mi  2Gi   128Mi            512Mi          4\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#limitrange-application-flow","title":"LimitRange Application Flow","text":"<pre><code>flowchart TD\n    Start([Pod Creation]) --&gt; HasLimits{Has resource&lt;br/&gt;limits/requests?}\n\n    HasLimits --&gt;|Yes| ValidateRange[Validate against LimitRange]\n    HasLimits --&gt;|No| ApplyDefaults[Apply LimitRange defaults]\n\n    ApplyDefaults --&gt; ValidateRange\n\n    ValidateRange --&gt; InRange{Within&lt;br/&gt;min/max?}\n\n    InRange --&gt;|Yes| RatioCheck{Limit/Request&lt;br/&gt;ratio OK?}\n    InRange --&gt;|No| Reject1[\u274c Reject: Out of range]\n\n    RatioCheck --&gt;|Yes| CheckQuota[Check ResourceQuota]\n    RatioCheck --&gt;|No| Reject2[\u274c Reject: Ratio exceeded]\n\n    CheckQuota --&gt; QuotaOK{Quota&lt;br/&gt;available?}\n\n    QuotaOK --&gt;|Yes| Accept[\u2705 Accept pod]\n    QuotaOK --&gt;|No| Reject3[\u274c Reject: Quota exceeded]\n\n    Accept --&gt; Schedule[Schedule pod]\n\n    style Accept fill:#99ff99\n    style Reject1 fill:#ff9999\n    style Reject2 fill:#ff9999\n    style Reject3 fill:#ff9999</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#multi-tenant-resource-management","title":"Multi-Tenant Resource Management","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#design-patterns","title":"Design Patterns","text":"<p>Pattern 1: Environment-Based Namespaces <pre><code># production namespace - Strict quotas\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: production\n  labels:\n    environment: production\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: production-quota\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: 200Gi\n    limits.cpu: \"200\"\n    limits.memory: 400Gi\n    count/pods: \"500\"\n</code></pre></p> <pre><code># development namespace - Relaxed quotas\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: development\n  labels:\n    environment: development\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: development-quota\n  namespace: development\nspec:\n  hard:\n    requests.cpu: \"20\"\n    requests.memory: 40Gi\n    limits.cpu: \"40\"\n    limits.memory: 80Gi\n    count/pods: \"100\"\n</code></pre> <p>Pattern 2: Team-Based Namespaces <pre><code># backend-team namespace\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: backend-team\n  labels:\n    team: backend\n    cost-center: \"1234\"\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: backend-quota\n  namespace: backend-team\nspec:\n  hard:\n    requests.cpu: \"50\"\n    requests.memory: 100Gi\n    count/deployments.apps: \"30\"\n</code></pre></p> <p>Pattern 3: Application-Based Namespaces <pre><code># ecommerce-app namespace\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: ecommerce-app\n  labels:\n    app: ecommerce\n    tier: frontend\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: ecommerce-quota\n  namespace: ecommerce-app\nspec:\n  hard:\n    requests.cpu: \"30\"\n    requests.memory: 60Gi\n    count/services: \"20\"\n    count/configmaps: \"30\"\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#quota-scope-selectors","title":"Quota Scope Selectors","text":"<p>Priority Class-Based Quotas: <pre><code># quota-high-priority.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: high-priority-quota\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"50\"\n    requests.memory: 100Gi\n    count/pods: \"100\"\n  scopeSelector:\n    matchExpressions:\n    - operator: In\n      scopeName: PriorityClass\n      values:\n      - high-priority\n</code></pre></p> <p>BestEffort/NotBestEffort Quotas: <pre><code># quota-besteffort.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: besteffort-quota\n  namespace: production\nspec:\n  hard:\n    count/pods: \"10\"  # Limit BestEffort pods\n  scopes:\n  - BestEffort\n---\n# quota-guaranteed.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: guaranteed-quota\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"80\"\n    requests.memory: 160Gi\n  scopes:\n  - NotBestEffort\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#troubleshooting-quota-issues","title":"Troubleshooting Quota Issues","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#common-error-scenarios","title":"Common Error Scenarios","text":"<p>Error 1: Insufficient Quota <pre><code># Error message:\n# Error from server (Forbidden): pods \"nginx\" is forbidden:\n# exceeded quota: production-quota, requested: requests.cpu=1,requests.memory=1Gi,\n# used: requests.cpu=49,requests.memory=99Gi,\n# limited: requests.cpu=50,requests.memory=100Gi\n</code></pre></p> <p>Diagnosis and Fix: <pre><code># 1. Check current quota usage\nkubectl describe quota production-quota -n production\n\n# 2. Identify resource hogs\nkubectl top pods -n production --sort-by=cpu\nkubectl top pods -n production --sort-by=memory\n\n# 3. Options:\n# Option A: Increase quota\nkubectl edit quota production-quota -n production\n\n# Option B: Scale down workloads\nkubectl scale deployment high-cpu-app --replicas=2 -n production\n\n# Option C: Delete unused resources\nkubectl get pods -n production --field-selector=status.phase=Succeeded -o name | \\\n  xargs kubectl delete -n production\n</code></pre></p> <p>Error 2: Missing Resource Requests <pre><code># Error message:\n# Error from server (Forbidden): pods \"nginx\" is forbidden:\n# failed quota: production-quota: must specify requests.cpu,requests.memory\n</code></pre></p> <p>Diagnosis and Fix: <pre><code># When ResourceQuota exists, ALL pods must specify requests/limits\n# Option A: Add requests/limits to pod\nkubectl run nginx --image=nginx -n production \\\n  --requests='cpu=100m,memory=128Mi' \\\n  --limits='cpu=200m,memory=256Mi'\n\n# Option B: Create LimitRange to provide defaults\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: default-limits\n  namespace: production\nspec:\n  limits:\n  - type: Container\n    defaultRequest:\n      cpu: 100m\n      memory: 128Mi\n    default:\n      cpu: 200m\n      memory: 256Mi\nEOF\n</code></pre></p> <p>Error 3: Limit/Request Ratio Exceeded <pre><code># Error message:\n# Error from server (Forbidden): pods \"nginx\" is forbidden:\n# maximum cpu limit to request ratio per Container is 4, but provided ratio is 10.000000\n</code></pre></p> <p>Diagnosis and Fix: <pre><code># Check LimitRange constraints\nkubectl describe limitrange -n production\n\n# Fix: Adjust pod resources to meet ratio\n# If request=100m and maxLimitRequestRatio=4, then limit cannot exceed 400m\nkubectl run nginx --image=nginx -n production \\\n  --requests='cpu=100m' \\\n  --limits='cpu=400m'  # 4:1 ratio\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#debugging-workflow","title":"Debugging Workflow","text":"<pre><code>flowchart TD\n    Error([Pod Creation Failed]) --&gt; CheckMsg{Error Message}\n\n    CheckMsg --&gt;|exceeded quota| QuotaDiag[Check Quota Status]\n    CheckMsg --&gt;|must specify| MissingRes[Add Resources or LimitRange]\n    CheckMsg --&gt;|ratio exceeded| RatioDiag[Check LimitRange Ratio]\n    CheckMsg --&gt;|insufficient| InsufficientRes[Increase Quota or Scale Down]\n\n    QuotaDiag --&gt; DescQuota[kubectl describe quota]\n    DescQuota --&gt; AnalyzeUsage{Quota Full?}\n\n    AnalyzeUsage --&gt;|Yes| Options[Choose Fix]\n    AnalyzeUsage --&gt;|No| CheckLR[Check LimitRange]\n\n    Options --&gt; OptA[Increase Quota]\n    Options --&gt; OptB[Delete Resources]\n    Options --&gt; OptC[Scale Down]\n\n    MissingRes --&gt; AddReq[Add requests/limits]\n    MissingRes --&gt; CreateLR[Create LimitRange]\n\n    RatioDiag --&gt; AdjustRatio[Adjust limit:request ratio]\n\n    CheckLR --&gt; DescLR[kubectl describe limitrange]\n\n    style Error fill:#ff9999\n    style OptA fill:#e1f5ff\n    style OptB fill:#fff4e1\n    style OptC fill:#e8f5e8</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#cka-exam-scenarios","title":"CKA Exam Scenarios","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#scenario-1-create-namespace-with-quota","title":"Scenario 1: Create Namespace with Quota","text":"<p>Task: Create namespace 'webapp' with quota: max 10 pods, 5 CPU cores, 10Gi memory.</p> <p>Solution: <pre><code># Create namespace\nkubectl create namespace webapp\n\n# Create quota (imperative)\nkubectl create quota webapp-quota \\\n  --hard=count/pods=10,requests.cpu=5,requests.memory=10Gi \\\n  -n webapp\n\n# Verify\nkubectl describe quota webapp-quota -n webapp\n</code></pre></p> <p>Alternative (Declarative): <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: webapp\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: webapp-quota\n  namespace: webapp\nspec:\n  hard:\n    count/pods: \"10\"\n    requests.cpu: \"5\"\n    requests.memory: 10Gi\nEOF\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#scenario-2-create-pod-in-quota-constrained-namespace","title":"Scenario 2: Create Pod in Quota-Constrained Namespace","text":"<p>Task: Create nginx pod in namespace with quota requiring resource specifications.</p> <p>Solution: <pre><code># Generate pod YAML with resources\nkubectl run nginx --image=nginx -n webapp \\\n  --requests='cpu=100m,memory=128Mi' \\\n  --limits='cpu=200m,memory=256Mi' \\\n  --dry-run=client -o yaml &gt; pod.yaml\n\n# Apply\nkubectl apply -f pod.yaml\n\n# Verify quota usage\nkubectl describe quota -n webapp\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#scenario-3-troubleshoot-quota-exceeded-error","title":"Scenario 3: Troubleshoot Quota Exceeded Error","text":"<p>Task: Deployment fails to scale due to quota. Identify issue and fix.</p> <p>Solution: <pre><code># 1. Check error\nkubectl get events -n webapp --sort-by='.lastTimestamp'\n\n# 2. Check quota usage\nkubectl describe quota -n webapp\n# Shows: requests.cpu used=4.8/5, requests.memory used=9.5Gi/10Gi\n\n# 3. Identify resource usage\nkubectl top pods -n webapp --sort-by=cpu\nkubectl top pods -n webapp --sort-by=memory\n\n# 4. Fix - Option A: Delete completed pods\nkubectl delete pod --field-selector=status.phase=Succeeded -n webapp\n\n# 4. Fix - Option B: Increase quota\nkubectl edit quota webapp-quota -n webapp\n# Increase limits\n\n# 5. Verify\nkubectl describe quota -n webapp\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#scenario-4-set-default-resource-constraints","title":"Scenario 4: Set Default Resource Constraints","text":"<p>Task: Create LimitRange in 'development' namespace with defaults: cpu=100m/200m, memory=128Mi/256Mi.</p> <p>Solution: <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: dev-limits\n  namespace: development\nspec:\n  limits:\n  - type: Container\n    defaultRequest:\n      cpu: 100m\n      memory: 128Mi\n    default:\n      cpu: 200m\n      memory: 256Mi\n    min:\n      cpu: 50m\n      memory: 64Mi\n    max:\n      cpu: 1\n      memory: 1Gi\nEOF\n\n# Verify\nkubectl describe limitrange dev-limits -n development\n\n# Test - create pod without resources (should get defaults)\nkubectl run test --image=nginx -n development\nkubectl get pod test -n development -o yaml | grep -A 10 resources:\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#scenario-5-multi-namespace-resource-isolation","title":"Scenario 5: Multi-Namespace Resource Isolation","text":"<p>Task: Create 3 namespaces (prod, staging, dev) with appropriate quotas.</p> <p>Solution: <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\n# Production - Strict quotas\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: prod\n  labels:\n    environment: production\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: prod-quota\n  namespace: prod\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: 200Gi\n    limits.cpu: \"200\"\n    limits.memory: 400Gi\n    count/pods: \"500\"\n    count/services: \"100\"\n---\n# Staging - Moderate quotas\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: staging\n  labels:\n    environment: staging\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: staging-quota\n  namespace: staging\nspec:\n  hard:\n    requests.cpu: \"50\"\n    requests.memory: 100Gi\n    limits.cpu: \"100\"\n    limits.memory: 200Gi\n    count/pods: \"250\"\n---\n# Development - Relaxed quotas\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n  labels:\n    environment: development\n---\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: dev-quota\n  namespace: dev\nspec:\n  hard:\n    requests.cpu: \"20\"\n    requests.memory: 40Gi\n    limits.cpu: \"40\"\n    limits.memory: 80Gi\n    count/pods: \"100\"\nEOF\n\n# Verify all quotas\nkubectl get quota -A\nkubectl describe quota -n prod\nkubectl describe quota -n staging\nkubectl describe quota -n dev\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#best-practices","title":"Best Practices","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#namespace-design","title":"Namespace Design","text":"<p>\u2705 DO: - Use namespaces to separate environments (prod, staging, dev) - Use namespaces for team isolation (backend-team, frontend-team) - Use namespaces for application isolation (app-a, app-b) - Apply labels to namespaces for organization - Document namespace ownership and purpose</p> <p>\u274c DON'T: - Use namespaces for version separation (use labels instead) - Create excessive granularity (1 namespace per microservice) - Rely solely on namespaces for security (combine with RBAC, NetworkPolicy) - Use special characters in namespace names</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#resource-quota-design","title":"Resource Quota Design","text":"<p>\u2705 DO: - Set both requests and limits quotas - Include object count quotas to prevent resource proliferation - Monitor quota usage regularly - Set quotas based on measured usage patterns - Use quota scope selectors for fine-grained control</p> <p>\u274c DON'T: - Set quotas too tight (causes frequent failures) - Set quotas too loose (defeats the purpose) - Forget to account for system pods in kube-system - Ignore quota usage metrics</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#limitrange-design","title":"LimitRange Design","text":"<p>\u2705 DO: - Always create LimitRange when using ResourceQuota - Set reasonable defaults for requests and limits - Enforce min/max constraints to prevent extremes - Set maxLimitRequestRatio to prevent wasteful overcommit - Document LimitRange rationale</p> <p>\u274c DON'T: - Set defaults too high (wastes resources) - Set defaults too low (causes performance issues) - Set maxLimitRequestRatio too strict (prevents legitimate use cases) - Forget to test LimitRange impact on existing workloads</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#monitoring-and-metrics","title":"Monitoring and Metrics","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#quota-usage-monitoring","title":"Quota Usage Monitoring","text":"<pre><code># Check all quotas in cluster\nkubectl get quota -A\n\n# Monitor specific namespace quota\nkubectl describe quota -n production\n\n# Watch quota usage\nkubectl get quota -n production -w\n\n# Get quota usage metrics\nkubectl get quota -n production -o json | \\\n  jq '.items[].status.used'\n\n# Custom columns for quota overview\nkubectl get quota -A -o custom-columns=\\\nNAMESPACE:.metadata.namespace,\\\nNAME:.metadata.name,\\\nCPU_USED:.status.used.\\'requests\\.cpu\\',\\\nCPU_HARD:.status.hard.\\'requests\\.cpu\\',\\\nMEM_USED:.status.used.\\'requests\\.memory\\',\\\nMEM_HARD:.status.hard.\\'requests\\.memory\\'\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#quota-utilization-metrics","title":"Quota Utilization Metrics","text":"<pre><code>graph LR\n    subgraph \"Namespace: production\"\n        Used[Used Resources&lt;br/&gt;CPU: 45/50&lt;br/&gt;Memory: 90Gi/100Gi&lt;br/&gt;Pods: 180/200]\n        Util[Utilization&lt;br/&gt;CPU: 90%&lt;br/&gt;Memory: 90%&lt;br/&gt;Pods: 90%]\n        Alert[\u26a0\ufe0f Alert Threshold&lt;br/&gt;\u2265 85%]\n    end\n\n    Used --&gt; Util\n    Util --&gt; Alert\n\n    Alert -.-&gt;|Trigger| Action1[Increase Quota]\n    Alert -.-&gt;|Trigger| Action2[Scale Down Workloads]\n    Alert -.-&gt;|Trigger| Action3[Optimize Resources]\n\n    style Used fill:#e1f5ff\n    style Util fill:#fff4e1\n    style Alert fill:#ff9999\n    style Action1 fill:#99ff99</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#practice-exercises","title":"Practice Exercises","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#exercise-1-basic-namespace-and-quota-10-minutes","title":"Exercise 1: Basic Namespace and Quota (10 minutes)","text":"<p>Tasks: 1. Create namespace 'test-ns' 2. Create ResourceQuota limiting to 5 pods, 2 CPU, 4Gi memory 3. Create 3 nginx pods with appropriate resources 4. Verify quota usage 5. Try creating 3 more pods (should fail) 6. Delete namespace</p> <p>Solution: <pre><code># 1. Create namespace\nkubectl create ns test-ns\n\n# 2. Create quota\nkubectl create quota test-quota \\\n  --hard=count/pods=5,requests.cpu=2,requests.memory=4Gi \\\n  -n test-ns\n\n# 3. Create pods\nfor i in {1..3}; do\n  kubectl run nginx-$i --image=nginx \\\n    --requests='cpu=200m,memory=512Mi' \\\n    --limits='cpu=400m,memory=1Gi' \\\n    -n test-ns\ndone\n\n# 4. Check quota\nkubectl describe quota test-quota -n test-ns\n\n# 5. Try more pods (will fail after 2 more)\nkubectl run nginx-4 --image=nginx \\\n  --requests='cpu=200m,memory=512Mi' -n test-ns\n\n# 6. Cleanup\nkubectl delete ns test-ns\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#exercise-2-limitrange-configuration-15-minutes","title":"Exercise 2: LimitRange Configuration (15 minutes)","text":"<p>Tasks: 1. Create namespace 'limit-test' 2. Create LimitRange with defaults and constraints 3. Create pod without resources (should get defaults) 4. Create pod with resources exceeding max (should fail) 5. Verify defaults applied</p> <p>Solution: <pre><code># 1. Create namespace\nkubectl create ns limit-test\n\n# 2. Create LimitRange\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: limit-test-range\n  namespace: limit-test\nspec:\n  limits:\n  - type: Container\n    defaultRequest:\n      cpu: 100m\n      memory: 128Mi\n    default:\n      cpu: 200m\n      memory: 256Mi\n    min:\n      cpu: 50m\n      memory: 64Mi\n    max:\n      cpu: 1\n      memory: 1Gi\n    maxLimitRequestRatio:\n      cpu: 4\n      memory: 4\nEOF\n\n# 3. Create pod without resources\nkubectl run test1 --image=nginx -n limit-test\n\n# Check applied defaults\nkubectl get pod test1 -n limit-test -o yaml | grep -A 10 resources:\n\n# 4. Try exceeding max (should fail)\nkubectl run test2 --image=nginx \\\n  --requests='cpu=2' -n limit-test\n# Error: maximum cpu usage per Container is 1, but limit is 2\n\n# 5. Cleanup\nkubectl delete ns limit-test\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#exercise-3-quota-troubleshooting-20-minutes","title":"Exercise 3: Quota Troubleshooting (20 minutes)","text":"<p>Tasks: 1. Create namespace with tight quota (2 pods max) 2. Create deployment with 5 replicas 3. Observe only 2 pods created 4. Diagnose and fix by increasing quota 5. Verify all 5 pods running</p> <p>Solution: <pre><code># 1. Create namespace and quota\nkubectl create ns tight-quota\nkubectl create quota tight-quota \\\n  --hard=count/pods=2,requests.cpu=1,requests.memory=1Gi \\\n  -n tight-quota\n\n# 2. Create deployment\nkubectl create deployment webapp --image=nginx --replicas=5 -n tight-quota\n\n# 3. Check pods (only 2 created)\nkubectl get pods -n tight-quota\nkubectl get rs -n tight-quota\n\n# View ReplicaSet events\nkubectl describe rs -n tight-quota\n# Shows: exceeded quota\n\n# 4. Diagnose\nkubectl describe quota tight-quota -n tight-quota\n# Shows: count/pods: 2/2\n\n# Fix - increase quota\nkubectl patch quota tight-quota -n tight-quota \\\n  --type='json' \\\n  -p='[{\"op\": \"replace\", \"path\": \"/spec/hard/count~1pods\", \"value\":\"10\"}]'\n\n# Or edit directly\nkubectl edit quota tight-quota -n tight-quota\n\n# 5. Verify\nkubectl get pods -n tight-quota\n# Should now show 5/5 pods running\n\n# Cleanup\nkubectl delete ns tight-quota\n</code></pre></p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#quick-reference","title":"Quick Reference","text":"","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#namespace-commands","title":"Namespace Commands","text":"<pre><code># Create\nkubectl create namespace &lt;name&gt;\nkubectl create ns &lt;name&gt;\n\n# List\nkubectl get namespaces\nkubectl get ns\n\n# Describe\nkubectl describe namespace &lt;name&gt;\n\n# Delete\nkubectl delete namespace &lt;name&gt;\n\n# Set default for context\nkubectl config set-context --current --namespace=&lt;name&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#resourcequota-commands","title":"ResourceQuota Commands","text":"<pre><code># Create quota\nkubectl create quota &lt;name&gt; --hard=&lt;key&gt;=&lt;value&gt; -n &lt;namespace&gt;\n\n# List quotas\nkubectl get quota -n &lt;namespace&gt;\nkubectl get quota -A\n\n# Describe quota\nkubectl describe quota &lt;name&gt; -n &lt;namespace&gt;\n\n# Edit quota\nkubectl edit quota &lt;name&gt; -n &lt;namespace&gt;\n\n# Delete quota\nkubectl delete quota &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#limitrange-commands","title":"LimitRange Commands","text":"<pre><code># Create from file\nkubectl apply -f limitrange.yaml\n\n# List limit ranges\nkubectl get limitrange -n &lt;namespace&gt;\nkubectl get limits -n &lt;namespace&gt;\n\n# Describe\nkubectl describe limitrange &lt;name&gt; -n &lt;namespace&gt;\n\n# Delete\nkubectl delete limitrange &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#common-quota-keys","title":"Common Quota Keys","text":"<pre><code># Compute resources\nrequests.cpu\nrequests.memory\nlimits.cpu\nlimits.memory\n\n# Storage\nrequests.storage\npersistentvolumeclaims\n\n# Object counts\ncount/pods\ncount/services\ncount/configmaps\ncount/secrets\ncount/deployments.apps\ncount/replicasets.apps\ncount/statefulsets.apps\ncount/jobs.batch\ncount/cronjobs.batch\n</code></pre>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Namespaces provide logical isolation - Not physical security boundaries</p> <p>\u2705 ResourceQuotas enforce aggregate limits - Prevent resource exhaustion per namespace</p> <p>\u2705 LimitRange provides defaults and constraints - Essential when using quotas</p> <p>\u2705 Always specify resource requests/limits - When quotas are active, required for admission</p> <p>\u2705 Monitor quota usage proactively - Avoid runtime failures from quota exhaustion</p> <p>\u2705 Combine quota scopes for flexibility - PriorityClass, BestEffort filters for fine-grained control</p> <p>\u2705 Delete namespace deletes all resources - Exercise caution with <code>kubectl delete ns</code></p> <p>\u2705 Exam context switching is critical - Always verify namespace before operations</p> <p>\u2705 Troubleshoot with describe - <code>kubectl describe quota/limitrange</code> shows usage and constraints</p> <p>\u2705 Plan quota capacity - Base on measured usage plus growth buffer</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/11/namespaces-resource-quotas/#next-steps","title":"Next Steps","text":"<p>After mastering namespaces and resource quotas, continue with:</p> <p>Post 6: Services and Networking - Service discovery and cluster networking</p> <p>Related Posts: - kubectl Essentials - Command-line mastery for Kubernetes - Kubernetes Architecture Fundamentals - Understanding cluster components - Kubernetes CKA Mastery - Complete Learning Path - Full exam preparation series</p> <p>External Resources: - Namespaces Official Documentation - Resource Quotas - Limit Ranges - Configure Default CPU/Memory Requests and Limits - CKA Exam Curriculum</p>","tags":["kubernetes","k8s","cka-prep","namespaces","resource-management","quotas"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/","title":"High-Performance pNFS v4.2 Distributed Storage Architecture","text":"<p>A deep dive into building a clustered, high-availability parallel NFS storage system with load-balanced metadata servers, NVMe-backed storage nodes, and low-latency interconnects.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#architecture-overview","title":"Architecture Overview","text":"<p>This architecture implements a production-grade parallel NFS (pNFS) v4.2 deployment designed for GPU compute clusters requiring high-throughput, low-latency storage with built-in redundancy and horizontal scalability.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#key-design-goals","title":"Key Design Goals","text":"<ul> <li>Parallel I/O Performance: Direct client-to-storage data paths bypassing metadata bottlenecks</li> <li>Metadata High Availability: Clustered MDS with automatic failover</li> <li>Horizontal Scalability: Add storage nodes without downtime</li> <li>Low Latency: InfiniBand/RoCE interconnects for sub-microsecond latencies</li> <li>Fault Tolerance: No single points of failure in the architecture</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#system-topology","title":"System Topology","text":"<pre><code>sequenceDiagram\n    participant Client as Client&lt;br/&gt;(pNFS v4.2)\n    participant MDS as MDS Cluster&lt;br/&gt;(Active-Active via VIP)\n    participant S1 as Storage Node 1&lt;br/&gt;(NVMe)\n    participant S2 as Storage Node 2&lt;br/&gt;(NVMe)\n    participant S3 as Storage Node 3&lt;br/&gt;(NVMe)\n\n    Note over Client,S3: \u2501\u2501\u2501\u2501\u2501\u2501\u2501 PHASE 1: METADATA PATH \u2501\u2501\u2501\u2501\u2501\u2501\u2501\n    Note over MDS: Virtual IP load balances to any MDS&lt;br/&gt;All MDS nodes share distributed state\n\n    Client-&gt;&gt;+MDS: LAYOUTGET(file_handle)\n    Note right of MDS: MDS queries distributed&lt;br/&gt;backend for file layout\n    MDS--&gt;&gt;-Client: LAYOUT(stripe_pattern, DS_list)\n    Note left of Client: \u2713 Client caches layout&lt;br/&gt;Stripe unit: 1MB&lt;br/&gt;Stripe count: 3 nodes\n\n    Note over Client,S3: \u2501\u2501\u2501\u2501\u2501\u2501\u2501 PHASE 2: DATA PATH (MDS BYPASSED) \u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n    par Parallel Direct I/O over InfiniBand/RoCE\n        Client-&gt;&gt;+S1: WRITE Stripe 0\n        S1-&gt;&gt;S1: NVMe I/O\n        S1--&gt;&gt;-Client: ACK\n    and\n        Client-&gt;&gt;+S2: WRITE Stripe 1\n        S2-&gt;&gt;S2: NVMe I/O\n        S2--&gt;&gt;-Client: ACK\n    and\n        Client-&gt;&gt;+S3: WRITE Stripe 2\n        S3-&gt;&gt;S3: NVMe I/O\n        S3--&gt;&gt;-Client: ACK\n    end\n\n    Note over Client,S3: \u26a1 Aggregate: 3 \u00d7 7 GB/s = ~20 GB/s effective throughput</code></pre> <p>Key Architecture Points:</p> Layer Component Function Control Plane MDS Cluster (Active-Active) Virtual IP \u2192 Load balances metadata requestsDistributed backend \u2192 Shared state (GFS2/OCFS2)Co-located with storage nodes Data Plane Storage Nodes Direct parallel I/O bypasses MDS entirelyEach node: MDS service + Data service + NVMeHigh-speed fabric: InfiniBand or 100GbE RoCE Client pNFS v4.2 One-time layout fetch \u2192 caches stripe patternDirect parallel writes to multiple storage nodesNo metadata bottleneck on data path <p>Architecture Advantage</p> <p>Separation of Control and Data Planes: Client contacts MDS once to get file layout, then performs all subsequent I/O directly to storage nodes over high-speed network. MDS handles only metadata operations (LAYOUTGET, OPEN, CLOSE), while bulk data transfer happens in parallel across multiple storage nodes, eliminating the metadata server bottleneck.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#component-breakdown","title":"Component Breakdown","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#1-client-layer-pnfs-v42-clients","title":"1. Client Layer (pNFS v4.2 Clients)","text":"<p>Role: GPU compute nodes running pNFS-aware clients</p> <p>Characteristics: - Protocol: NFSv4.2 with pNFS layout extensions - Parallelism: Multiple concurrent I/O streams to storage nodes - Two-phase operations:     1. Metadata phase: Request file layout from MDS via VIP     2. Data phase: Direct parallel I/O to multiple storage nodes</p> <p>Advantages: - Metadata and data paths are separated - MDS only handles control plane; data plane scales independently - Clients cache layouts, reducing metadata round-trips</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#2-metadata-virtual-ip-vip-load-balancer","title":"2. Metadata Virtual IP (VIP) / Load Balancer","text":"<p>Role: Distribute metadata requests across clustered MDS instances</p> <p>Implementation Options:</p> Technology Use Case Pros Cons Keepalived + VRRP Simple HA Easy setup, fast failover Layer 3 only, single active HAProxy Advanced LB Health checks, stats, multi-algo Additional component Pacemaker + Corosync Enterprise HA Full cluster manager Complex configuration <p>Configuration Considerations: - Failover time: Target &lt;2 seconds for MDS failover - Session stickiness: Not required (stateless metadata operations) - Health checks: Monitor MDS service health on each node</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#3-mds-cluster-metadata-servers","title":"3. MDS Cluster (Metadata Servers)","text":"<p>Role: Manage namespace, permissions, file layouts, and client coordination</p> <p>Clustering Strategy:</p> <p>Active-Active Clustering</p> <p>All MDS instances are active simultaneously, sharing load via the VIP. This differs from traditional active-passive designs and requires:</p> <ul> <li>Shared backend: Distributed consensus or shared storage for metadata</li> <li>State synchronization: Real-time metadata replication</li> <li>Lock coordination: Distributed locking for file operations</li> </ul> <p>Backend Options:</p> <pre><code>Option 1: Shared Block Device (DRBD + GFS2/OCFS2)\n  pros:\n    - Battle-tested clustering\n    - POSIX semantics\n  cons:\n    - Block-level sync overhead\n    - Limited to 2-3 nodes typically\n\nOption 2: Distributed Database (etcd/Consul)\n  pros:\n    - Raft consensus built-in\n    - Horizontal scaling\n    - Cloud-native\n  cons:\n    - Additional latency\n    - More complex integration\n\nOption 3: Lustre MGS/MDT (if using Lustre as pNFS backend)\n  pros:\n    - Native high availability\n    - Proven at exascale\n  cons:\n    - Lustre-specific\n    - Complex deployment\n</code></pre> <p>Heartbeat Mechanism: - Interval: 500ms - 1s between nodes - Quorum: Majority voting prevents split-brain - Fencing: STONITH (Shoot The Other Node In The Head) for failed nodes</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#4-high-speed-network-fabric","title":"4. High-Speed Network Fabric","text":"<p>Role: Low-latency, high-bandwidth interconnect for storage traffic</p> <p>Technology Comparison:</p> Technology Bandwidth Latency Use Case InfiniBand HDR 200 Gbps &lt;1 \u03bcs HPC, AI training clusters 100GbE RoCE v2 100 Gbps &lt;5 \u03bcs Cost-effective alternative Omni-Path 100 Gbps &lt;1 \u03bcs Intel ecosystem <p>Network Design: <pre><code>- Dedicated storage VLAN/subnet\n- Jumbo frames (MTU 9000) for throughput\n- RDMA for zero-copy transfers\n- Lossless Ethernet (PFC) if using RoCE\n- Multiple paths for redundancy (LACP/MLAG)\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#5-storage-nodes","title":"5. Storage Nodes","text":"<p>Role: Serve actual file data via pNFS Data Service (DS)</p> <p>Node Architecture:</p> <pre><code>Each storage node runs:\n\u251c\u2500\u2500 MDS Service (part of cluster)\n\u251c\u2500\u2500 Data Service (DS) (serves pNFS I/O)\n\u2514\u2500\u2500 Physical Storage (NVMe SSDs)\n</code></pre> <p>NVMe Configuration: - Device: PCIe Gen4 NVMe SSDs (7000+ MB/s per device) - RAID: No RAID (rely on pNFS striping across nodes) - File System: XFS or ZFS for local storage - Tuning:     - <code>nvme.io_timeout=4294967295</code> (disable timeout)     - <code>elevator=none</code> (bypass I/O scheduler for NVMe)     - <code>vm.dirty_ratio=5</code> (aggressive writeback)</p> <p>Capacity Planning: <pre><code>Per-node capacity:\n  - 4x 4TB NVMe = 16TB raw per node\n  - 10 nodes = 160TB aggregate raw\n  - No RAID overhead (redundancy via replication)\n  - Effective capacity: ~140TB (accounting for metadata)\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#data-flow-read-operation","title":"Data Flow: Read Operation","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-1-layout-request-metadata-path","title":"Phase 1: Layout Request (Metadata Path)","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant VIP\n    participant MDS1\n    participant Backend\n\n    Client-&gt;&gt;VIP: LAYOUTGET (file handle)\n    VIP-&gt;&gt;MDS1: Forward request\n    MDS1-&gt;&gt;Backend: Query file layout\n    Backend--&gt;&gt;MDS1: Layout map\n    MDS1--&gt;&gt;Client: LAYOUT (stripe pattern, DS list)\n    Note over Client: Client caches layout</code></pre> <p>Layout Information Returned: <pre><code>{\n  \"layout_type\": \"LAYOUT4_NFSV4_1_FILES\",\n  \"stripe_unit\": 1048576,\n  \"stripe_count\": 4,\n  \"data_servers\": [\n    \"10.10.1.11:2049\",  // Storage Node 1\n    \"10.10.1.12:2049\",  // Storage Node 2\n    \"10.10.1.13:2049\",  // Storage Node 3\n    \"10.10.1.14:2049\"   // Storage Node 4\n  ]\n}\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-2-parallel-data-io-data-path","title":"Phase 2: Parallel Data I/O (Data Path)","text":"<pre><code>graph LR\n    Client --&gt;|Stripe 0| DS1[Storage Node 1]\n    Client --&gt;|Stripe 1| DS2[Storage Node 2]\n    Client --&gt;|Stripe 3| DS3[Storage Node 3]\n    Client --&gt;|Stripe 4| DS4[Storage Node 4]\n\n    DS1 --&gt; NVMe1[NVMe SSD]\n    DS2 --&gt; NVMe2[NVMe SSD]\n    DS3 --&gt; NVMe3[NVMe SSD]\n    DS4 --&gt; NVMe4[NVMe SSD]</code></pre> <p>Throughput Calculation: <pre><code>Single NVMe: 7 GB/s read\n4-way stripe: 7 GB/s \u00d7 4 = 28 GB/s aggregate\nOverhead (20%): ~22 GB/s effective client throughput\n</code></pre></p> <p>Key Advantage</p> <p>The MDS is completely bypassed during data I/O. Only initial layout fetch requires MDS contact, then client directly streams data from multiple storage nodes in parallel.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#write-operation-with-coherency","title":"Write Operation with Coherency","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#challenges","title":"Challenges","text":"<ul> <li>Cache coherency: Multiple clients may access same file</li> <li>Consistency: Must maintain POSIX semantics</li> <li>Layout revocation: MDS may recall layouts during conflicts</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#write-flow","title":"Write Flow","text":"<pre><code>sequenceDiagram\n    participant Client1\n    participant Client2\n    participant MDS\n    participant DS1\n\n    Client1-&gt;&gt;MDS: OPEN (file, WRITE)\n    MDS--&gt;&gt;Client1: LAYOUT (read-write)\n    Client1-&gt;&gt;DS1: WRITE data\n\n    Client2-&gt;&gt;MDS: OPEN (same file, WRITE)\n    MDS-&gt;&gt;Client1: CB_LAYOUTRECALL\n    Client1-&gt;&gt;DS1: COMMIT writes\n    Client1-&gt;&gt;MDS: LAYOUTRETURN\n    MDS--&gt;&gt;Client2: LAYOUT (read-write)</code></pre> <p>Layout Recall Scenarios: 1. Write-write conflict: Second writer needs exclusive layout 2. Read-write conflict: Writer needs to invalidate reader caches 3. Layout change: File being migrated or restriped</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#high-availability-scenarios","title":"High Availability Scenarios","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#scenario-1-mds-node-failure","title":"Scenario 1: MDS Node Failure","text":"<pre><code>Before:\n  VIP \u2192 MDS1 (active)\n      \u2192 MDS2 (active)\n      \u2192 MDS3 (active)  \u2190 fails\n\nAfter (within 2 seconds):\n  VIP \u2192 MDS1 (active)  \u2190 absorbs load\n      \u2192 MDS2 (active)  \u2190 absorbs load\n\n  MDS3: Fenced by cluster, removed from VIP pool\n  Client layouts: Still valid, no client disruption\n</code></pre> <p>Recovery Actions: - Quorum maintained (2/3 nodes) - Clients continue data I/O unaffected - New metadata requests distributed to healthy MDS nodes - Failed MDS auto-rejoins after recovery</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#scenario-2-storage-node-failure","title":"Scenario 2: Storage Node Failure","text":"<pre><code>pNFS File with 4-way striping across nodes 1-4:\n  Node 3 fails \u2192 Stripes 2 (stored on node 3) unavailable\n\nClient behavior:\n  1. Client detects I/O error on stripe 2\n  2. Client returns partial read/write to application\n  3. Application must handle EIO (or use replication)\n\nRecovery:\n  - Option A: File replicated (pNFS server-side replication)\n             \u2192 Automatic failover to replica stripe\n  - Option B: No replication \u2192 Data loss for affected stripes\n</code></pre> <p>Data Durability</p> <p>pNFS itself does NOT provide redundancy. You must implement:</p> <ul> <li>Server-side replication (e.g., Lustre OST pools)</li> <li>Client-side RAID (mdadm over pNFS)</li> <li>Application-level erasure coding</li> <li>Regular snapshots/backups</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#scenario-3-network-partition-split-brain-prevention","title":"Scenario 3: Network Partition (Split-Brain Prevention)","text":"<pre><code>Network partition splits cluster:\n  Partition A: MDS1, MDS2 (2 nodes)\n  Partition B: MDS3 (1 node)\n\nQuorum voting:\n  Partition A: 2/3 nodes = HAS QUORUM \u2192 continues operation\n  Partition B: 1/3 nodes = NO QUORUM \u2192 enters read-only mode\n\nPrevention:\n  - Fencing agent (IPMI, PDU) forcibly powers off minority partition\n  - Prevents conflicting writes to shared backend\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#performance-tuning","title":"Performance Tuning","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#client-side-tunables","title":"Client-Side Tunables","text":"<pre><code># /etc/nfsmount.conf or mount options\nmount -t nfs4 -o \\\n  vers=4.2,\\                      # Enable pNFS\n  pnfs,\\                          # Use parallel NFS layouts\n  rsize=1048576,\\                 # 1MB read size\n  wsize=1048576,\\                 # 1MB write size\n  timeo=600,\\                     # 60s timeout\n  retrans=2,\\                     # 2 retransmissions\n  hard,\\                          # Hard mount (don't give up)\n  async,\\                         # Asynchronous I/O\n  ac,\\                            # Attribute caching\n  actimeo=3600 \\                  # 1-hour attribute cache\n  10.10.1.100:/export /mnt/pnfs\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#server-side-tunables","title":"Server-Side Tunables","text":"<pre><code># NFS server threads (per-node)\necho 256 &gt; /proc/sys/sunrpc/nfsd_threads\n\n# Network receive buffers\nsysctl -w net.core.rmem_max=134217728\nsysctl -w net.core.wmem_max=134217728\n\n# NVMe queue depth\necho 1024 &gt; /sys/block/nvme0n1/queue/nr_requests\n\n# Disable CPU frequency scaling (performance mode)\ncpupower frequency-set -g performance\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#monitoring-metrics","title":"Monitoring Metrics","text":"<pre><code>Key metrics to track:\n  - MDS operations/sec (LAYOUTGET, OPEN, CLOSE)\n  - Data server throughput (GB/s per node)\n  - Latency percentiles (p50, p95, p99)\n  - Client cache hit rates\n  - Network utilization (per fabric)\n  - NVMe IOPS and latency\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#implementation-deployment-checklist","title":"Implementation: Deployment Checklist","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-1-network-setup","title":"Phase 1: Network Setup","text":"<ul> <li> Deploy InfiniBand/RoCE fabric</li> <li> Configure storage VLAN with jumbo frames</li> <li> Enable RDMA on all nodes</li> <li> Verify bandwidth with <code>ib_write_bw</code> / <code>ib_read_bw</code></li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-2-storage-node-provisioning","title":"Phase 2: Storage Node Provisioning","text":"<ul> <li> Install NVMe SSDs and verify <code>nvme list</code></li> <li> Create XFS/ZFS filesystems</li> <li> Apply NVMe performance tunings</li> <li> Install <code>nfs-kernel-server</code> with pNFS support</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-3-mds-cluster-setup","title":"Phase 3: MDS Cluster Setup","text":"<ul> <li> Choose clustering backend (DRBD, etcd, etc.)</li> <li> Configure Pacemaker/Corosync or equivalent</li> <li> Set up VIP with failover tests</li> <li> Deploy metadata synchronization</li> <li> Test quorum and fencing</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-4-pnfs-configuration","title":"Phase 4: pNFS Configuration","text":"<ul> <li> Configure pNFS layouts on each storage node</li> <li> Export file systems via NFS4 with pNFS enabled</li> <li> Register data servers with MDS</li> <li> Test layout distribution from clients</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-5-client-deployment","title":"Phase 5: Client Deployment","text":"<ul> <li> Mount pNFS export with optimized parameters</li> <li> Verify parallel I/O with <code>dd</code> or <code>fio</code></li> <li> Test layout recall and coherency</li> <li> Run application workload benchmarks</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#phase-6-production-hardening","title":"Phase 6: Production Hardening","text":"<ul> <li> Set up monitoring (Prometheus + Grafana)</li> <li> Configure alerting for node failures</li> <li> Document failover procedures</li> <li> Schedule regular disaster recovery drills</li> <li> Implement backup strategy</li> </ul>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#real-world-performance","title":"Real-World Performance","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#benchmark-environment","title":"Benchmark Environment","text":"<pre><code>Hardware:\n  - 10x storage nodes (Dell R750)\n  - 4x 7.68TB NVMe per node (Samsung PM9A3)\n  - 100GbE RoCE network\n  - 2x AMD EPYC 7543 per node\n\nWorkload:\n  - FIO sequential read (4MB block size)\n  - 8 clients, 16 threads each\n</code></pre>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#results","title":"Results","text":"Metric Value Notes Aggregate Throughput 82 GB/s 10 nodes \u00d7 ~8 GB/s each Per-Client Throughput 10.2 GB/s 82 GB/s / 8 clients Latency (p99) 3.2 ms Network + NVMe + pNFS overhead MDS Load 2,300 ops/s Only layout requests CPU Utilization 35% avg Plenty of headroom <p>Key Takeaway</p> <p>pNFS achieved near-linear scaling across 10 storage nodes. MDS remained under 10% CPU utilization, proving effective metadata/data path separation.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#troubleshooting-guide","title":"Troubleshooting Guide","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#problem-clients-not-using-pnfs-falling-back-to-standard-nfs","title":"Problem: Clients not using pNFS (falling back to standard NFS)","text":"<p>Symptoms: <pre><code># All I/O going through MDS node\nnfsstat -m | grep \"pnfs\"  # Shows \"pnfs: not in use\"\n</code></pre></p> <p>Diagnosis: <pre><code># Check server pNFS support\nnfsstat -s | grep pnfs\n\n# Check client kernel support\ngrep PNFS /boot/config-$(uname -r)  # Should show CONFIG_PNFS_FILE_LAYOUT=m\n</code></pre></p> <p>Solution: - Ensure server exports with <code>pnfs</code> option - Verify client kernel has <code>nfs_layout_nfsv41_files</code> module loaded - Check for layout request denials in <code>/var/log/messages</code></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#problem-high-mds-cpu-usage","title":"Problem: High MDS CPU usage","text":"<p>Symptoms: <pre><code># MDS nodes showing &gt;80% CPU\ntop  # nfsd threads consuming CPU\n</code></pre></p> <p>Diagnosis: <pre><code># Check for excessive LAYOUTGET operations\nnfsstat -s | grep LAYOUTGET\n</code></pre></p> <p>Possible Causes: - Clients not caching layouts (check <code>actimeo</code>) - Frequent layout recalls (check for conflicting access patterns) - Insufficient MDS threads (check <code>nfsd_threads</code>)</p> <p>Solution: <pre><code># Increase client attribute cache timeout\nmount -o remount,actimeo=3600 /mnt/pnfs\n\n# Add more MDS threads\necho 512 &gt; /proc/sys/sunrpc/nfsd_threads\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#problem-uneven-storage-utilization","title":"Problem: Uneven storage utilization","text":"<p>Symptoms: <pre><code># One storage node at 90%, others at 40%\ndf -h /storage/*\n</code></pre></p> <p>Diagnosis: <pre><code># Check file layout distribution\n# (Requires pNFS-aware tooling or manual inspection)\n</code></pre></p> <p>Solution: - Re-stripe files: Use pNFS restripe tools if available - Balance new files: Adjust MDS layout selection algorithm - Add/remove nodes: Trigger cluster rebalancing</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#advanced-topics","title":"Advanced Topics","text":"","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#1-hierarchical-storage-management-hsm-with-pnfs","title":"1. Hierarchical Storage Management (HSM) with pNFS","text":"<p>Implement tiered storage by combining: - Hot tier: NVMe-backed pNFS for active data - Warm tier: SATA SSD pNFS for recent data - Cold tier: HDD-based object storage (S3) for archives</p> <p>Layout policy: <pre><code>def select_storage_tier(file_metadata):\n    if file_metadata.access_count &gt; 100:\n        return TIER_NVME\n    elif file_metadata.age_days &lt; 30:\n        return TIER_SSD\n    else:\n        return TIER_HDD\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#2-erasure-coding-for-space-efficiency","title":"2. Erasure Coding for Space Efficiency","text":"<p>Instead of replication (2x-3x overhead), use erasure coding: - Reed-Solomon (8+3): 1.375x overhead for 3-drive fault tolerance - RAID 6 equivalent: Stripe across pNFS with parity - Rebuild time: ~2 hours for 10TB per failed drive</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#3-multi-site-pnfs-replication","title":"3. Multi-Site pNFS Replication","text":"<p>For disaster recovery: <pre><code>Site A (Primary):          Site B (DR):\n  10 storage nodes    \u2192      10 storage nodes\n  Active MDS cluster  \u2192      Standby MDS cluster\n\nAsync replication (rsync/DRBD async or Lustre HSM)\n</code></pre></p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#conclusion","title":"Conclusion","text":"<p>This pNFS v4.2 architecture provides:</p> <p>\u2705 High throughput: 80+ GB/s aggregate via parallel I/O \u2705 Low latency: &lt;5ms p99 with InfiniBand/RoCE \u2705 High availability: No single points of failure \u2705 Horizontal scalability: Add nodes without downtime \u2705 Operational simplicity: Standard NFS client compatibility</p> <p>Trade-offs: - Complexity: More moving parts than traditional NAS - Data durability: Requires additional replication/erasure coding - Cost: High-speed network and NVMe SSDs increase CapEx</p> <p>Ideal for: - AI/ML training clusters (GPU \u2192 storage throughput) - HPC workloads (parallel file access patterns) - Video rendering farms (large file streaming) - High-frequency trading (low-latency shared storage)</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"blog/2025/11/10/pnfs-distributed-storage-architecture/#references","title":"References","text":"<ul> <li>RFC 8881 - NFSv4.1 Protocol</li> <li>RFC 7862 - NFSv4.2 Protocol</li> <li>Linux pNFS Documentation</li> <li>Lustre pNFS Guide</li> <li>Red Hat: Configuring pNFS</li> </ul> <p>Tags: #pNFS #distributed-storage #NVMe #high-availability #load-balancing #metadata #clustering #InfiniBand #RoCE #parallel-io #file-systems #linux #performance-tuning #scalability</p> <p>Category: Storage, Architecture</p> <p>Have questions or running a similar setup? Open a discussion or reach out.</p>","tags":["pNFS","distributed-storage","NVMe","high-availability","load-balancing","metadata","clustering","InfiniBand","RoCE","parallel-io"]},{"location":"journal/","title":"Journal","text":"<p>Time-based log entries, learning notes, and progress updates.</p>"},{"location":"journal/#coming-soon","title":"Coming Soon","text":"<p>This section will contain:</p> <ul> <li>Learning Logs: Daily/weekly learning summaries</li> <li>Project Progress: Implementation updates</li> <li>Experiments: Technical experiments and findings</li> <li>Quick Notes: Short observations and discoveries</li> </ul> <p>Check back soon or watch the repository for updates.</p>"},{"location":"kb/","title":"Knowledge Base","text":"<p>Evergreen reference material, technical documentation, and curated resources.</p>"},{"location":"kb/#coming-soon","title":"Coming Soon","text":"<p>This section will contain:</p> <ul> <li>System Design Patterns: Reusable architectural patterns</li> <li>Protocol References: Detailed protocol documentation</li> <li>Tool Guides: Configuration and usage guides</li> <li>Troubleshooting Playbooks: Common issues and solutions</li> <li>Performance Baselines: Benchmark data and analysis</li> </ul> <p>Check back soon or watch the repository for updates.</p>"},{"location":"kubernetes/","title":"Kubernetes CKA Mastery","text":"<p>Complete hands-on guide to Kubernetes administration and CKA certification</p>"},{"location":"kubernetes/#about-the-cka-exam","title":"\ud83c\udfaf About the CKA Exam","text":"<p>The Certified Kubernetes Administrator (CKA) certification demonstrates proficiency in Kubernetes cluster administration, troubleshooting, and operations.</p>"},{"location":"kubernetes/#exam-details","title":"Exam Details","text":"<ul> <li>Duration: 2 hours</li> <li>Format: ~17 performance-based tasks (100% hands-on terminal work)</li> <li>Pass Score: 66%</li> <li>Cost: $445 (includes one free retake)</li> <li>Environment: Remote proctored, browser-based terminal</li> </ul>"},{"location":"kubernetes/#exam-domains-weights","title":"Exam Domains &amp; Weights","text":"<pre><code>pie title CKA Exam Domain Distribution\n    \"Troubleshooting\" : 30\n    \"Cluster Architecture\" : 25\n    \"Services &amp; Networking\" : 20\n    \"Workloads &amp; Scheduling\" : 15\n    \"Storage\" : 10</code></pre> Domain Weight Focus Areas Troubleshooting 30% Cluster/node issues, application debugging, monitoring Cluster Architecture 25% Installation, upgrades, RBAC, security, CRDs Services &amp; Networking 20% Services, Ingress, Gateway API, Network Policies Workloads &amp; Scheduling 15% Deployments, scheduling, pod configuration Storage 10% PV/PVC, ConfigMaps, Secrets, StorageClasses"},{"location":"kubernetes/#learning-path","title":"\ud83d\udcda Learning Path","text":"<p>This series covers 22 comprehensive posts organized into 7 phases, following the optimal learning sequence for CKA exam success.</p> <pre><code>graph TD\n    A[Phase 1: Foundations] --&gt; B[Phase 2: Workloads]\n    B --&gt; C[Phase 3: Networking]\n    C --&gt; D[Phase 4: Storage]\n    D --&gt; E[Phase 5: Security]\n    E --&gt; F[Phase 6: Advanced Config]\n    F --&gt; G[Phase 7: Troubleshooting]\n\n    A --&gt; A1[Architecture]\n    A --&gt; A2[Lab Setup]\n    A --&gt; A3[kubectl Basics]\n    A --&gt; A4[YAML &amp; Objects]\n    A --&gt; A5[Namespaces]\n\n    B --&gt; B1[Pods]\n    B --&gt; B2[Deployments]\n    B --&gt; B3[Scheduling]\n\n    C --&gt; C1[Services]\n    C --&gt; C2[Ingress/Gateway]\n    C --&gt; C3[Network Policies]\n    C --&gt; C4[DNS]\n\n    D --&gt; D1[PV/PVC]\n    D --&gt; D2[ConfigMaps/Secrets]\n\n    E --&gt; E1[RBAC]\n    E --&gt; E2[Security Contexts]\n    E --&gt; E3[CRDs/Operators]\n\n    F --&gt; F1[Helm]\n    F --&gt; F2[Kustomize]\n\n    G --&gt; G1[Cluster Troubleshooting]\n    G --&gt; G2[App Troubleshooting]\n    G --&gt; G3[Monitoring]\n\n    style A fill:#e1f5ff\n    style B fill:#fff4e1\n    style C fill:#e8f5e8\n    style D fill:#f3e5f5\n    style E fill:#ffe5e5\n    style F fill:#fff9e5\n    style G fill:#ffe5f0</code></pre>"},{"location":"kubernetes/#phase-1-foundations-5-posts","title":"\ud83c\udfd7\ufe0f Phase 1: Foundations (5 posts)","text":"<p>Build your foundational knowledge of Kubernetes architecture and essential tools.</p>"},{"location":"kubernetes/#1-kubernetes-architecture-fundamentals","title":"1. Kubernetes Architecture Fundamentals","text":"<p>Control plane components, worker nodes, etcd, API server, scheduler, controller manager Tags: <code>kubernetes</code> <code>architecture</code> <code>fundamentals</code> <code>cka-prep</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#2-setting-up-your-kubernetes-lab-environment","title":"2. Setting Up Your Kubernetes Lab Environment","text":"<p>kubeadm, Minikube, kind, kubectl installation, kubeconfig management Tags: <code>kubernetes</code> <code>installation</code> <code>lab-setup</code> <code>kubeadm</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#3-kubectl-essentials-your-kubernetes-swiss-army-knife","title":"3. kubectl Essentials: Your Kubernetes Swiss Army Knife","text":"<p>Master kubectl commands, aliases, output formats, context switching, imperative vs declarative Tags: <code>kubernetes</code> <code>kubectl</code> <code>cli</code> <code>basics</code> Domain: All (foundational skill)</p>"},{"location":"kubernetes/#4-understanding-kubernetes-objects-and-yaml-manifests","title":"4. Understanding Kubernetes Objects and YAML Manifests","text":"<p>API objects, YAML syntax, metadata, spec, status, labels, annotations, selectors Tags: <code>kubernetes</code> <code>yaml</code> <code>objects</code> <code>manifests</code> Domain: All (foundational skill)</p>"},{"location":"kubernetes/#5-namespaces-and-resource-quotas","title":"5. Namespaces and Resource Quotas","text":"<p>Namespace isolation, resource quotas, limit ranges, default namespace management Tags: <code>kubernetes</code> <code>namespaces</code> <code>resource-management</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#phase-2-workloads-scheduling-3-posts","title":"\u2699\ufe0f Phase 2: Workloads &amp; Scheduling (3 posts)","text":"<p>Master pod management, deployments, and advanced scheduling techniques.</p>"},{"location":"kubernetes/#6-pods-the-atomic-unit-of-kubernetes","title":"6. Pods: The Atomic Unit of Kubernetes","text":"<p>Pod lifecycle, init containers, sidecar patterns, multi-container communication Tags: <code>kubernetes</code> <code>pods</code> <code>workloads</code> <code>containers</code> Domain: Workloads &amp; Scheduling (15%)</p>"},{"location":"kubernetes/#7-deployments-replicasets-and-rolling-updates","title":"7. Deployments, ReplicaSets, and Rolling Updates","text":"<p>Deployments, ReplicaSets, DaemonSets, StatefulSets, rollouts, rollback strategies Tags: <code>kubernetes</code> <code>deployments</code> <code>replicasets</code> <code>workloads</code> Domain: Workloads &amp; Scheduling (15%)</p>"},{"location":"kubernetes/#8-advanced-scheduling-taints-tolerations-and-affinity","title":"8. Advanced Scheduling: Taints, Tolerations, and Affinity","text":"<p>Node selectors, taints/tolerations, node/pod affinity, anti-affinity, priority classes Tags: <code>kubernetes</code> <code>scheduling</code> <code>advanced</code> <code>affinity</code> Domain: Workloads &amp; Scheduling (15%)</p>"},{"location":"kubernetes/#phase-3-services-networking-4-posts","title":"\ud83c\udf10 Phase 3: Services &amp; Networking (4 posts)","text":"<p>Deep dive into Kubernetes networking, service discovery, and traffic management.</p>"},{"location":"kubernetes/#9-kubernetes-services-exposing-your-applications","title":"9. Kubernetes Services: Exposing Your Applications","text":"<p>ClusterIP, NodePort, LoadBalancer, ExternalName, service discovery, endpoints Tags: <code>kubernetes</code> <code>services</code> <code>networking</code> <code>service-discovery</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#10-ingress-and-gateway-api-modern-traffic-management","title":"10. Ingress and Gateway API: Modern Traffic Management","text":"<p>Ingress controllers, Ingress rules, Gateway API (GatewayClass, Gateway, HTTPRoute) Tags: <code>kubernetes</code> <code>ingress</code> <code>gateway-api</code> <code>traffic-management</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#11-network-policies-securing-pod-communication","title":"11. Network Policies: Securing Pod Communication","text":"<p>NetworkPolicy resources, ingress/egress rules, pod/namespace selectors, isolation Tags: <code>kubernetes</code> <code>network-policies</code> <code>security</code> <code>networking</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#12-coredns-and-service-discovery-deep-dive","title":"12. CoreDNS and Service Discovery Deep Dive","text":"<p>CoreDNS configuration, DNS for Services and Pods, troubleshooting DNS issues Tags: <code>kubernetes</code> <code>dns</code> <code>coredns</code> <code>service-discovery</code> Domain: Services &amp; Networking (20%)</p>"},{"location":"kubernetes/#phase-4-storage-2-posts","title":"\ud83d\udcbe Phase 4: Storage (2 posts)","text":"<p>Understand persistent storage and configuration management in Kubernetes.</p>"},{"location":"kubernetes/#13-persistent-volumes-and-claims-stateful-storage","title":"13. Persistent Volumes and Claims: Stateful Storage","text":"<p>PV, PVC, StorageClass, access modes, reclaim policies, dynamic provisioning Tags: <code>kubernetes</code> <code>storage</code> <code>persistent-volumes</code> <code>stateful</code> Domain: Storage (10%)</p>"},{"location":"kubernetes/#14-configmaps-secrets-and-volume-mounts","title":"14. ConfigMaps, Secrets, and Volume Mounts","text":"<p>ConfigMaps, Secrets, volume mounts, environment variables, projected volumes Tags: <code>kubernetes</code> <code>configmaps</code> <code>secrets</code> <code>configuration</code> Domain: Storage (10%)</p>"},{"location":"kubernetes/#phase-5-security-configuration-3-posts","title":"\ud83d\udd12 Phase 5: Security &amp; Configuration (3 posts)","text":"<p>Secure your cluster with RBAC, security contexts, and extensibility.</p>"},{"location":"kubernetes/#15-rbac-role-based-access-control","title":"15. RBAC: Role-Based Access Control","text":"<p>Roles, ClusterRoles, RoleBindings, ClusterRoleBindings, ServiceAccounts Tags: <code>kubernetes</code> <code>rbac</code> <code>security</code> <code>access-control</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#16-security-contexts-and-pod-security-standards","title":"16. Security Contexts and Pod Security Standards","text":"<p>SecurityContext, Pod Security Admission, privileged containers, capabilities, PSS Tags: <code>kubernetes</code> <code>security</code> <code>pod-security</code> <code>hardening</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#17-custom-resources-and-operators-crds","title":"17. Custom Resources and Operators (CRDs)","text":"<p>CustomResourceDefinitions, custom controllers, Operators, CRD inspection Tags: <code>kubernetes</code> <code>crds</code> <code>operators</code> <code>extensibility</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#phase-6-advanced-configuration-2-posts","title":"\ud83d\udd27 Phase 6: Advanced Configuration (2 posts)","text":"<p>Master Helm and Kustomize for production-grade configuration management.</p>"},{"location":"kubernetes/#18-helm-kubernetes-package-manager","title":"18. Helm: Kubernetes Package Manager","text":"<p>Helm charts, templating, values files, releases, hooks, chart repositories Tags: <code>kubernetes</code> <code>helm</code> <code>package-management</code> <code>charts</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#19-kustomize-template-free-configuration-management","title":"19. Kustomize: Template-Free Configuration Management","text":"<p>Kustomize bases, overlays, patches, transformers, generators, GitOps patterns Tags: <code>kubernetes</code> <code>kustomize</code> <code>configuration</code> <code>gitops</code> Domain: Cluster Architecture (25%)</p>"},{"location":"kubernetes/#phase-7-troubleshooting-monitoring-3-posts","title":"\ud83d\udd0d Phase 7: Troubleshooting &amp; Monitoring (3 posts)","text":"<p>Become an expert at diagnosing and resolving Kubernetes issues.</p>"},{"location":"kubernetes/#20-troubleshooting-clusters-nodes-and-components","title":"20. Troubleshooting Clusters, Nodes, and Components","text":"<p>Node issues, control plane debugging, certificate problems, etcd health checks Tags: <code>kubernetes</code> <code>troubleshooting</code> <code>debugging</code> <code>cluster-health</code> Domain: Troubleshooting (30%)</p>"},{"location":"kubernetes/#21-application-troubleshooting-and-log-analysis","title":"21. Application Troubleshooting and Log Analysis","text":"<p>Pod debugging, container logs, exec commands, ephemeral containers, event analysis Tags: <code>kubernetes</code> <code>troubleshooting</code> <code>logs</code> <code>debugging</code> Domain: Troubleshooting (30%)</p>"},{"location":"kubernetes/#22-monitoring-metrics-and-resource-management","title":"22. Monitoring, Metrics, and Resource Management","text":"<p>Metrics Server, resource requests/limits, HPA, VPA, monitoring stack integration Tags: <code>kubernetes</code> <code>monitoring</code> <code>metrics</code> <code>autoscaling</code> Domain: Troubleshooting (30%)</p>"},{"location":"kubernetes/#how-to-use-this-series","title":"\ud83d\udcd6 How to Use This Series","text":""},{"location":"kubernetes/#recommended-study-approach","title":"Recommended Study Approach","text":"<ol> <li>Follow the Order: Posts are sequenced for optimal learning progression</li> <li>Hands-On Practice: Set up a lab environment (Post 2) and practice every command</li> <li>Take Notes: Create your own command cheat sheets as you progress</li> <li>Review Diagrams: Study the architecture diagrams to understand component relationships</li> <li>Do the Exercises: Complete practice tasks at the end of each post</li> <li>Cross-Reference: Use links between posts to review related concepts</li> </ol>"},{"location":"kubernetes/#study-timeline","title":"Study Timeline","text":"<ul> <li>Intensive: 4-6 weeks (1 post per day)</li> <li>Standard: 8-12 weeks (2-3 posts per week)</li> <li>Relaxed: 3-4 months (1-2 posts per week)</li> </ul>"},{"location":"kubernetes/#exam-preparation-tips","title":"Exam Preparation Tips","text":"<p>\u2705 Do: - Practice in a terminal environment (exam is 100% command-line) - Use <code>kubectl</code> imperative commands for speed - Master <code>kubectl explain</code> and <code>-h</code> flags for in-exam reference - Time yourself on practice exercises - Focus heavily on Troubleshooting (30% weight)</p> <p>\u274c Don't: - Memorize YAML templates (use <code>kubectl</code> generators instead) - Ignore troubleshooting topics (highest exam weight) - Skip hands-on practice (reading alone is insufficient) - Forget about time management (2 hours goes fast)</p>"},{"location":"kubernetes/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<p>Before starting this series, you should have:</p> <ul> <li>Basic understanding of Linux command line</li> <li>Familiarity with containerization concepts (Docker)</li> <li>Access to a Linux/macOS machine or Windows with WSL2</li> <li>Willingness to practice hands-on (not just read)</li> </ul>"},{"location":"kubernetes/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>Official CKA Exam Page</li> <li>Kubernetes Official Documentation</li> <li>kubectl Command Reference</li> <li>CKA Curriculum (Official)</li> </ul>"},{"location":"kubernetes/#ready-to-start","title":"\ud83d\ude80 Ready to Start?","text":"<p>Begin your journey with Post 1: Kubernetes Architecture Fundamentals and work through the series systematically.</p> <p>Good luck with your CKA certification! \ud83c\udf93</p> <p>Last Updated: 2025-11-10 Series Status: In Progress (Post 1 available) Total Posts: 22 planned</p>"},{"location":"principles/","title":"Principles","text":"<p>Engineering principles, design philosophies, and decision-making frameworks.</p>"},{"location":"principles/#coming-soon","title":"Coming Soon","text":"<p>This section will explore:</p> <ul> <li>Architecture Principles: Foundational design guidelines</li> <li>Performance Principles: Optimization philosophies</li> <li>Reliability Principles: Building resilient systems</li> <li>Scalability Principles: Growing systems effectively</li> <li>Simplicity Principles: Managing complexity</li> </ul> <p>Check back soon or watch the repository for updates.</p>"},{"location":"blog/archive/2025/","title":"November 2025","text":""},{"location":"blog/category/kubernetes/","title":"Kubernetes","text":""},{"location":"blog/category/cli/","title":"CLI","text":""},{"location":"blog/category/architecture/","title":"Architecture","text":""},{"location":"blog/category/infrastructure/","title":"Infrastructure","text":""},{"location":"blog/category/configuration/","title":"Configuration","text":""},{"location":"blog/category/storage/","title":"Storage","text":""}]}